{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UrBvH-g8GxD",
    "outputId": "65ac4b7c-55e6-461a-da73-3310573b02d6"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/hannahpu/widsdatathon2022.git\n",
    "# ! ls ./widsdatathon2022\n",
    "# ! pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "wBT_F_YX7tyX",
    "outputId": "1cfedaf2-6f51-4eb3-96d0-0111e7e7b0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-25\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from datetime import datetime\\nimport sys\\n\\nimport pandas as pd\\nimport catboost as cb\\nimport xgboost as xgb\\n\\nimport lightgbm as lgb\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# Will need enable_iterative_imputer import otherwise IterativeImputer\\n# gives import error\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.experimental import enable_iterative_imputer\\nfrom sklearn.impute import IterativeImputer\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\nsys.path.append(\\\"..\\\")\\nimport global_vars as gv\\nfrom utils import model_utils as mu\\nfrom utils import data_utils as du\\nfrom utils import data_process_utils as dpu\\nfrom utils import visualize as viz\\n\\n%load_ext nb_black\\n\\ntoday = datetime.today().date()\\nprint(today)\";\n",
       "                var nbb_formatted_code = \"from datetime import datetime\\nimport sys\\n\\nimport pandas as pd\\nimport catboost as cb\\nimport xgboost as xgb\\n\\nimport lightgbm as lgb\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# Will need enable_iterative_imputer import otherwise IterativeImputer\\n# gives import error\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.experimental import enable_iterative_imputer\\nfrom sklearn.impute import IterativeImputer\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\nsys.path.append(\\\"..\\\")\\nimport global_vars as gv\\nfrom utils import model_utils as mu\\nfrom utils import data_utils as du\\nfrom utils import data_process_utils as dpu\\nfrom utils import visualize as viz\\n\\n%load_ext nb_black\\n\\ntoday = datetime.today().date()\\nprint(today)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Will need enable_iterative_imputer import otherwise IterativeImputer\n",
    "# gives import error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import global_vars as gv\n",
    "from utils import model_utils as mu\n",
    "from utils import data_utils as du\n",
    "from utils import data_process_utils as dpu\n",
    "from utils import visualize as viz\n",
    "\n",
    "%load_ext nb_black\n",
    "\n",
    "today = datetime.today().date()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tY7bD2Awnps9",
    "outputId": "d22e2d8d-459c-442e-b508-f33f6fee5b7e"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"wids_path = \\\"../\\\"\";\n",
       "                var nbb_formatted_code = \"wids_path = \\\"../\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wids_path = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "miNzq96M7xAu",
    "outputId": "39810107-9d80-4d6b-dcea-72cb9a7a7b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dimension: (9705, 63)\n",
      "Train dimension: (75757, 64)\n",
      "Sample solution dimension: (9705, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"test_df = pd.read_csv(\\\"../data/test.csv\\\")\\nprint(f\\\"Test dimension: {test_df.shape}\\\")\\ntrain_df = pd.read_csv(\\\"../data/train.csv\\\")\\nprint(f\\\"Train dimension: {train_df.shape}\\\")\\nsample_solution_df = pd.read_csv(\\\"../data/sample_solution.csv\\\")\\nprint(f\\\"Sample solution dimension: {sample_solution_df.shape}\\\")\\ntrain_df.columns = train_df.columns.str.lower()\\ntest_df.columns = test_df.columns.str.lower()\";\n",
       "                var nbb_formatted_code = \"test_df = pd.read_csv(\\\"../data/test.csv\\\")\\nprint(f\\\"Test dimension: {test_df.shape}\\\")\\ntrain_df = pd.read_csv(\\\"../data/train.csv\\\")\\nprint(f\\\"Train dimension: {train_df.shape}\\\")\\nsample_solution_df = pd.read_csv(\\\"../data/sample_solution.csv\\\")\\nprint(f\\\"Sample solution dimension: {sample_solution_df.shape}\\\")\\ntrain_df.columns = train_df.columns.str.lower()\\ntest_df.columns = test_df.columns.str.lower()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "print(f\"Test dimension: {test_df.shape}\")\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"Train dimension: {train_df.shape}\")\n",
    "sample_solution_df = pd.read_csv(\"../data/sample_solution.csv\")\n",
    "print(f\"Sample solution dimension: {sample_solution_df.shape}\")\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "test_df.columns = test_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State_6     50840\n",
       "State_11     6412\n",
       "State_1      5618\n",
       "State_2      4871\n",
       "State_4      4300\n",
       "State_8      3701\n",
       "State_10       15\n",
       "Name: state_factor, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State_11    3268\n",
       "State_4     2568\n",
       "State_2     1515\n",
       "State_8     1323\n",
       "State_1     1027\n",
       "State_10       4\n",
       "Name: state_factor, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6    22449\n",
       "5    18308\n",
       "4    12946\n",
       "3    10879\n",
       "2     9058\n",
       "1     2117\n",
       "Name: year_factor, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>building_class</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>energy_star_rating</th>\n",
       "      <th>elevation</th>\n",
       "      <th>january_min_temp</th>\n",
       "      <th>january_avg_temp</th>\n",
       "      <th>january_max_temp</th>\n",
       "      <th>february_min_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>days_above_80f</th>\n",
       "      <th>days_above_90f</th>\n",
       "      <th>days_above_100f</th>\n",
       "      <th>days_above_110f</th>\n",
       "      <th>direction_max_wind_speed</th>\n",
       "      <th>direction_peak_wind_speed</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>days_with_fog</th>\n",
       "      <th>site_eui</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_factor</th>\n",
       "      <th>year_factor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">State_1</th>\n",
       "      <th>1</th>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>338</td>\n",
       "      <td>294</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>...</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>541</td>\n",
       "      <td>432</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>...</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>609</td>\n",
       "      <td>599</td>\n",
       "      <td>609</td>\n",
       "      <td>577</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>913</td>\n",
       "      <td>677</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>...</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>1242</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>965</td>\n",
       "      <td>707</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>...</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>1261</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>995</td>\n",
       "      <td>725</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>...</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>1041</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>987</td>\n",
       "      <td>714</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>...</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">State_10</th>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">State_11</th>\n",
       "      <th>5</th>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3189</td>\n",
       "      <td>2460</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>...</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>2435</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>...</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">State_2</th>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>513</td>\n",
       "      <td>246</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>...</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>1334</td>\n",
       "      <td>1131</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>...</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>1370</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>1524</td>\n",
       "      <td>1306</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>...</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1558</td>\n",
       "      <td>1558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1369</td>\n",
       "      <td>1164</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>...</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">State_4</th>\n",
       "      <th>4</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>195</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1164</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>...</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>592</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2602</td>\n",
       "      <td>2237</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>...</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>1187</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">State_6</th>\n",
       "      <th>1</th>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1611</td>\n",
       "      <td>1228</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>8072</td>\n",
       "      <td>1464</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>...</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "      <td>6513</td>\n",
       "      <td>6513</td>\n",
       "      <td>6513</td>\n",
       "      <td>6574</td>\n",
       "      <td>8364</td>\n",
       "      <td>8364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>8120</td>\n",
       "      <td>1405</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>...</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "      <td>2288</td>\n",
       "      <td>2288</td>\n",
       "      <td>2288</td>\n",
       "      <td>2447</td>\n",
       "      <td>8298</td>\n",
       "      <td>8298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>9074</td>\n",
       "      <td>7500</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>...</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "      <td>8929</td>\n",
       "      <td>8929</td>\n",
       "      <td>8929</td>\n",
       "      <td>1745</td>\n",
       "      <td>9269</td>\n",
       "      <td>9269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>10130</td>\n",
       "      <td>8526</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>...</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "      <td>5477</td>\n",
       "      <td>4786</td>\n",
       "      <td>5477</td>\n",
       "      <td>5477</td>\n",
       "      <td>10146</td>\n",
       "      <td>10146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>13000</td>\n",
       "      <td>10564</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>...</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "      <td>6163</td>\n",
       "      <td>6163</td>\n",
       "      <td>6163</td>\n",
       "      <td>7040</td>\n",
       "      <td>13017</td>\n",
       "      <td>13017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">State_8</th>\n",
       "      <th>3</th>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>818</td>\n",
       "      <td>493</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>...</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>482</td>\n",
       "      <td>482</td>\n",
       "      <td>482</td>\n",
       "      <td>482</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>530</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>...</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>158</td>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>911</td>\n",
       "      <td>582</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>...</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>1156</td>\n",
       "      <td>844</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>...</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>635</td>\n",
       "      <td>1158</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          building_class  facility_type  floor_area  \\\n",
       "state_factor year_factor                                              \n",
       "State_1      1                       358            358         358   \n",
       "             2                       680            680         680   \n",
       "             3                      1242           1242        1242   \n",
       "             4                      1261           1261        1261   \n",
       "             5                      1041           1041        1041   \n",
       "             6                      1036           1036        1036   \n",
       "State_10     3                         3              3           3   \n",
       "             4                         4              4           4   \n",
       "             5                         4              4           4   \n",
       "             6                         4              4           4   \n",
       "State_11     5                      3191           3191        3191   \n",
       "             6                      3221           3221        3221   \n",
       "State_2      1                        13             13          13   \n",
       "             2                        14             14          14   \n",
       "             3                       515            515         515   \n",
       "             4                      1370           1370        1370   \n",
       "             5                      1558           1558        1558   \n",
       "             6                      1401           1401        1401   \n",
       "State_4      4                       232            232         232   \n",
       "             5                      1456           1456        1456   \n",
       "             6                      2612           2612        2612   \n",
       "State_6      1                      1746           1746        1746   \n",
       "             2                      8364           8364        8364   \n",
       "             3                      8298           8298        8298   \n",
       "             4                      9269           9269        9269   \n",
       "             5                     10146          10146       10146   \n",
       "             6                     13017          13017       13017   \n",
       "State_8      3                       821            821         821   \n",
       "             4                       810            810         810   \n",
       "             5                       912            912         912   \n",
       "             6                      1158           1158        1158   \n",
       "\n",
       "                          year_built  energy_star_rating  elevation  \\\n",
       "state_factor year_factor                                              \n",
       "State_1      1                   338                 294        358   \n",
       "             2                   541                 432        680   \n",
       "             3                   913                 677       1242   \n",
       "             4                   965                 707       1261   \n",
       "             5                   995                 725       1041   \n",
       "             6                   987                 714       1036   \n",
       "State_10     3                     3                   2          3   \n",
       "             4                     4                   3          4   \n",
       "             5                     4                   3          4   \n",
       "             6                     4                   4          4   \n",
       "State_11     5                  3189                2460       3191   \n",
       "             6                  3221                2435       3221   \n",
       "State_2      1                    12                   5         13   \n",
       "             2                    12                   8         14   \n",
       "             3                   513                 246        515   \n",
       "             4                  1334                1131       1370   \n",
       "             5                  1524                1306       1558   \n",
       "             6                  1369                1164       1401   \n",
       "State_4      4                   232                 195        232   \n",
       "             5                  1456                1164       1456   \n",
       "             6                  2602                2237       2612   \n",
       "State_6      1                  1611                1228       1746   \n",
       "             2                  8072                1464       8364   \n",
       "             3                  8120                1405       8298   \n",
       "             4                  9074                7500       9269   \n",
       "             5                 10130                8526      10146   \n",
       "             6                 13000               10564      13017   \n",
       "State_8      3                   818                 493        821   \n",
       "             4                   810                 530        810   \n",
       "             5                   911                 582        912   \n",
       "             6                  1156                 844       1158   \n",
       "\n",
       "                          january_min_temp  january_avg_temp  \\\n",
       "state_factor year_factor                                       \n",
       "State_1      1                         358               358   \n",
       "             2                         680               680   \n",
       "             3                        1242              1242   \n",
       "             4                        1261              1261   \n",
       "             5                        1041              1041   \n",
       "             6                        1036              1036   \n",
       "State_10     3                           3                 3   \n",
       "             4                           4                 4   \n",
       "             5                           4                 4   \n",
       "             6                           4                 4   \n",
       "State_11     5                        3191              3191   \n",
       "             6                        3221              3221   \n",
       "State_2      1                          13                13   \n",
       "             2                          14                14   \n",
       "             3                         515               515   \n",
       "             4                        1370              1370   \n",
       "             5                        1558              1558   \n",
       "             6                        1401              1401   \n",
       "State_4      4                         232               232   \n",
       "             5                        1456              1456   \n",
       "             6                        2612              2612   \n",
       "State_6      1                        1746              1746   \n",
       "             2                        8364              8364   \n",
       "             3                        8298              8298   \n",
       "             4                        9269              9269   \n",
       "             5                       10146             10146   \n",
       "             6                       13017             13017   \n",
       "State_8      3                         821               821   \n",
       "             4                         810               810   \n",
       "             5                         912               912   \n",
       "             6                        1158              1158   \n",
       "\n",
       "                          january_max_temp  february_min_temp  ...  \\\n",
       "state_factor year_factor                                       ...   \n",
       "State_1      1                         358                358  ...   \n",
       "             2                         680                680  ...   \n",
       "             3                        1242               1242  ...   \n",
       "             4                        1261               1261  ...   \n",
       "             5                        1041               1041  ...   \n",
       "             6                        1036               1036  ...   \n",
       "State_10     3                           3                  3  ...   \n",
       "             4                           4                  4  ...   \n",
       "             5                           4                  4  ...   \n",
       "             6                           4                  4  ...   \n",
       "State_11     5                        3191               3191  ...   \n",
       "             6                        3221               3221  ...   \n",
       "State_2      1                          13                 13  ...   \n",
       "             2                          14                 14  ...   \n",
       "             3                         515                515  ...   \n",
       "             4                        1370               1370  ...   \n",
       "             5                        1558               1558  ...   \n",
       "             6                        1401               1401  ...   \n",
       "State_4      4                         232                232  ...   \n",
       "             5                        1456               1456  ...   \n",
       "             6                        2612               2612  ...   \n",
       "State_6      1                        1746               1746  ...   \n",
       "             2                        8364               8364  ...   \n",
       "             3                        8298               8298  ...   \n",
       "             4                        9269               9269  ...   \n",
       "             5                       10146              10146  ...   \n",
       "             6                       13017              13017  ...   \n",
       "State_8      3                         821                821  ...   \n",
       "             4                         810                810  ...   \n",
       "             5                         912                912  ...   \n",
       "             6                        1158               1158  ...   \n",
       "\n",
       "                          days_above_80f  days_above_90f  days_above_100f  \\\n",
       "state_factor year_factor                                                    \n",
       "State_1      1                       358             358              358   \n",
       "             2                       680             680              680   \n",
       "             3                      1242            1242             1242   \n",
       "             4                      1261            1261             1261   \n",
       "             5                      1041            1041             1041   \n",
       "             6                      1036            1036             1036   \n",
       "State_10     3                         3               3                3   \n",
       "             4                         4               4                4   \n",
       "             5                         4               4                4   \n",
       "             6                         4               4                4   \n",
       "State_11     5                      3191            3191             3191   \n",
       "             6                      3221            3221             3221   \n",
       "State_2      1                        13              13               13   \n",
       "             2                        14              14               14   \n",
       "             3                       515             515              515   \n",
       "             4                      1370            1370             1370   \n",
       "             5                      1558            1558             1558   \n",
       "             6                      1401            1401             1401   \n",
       "State_4      4                       232             232              232   \n",
       "             5                      1456            1456             1456   \n",
       "             6                      2612            2612             2612   \n",
       "State_6      1                      1746            1746             1746   \n",
       "             2                      8364            8364             8364   \n",
       "             3                      8298            8298             8298   \n",
       "             4                      9269            9269             9269   \n",
       "             5                     10146           10146            10146   \n",
       "             6                     13017           13017            13017   \n",
       "State_8      3                       821             821              821   \n",
       "             4                       810             810              810   \n",
       "             5                       912             912              912   \n",
       "             6                      1158            1158             1158   \n",
       "\n",
       "                          days_above_110f  direction_max_wind_speed  \\\n",
       "state_factor year_factor                                              \n",
       "State_1      1                        358                        27   \n",
       "             2                        680                       609   \n",
       "             3                       1242                        33   \n",
       "             4                       1261                        55   \n",
       "             5                       1041                        22   \n",
       "             6                       1036                        11   \n",
       "State_10     3                          3                         3   \n",
       "             4                          4                         0   \n",
       "             5                          4                         4   \n",
       "             6                          4                         4   \n",
       "State_11     5                       3191                         0   \n",
       "             6                       3221                       620   \n",
       "State_2      1                         13                         0   \n",
       "             2                         14                         0   \n",
       "             3                        515                         0   \n",
       "             4                       1370                       269   \n",
       "             5                       1558                         0   \n",
       "             6                       1401                        95   \n",
       "State_4      4                        232                         0   \n",
       "             5                       1456                       316   \n",
       "             6                       2612                        95   \n",
       "State_6      1                       1746                      1746   \n",
       "             2                       8364                      6513   \n",
       "             3                       8298                      2288   \n",
       "             4                       9269                      8929   \n",
       "             5                      10146                      5477   \n",
       "             6                      13017                      6163   \n",
       "State_8      3                        821                       482   \n",
       "             4                        810                       178   \n",
       "             5                        912                        48   \n",
       "             6                       1158                       688   \n",
       "\n",
       "                          direction_peak_wind_speed  max_wind_speed  \\\n",
       "state_factor year_factor                                              \n",
       "State_1      1                                   12              27   \n",
       "             2                                  599             609   \n",
       "             3                                   20              33   \n",
       "             4                                   55              55   \n",
       "             5                                   22              22   \n",
       "             6                                   11              11   \n",
       "State_10     3                                    3               3   \n",
       "             4                                    0               0   \n",
       "             5                                    4               4   \n",
       "             6                                    4               4   \n",
       "State_11     5                                    0               0   \n",
       "             6                                  620             620   \n",
       "State_2      1                                    0               0   \n",
       "             2                                    0               0   \n",
       "             3                                    0               0   \n",
       "             4                                  269             269   \n",
       "             5                                    0               0   \n",
       "             6                                   95              95   \n",
       "State_4      4                                    0               0   \n",
       "             5                                  316             316   \n",
       "             6                                   95              95   \n",
       "State_6      1                                 1746            1746   \n",
       "             2                                 6513            6513   \n",
       "             3                                 2288            2288   \n",
       "             4                                 8929            8929   \n",
       "             5                                 4786            5477   \n",
       "             6                                 6163            6163   \n",
       "State_8      3                                  482             482   \n",
       "             4                                  178             178   \n",
       "             5                                   48              48   \n",
       "             6                                  688             688   \n",
       "\n",
       "                          days_with_fog  site_eui     id  \n",
       "state_factor year_factor                                  \n",
       "State_1      1                       15       358    358  \n",
       "             2                      577       680    680  \n",
       "             3                       27      1242   1242  \n",
       "             4                       40      1261   1261  \n",
       "             5                       22      1041   1041  \n",
       "             6                        0      1036   1036  \n",
       "State_10     3                        3         3      3  \n",
       "             4                        0         4      4  \n",
       "             5                        4         4      4  \n",
       "             6                        4         4      4  \n",
       "State_11     5                        0      3191   3191  \n",
       "             6                      620      3221   3221  \n",
       "State_2      1                        0        13     13  \n",
       "             2                        0        14     14  \n",
       "             3                        0       515    515  \n",
       "             4                      269      1370   1370  \n",
       "             5                        0      1558   1558  \n",
       "             6                       95      1401   1401  \n",
       "State_4      4                      154       232    232  \n",
       "             5                      592      1456   1456  \n",
       "             6                     1187      2612   2612  \n",
       "State_6      1                     1746      1746   1746  \n",
       "             2                     6574      8364   8364  \n",
       "             3                     2447      8298   8298  \n",
       "             4                     1745      9269   9269  \n",
       "             5                     5477     10146  10146  \n",
       "             6                     7040     13017  13017  \n",
       "State_8      3                      482       821    821  \n",
       "             4                      158       810    810  \n",
       "             5                       48       912    912  \n",
       "             6                      635      1158   1158  \n",
       "\n",
       "[31 rows x 62 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"display(train_df.state_factor.value_counts())\\ndisplay(test_df.state_factor.value_counts())\\n\\n# display(train_df.query(\\\"state_factor == 'State_6'\\\").year_factor.value_counts())\\n# for state in train_df.state_factor.unique():\\n#     print(state)\\n#     display(train_df.query(\\\"state_factor == @state\\\").year_factor.value_counts())\\n\\n# Upsample by two columns?\\ndisplay(train_df.year_factor.value_counts())\\n\\ndisplay(train_df.groupby([\\\"state_factor\\\", \\\"year_factor\\\"]).count())\";\n",
       "                var nbb_formatted_code = \"display(train_df.state_factor.value_counts())\\ndisplay(test_df.state_factor.value_counts())\\n\\n# display(train_df.query(\\\"state_factor == 'State_6'\\\").year_factor.value_counts())\\n# for state in train_df.state_factor.unique():\\n#     print(state)\\n#     display(train_df.query(\\\"state_factor == @state\\\").year_factor.value_counts())\\n\\n# Upsample by two columns?\\ndisplay(train_df.year_factor.value_counts())\\n\\ndisplay(train_df.groupby([\\\"state_factor\\\", \\\"year_factor\\\"]).count())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.state_factor.value_counts())\n",
    "display(test_df.state_factor.value_counts())\n",
    "\n",
    "# display(train_df.query(\"state_factor == 'State_6'\").year_factor.value_counts())\n",
    "# for state in train_df.state_factor.unique():\n",
    "#     print(state)\n",
    "#     display(train_df.query(\"state_factor == @state\").year_factor.value_counts())\n",
    "\n",
    "# Upsample by two columns?\n",
    "display(train_df.year_factor.value_counts())\n",
    "\n",
    "display(train_df.groupby([\"state_factor\", \"year_factor\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "xHd39G2t9b4H",
    "outputId": "dc1d9151-b0bb-4afc-9740-2f9f45084b9e"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Add parsed facility type, after parsing it has 20 types\\ntrain_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=train_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\\ntest_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=test_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"# Add parsed facility type, after parsing it has 20 types\\ntrain_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=train_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\\ntest_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=test_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add parsed facility type, after parsing it has 20 types\n",
    "train_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
    "    input_df=train_df.copy(), facility_type_colname=\"facility_type\"\n",
    ")\n",
    "test_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
    "    input_df=test_df.copy(), facility_type_colname=\"facility_type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "6vRguYhg-3Ii",
    "outputId": "d8b7171c-0415-4050-9359-22f0c4cfb68c"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Backfill missing 'direction_max_wind_speed' with categorized values based on\\n# [\\\"state_factor\\\", \\\"year\\\"] aggregation\\ngroupby_list = [\\\"state_factor\\\", \\\"year_factor\\\"]\\ncol = \\\"direction_max_wind_speed\\\"\\n\\ntrain_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=train_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=groupby_list,\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# Because there is only one year in test data therefore backfill based on\\n# [\\\"state_factor\\\", \\\"year_factor\\\"] won't work, therefore we only used \\\"state_factor\\\"\\n# instead\\ntest_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=test_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=[\\\"state_factor\\\"],\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# print(train_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n# print(test_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n\\n# Get categorized on 'backfilled_direction_max_wind_speed'\\nbackfilled_max_wind_speed_col = \\\"backfilled_direction_max_wind_speed\\\"\\ntrain_w_categorized_max_wind_speed_df = (\\n    train_backfill_direction_max_wind_speed_df.assign(\\n        categorized_direction_max_wind_speed=lambda df: df[\\n            backfilled_max_wind_speed_col\\n        ].apply(\\n            lambda a_direction_value: dpu.categorize_wind_direction(\\n                wind_direction_degree=a_direction_value, n_bins_categorized=8\\n            )\\n        )\\n    )\\n)\\n\\ntest_w_categorized_max_wind_speed_df = test_backfill_direction_max_wind_speed_df.assign(\\n    categorized_direction_max_wind_speed=lambda df: df[\\n        backfilled_max_wind_speed_col\\n    ].apply(\\n        lambda a_direction_value: dpu.categorize_wind_direction(\\n            wind_direction_degree=a_direction_value, n_bins_categorized=8\\n        )\\n    )\\n)\\n# print(train_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\\n# print(test_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\";\n",
       "                var nbb_formatted_code = \"# Backfill missing 'direction_max_wind_speed' with categorized values based on\\n# [\\\"state_factor\\\", \\\"year\\\"] aggregation\\ngroupby_list = [\\\"state_factor\\\", \\\"year_factor\\\"]\\ncol = \\\"direction_max_wind_speed\\\"\\n\\ntrain_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=train_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=groupby_list,\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# Because there is only one year in test data therefore backfill based on\\n# [\\\"state_factor\\\", \\\"year_factor\\\"] won't work, therefore we only used \\\"state_factor\\\"\\n# instead\\ntest_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=test_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=[\\\"state_factor\\\"],\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# print(train_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n# print(test_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n\\n# Get categorized on 'backfilled_direction_max_wind_speed'\\nbackfilled_max_wind_speed_col = \\\"backfilled_direction_max_wind_speed\\\"\\ntrain_w_categorized_max_wind_speed_df = (\\n    train_backfill_direction_max_wind_speed_df.assign(\\n        categorized_direction_max_wind_speed=lambda df: df[\\n            backfilled_max_wind_speed_col\\n        ].apply(\\n            lambda a_direction_value: dpu.categorize_wind_direction(\\n                wind_direction_degree=a_direction_value, n_bins_categorized=8\\n            )\\n        )\\n    )\\n)\\n\\ntest_w_categorized_max_wind_speed_df = test_backfill_direction_max_wind_speed_df.assign(\\n    categorized_direction_max_wind_speed=lambda df: df[\\n        backfilled_max_wind_speed_col\\n    ].apply(\\n        lambda a_direction_value: dpu.categorize_wind_direction(\\n            wind_direction_degree=a_direction_value, n_bins_categorized=8\\n        )\\n    )\\n)\\n# print(train_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\\n# print(test_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Backfill missing 'direction_max_wind_speed' with categorized values based on\n",
    "# [\"state_factor\", \"year\"] aggregation\n",
    "groupby_list = [\"state_factor\", \"year_factor\"]\n",
    "col = \"direction_max_wind_speed\"\n",
    "\n",
    "train_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\n",
    "    input_df=train_w_parsed_facility_type_df,\n",
    "    mapping_df=train_w_parsed_facility_type_df,\n",
    "    groupby_list=groupby_list,\n",
    "    wind_direction_colname=col,\n",
    "    agg_approach_func=np.nanmean,\n",
    ")\n",
    "# Because there is only one year in test data therefore backfill based on\n",
    "# [\"state_factor\", \"year_factor\"] won't work, therefore we only used \"state_factor\"\n",
    "# instead\n",
    "test_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\n",
    "    input_df=test_w_parsed_facility_type_df,\n",
    "    mapping_df=train_w_parsed_facility_type_df,\n",
    "    groupby_list=[\"state_factor\"],\n",
    "    wind_direction_colname=col,\n",
    "    agg_approach_func=np.nanmean,\n",
    ")\n",
    "# print(train_backfill_direction_max_wind_speed_df.filter(like=\"direction_max\").info())\n",
    "# print(test_backfill_direction_max_wind_speed_df.filter(like=\"direction_max\").info())\n",
    "\n",
    "# Get categorized on 'backfilled_direction_max_wind_speed'\n",
    "backfilled_max_wind_speed_col = \"backfilled_direction_max_wind_speed\"\n",
    "train_w_categorized_max_wind_speed_df = (\n",
    "    train_backfill_direction_max_wind_speed_df.assign(\n",
    "        categorized_direction_max_wind_speed=lambda df: df[\n",
    "            backfilled_max_wind_speed_col\n",
    "        ].apply(\n",
    "            lambda a_direction_value: dpu.categorize_wind_direction(\n",
    "                wind_direction_degree=a_direction_value, n_bins_categorized=8\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "test_w_categorized_max_wind_speed_df = test_backfill_direction_max_wind_speed_df.assign(\n",
    "    categorized_direction_max_wind_speed=lambda df: df[\n",
    "        backfilled_max_wind_speed_col\n",
    "    ].apply(\n",
    "        lambda a_direction_value: dpu.categorize_wind_direction(\n",
    "            wind_direction_degree=a_direction_value, n_bins_categorized=8\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# print(train_w_categorized_max_wind_speed_df.filter(like=\"categorized_direction\"))\n",
    "# print(test_w_categorized_max_wind_speed_df.filter(like=\"categorized_direction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkuPjfeMYrnY"
   },
   "source": [
    "**Use iterative imputer to impute energy star ratings**\n",
    "\n",
    "updated as of 02/23: Not using \"facility_type_parsed\" in to fit the imputer as we will be relabel the facility type using energy star ratings\n",
    "\n",
    "With PCA components = 19 which explains 99% variance and one-hot-encoding. The categorical features used in the imputer are \"state_factor\", \"building_class\", and \"facility_type_parsed\". The numerical features are all below temp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "rHdy0I7SImpp",
    "outputId": "a4163469-b1a5-4fef-b1f7-aa91c5fe40ed"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"train_impute_energy_star_df = train_w_categorized_max_wind_speed_df.copy()\\ntest_impute_energy_star_df = test_w_categorized_max_wind_speed_df.copy()\\n\\n# Run a PCA for missing value imputation in energy star rating\\ncols_to_reduce_numerical = gv.below_temp_col_list \\ncols_to_reduce_categorical = [\\\"state_factor\\\", \\n                              \\\"building_class\\\", \\n#                               \\\"facility_type_parsed\\\"\\n                             ]\\n\\n# Need a one-hot-encoding\\ntrain_impute_energy_star_dfs_list = []\\ntest_impute_energy_star_dfs_list = []\\nfor a_categorical_col in cols_to_reduce_categorical:\\n    onehot_encoder = OneHotEncoder().fit(\\n      train_impute_energy_star_df[[a_categorical_col]])\\n    train_impute_energy_star_transformed_array = onehot_encoder.transform(\\n      train_impute_energy_star_df[[a_categorical_col]]).toarray()\\n    test_impute_energy_star_transformed_array = onehot_encoder.transform(\\n      test_impute_energy_star_df[[a_categorical_col]]).toarray()\\n    \\n    train_impute_energy_star_transformed_df = pd.DataFrame(\\n      train_impute_energy_star_transformed_array, \\n      columns=[f\\\"{a_categorical_col}_{i}\\\" for i in \\n               range(train_impute_energy_star_transformed_array.shape[1])])\\n    test_impute_energy_star_transformed_df = pd.DataFrame(\\n      test_impute_energy_star_transformed_array, \\n      columns=[f\\\"{a_categorical_col}_{i}\\\" for i in \\n               range(test_impute_energy_star_transformed_array.shape[1])])\\n    \\n    train_impute_energy_star_dfs_list.append(train_impute_energy_star_transformed_df)\\n    test_impute_energy_star_dfs_list.append(test_impute_energy_star_transformed_df)\\n\\n# Merge processed categorical data into one based on index\\ntrain_impute_energy_star_processed_categorical_df = pd.concat(\\n    train_impute_energy_star_dfs_list, axis=1\\n)\\ntest_impute_energy_star_processed_categorical_df = pd.concat(\\n    test_impute_energy_star_dfs_list, axis=1\\n)\\n\\nscaled_train_impute_energy_star_df, scaled_test_impute_energy_star_df = mu.scale_data(\\n    train_impute_energy_star_df[cols_to_reduce_numerical], \\n    test_impute_energy_star_df[cols_to_reduce_numerical]\\n)\\n\\n# Merge processed categorical and numerical together\\ntrain_impute_energy_star_merged_df = train_impute_energy_star_processed_categorical_df.merge(\\n   scaled_train_impute_energy_star_df, left_index=True, right_index=True,\\n   how=\\\"left\\\" \\n)\\n\\ntest_impute_energy_star_merged_df = test_impute_energy_star_processed_categorical_df.merge(\\n   scaled_test_impute_energy_star_df, left_index=True, right_index=True,\\n   how=\\\"left\\\" \\n)\";\n",
       "                var nbb_formatted_code = \"train_impute_energy_star_df = train_w_categorized_max_wind_speed_df.copy()\\ntest_impute_energy_star_df = test_w_categorized_max_wind_speed_df.copy()\\n\\n# Run a PCA for missing value imputation in energy star rating\\ncols_to_reduce_numerical = gv.below_temp_col_list\\ncols_to_reduce_categorical = [\\n    \\\"state_factor\\\",\\n    \\\"building_class\\\",\\n    #                               \\\"facility_type_parsed\\\"\\n]\\n\\n# Need a one-hot-encoding\\ntrain_impute_energy_star_dfs_list = []\\ntest_impute_energy_star_dfs_list = []\\nfor a_categorical_col in cols_to_reduce_categorical:\\n    onehot_encoder = OneHotEncoder().fit(\\n        train_impute_energy_star_df[[a_categorical_col]]\\n    )\\n    train_impute_energy_star_transformed_array = onehot_encoder.transform(\\n        train_impute_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n    test_impute_energy_star_transformed_array = onehot_encoder.transform(\\n        test_impute_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n\\n    train_impute_energy_star_transformed_df = pd.DataFrame(\\n        train_impute_energy_star_transformed_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(train_impute_energy_star_transformed_array.shape[1])\\n        ],\\n    )\\n    test_impute_energy_star_transformed_df = pd.DataFrame(\\n        test_impute_energy_star_transformed_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(test_impute_energy_star_transformed_array.shape[1])\\n        ],\\n    )\\n\\n    train_impute_energy_star_dfs_list.append(train_impute_energy_star_transformed_df)\\n    test_impute_energy_star_dfs_list.append(test_impute_energy_star_transformed_df)\\n\\n# Merge processed categorical data into one based on index\\ntrain_impute_energy_star_processed_categorical_df = pd.concat(\\n    train_impute_energy_star_dfs_list, axis=1\\n)\\ntest_impute_energy_star_processed_categorical_df = pd.concat(\\n    test_impute_energy_star_dfs_list, axis=1\\n)\\n\\nscaled_train_impute_energy_star_df, scaled_test_impute_energy_star_df = mu.scale_data(\\n    train_impute_energy_star_df[cols_to_reduce_numerical],\\n    test_impute_energy_star_df[cols_to_reduce_numerical],\\n)\\n\\n# Merge processed categorical and numerical together\\ntrain_impute_energy_star_merged_df = (\\n    train_impute_energy_star_processed_categorical_df.merge(\\n        scaled_train_impute_energy_star_df,\\n        left_index=True,\\n        right_index=True,\\n        how=\\\"left\\\",\\n    )\\n)\\n\\ntest_impute_energy_star_merged_df = (\\n    test_impute_energy_star_processed_categorical_df.merge(\\n        scaled_test_impute_energy_star_df, left_index=True, right_index=True, how=\\\"left\\\"\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_impute_energy_star_df = train_w_categorized_max_wind_speed_df.copy()\n",
    "test_impute_energy_star_df = test_w_categorized_max_wind_speed_df.copy()\n",
    "\n",
    "# Run a PCA for missing value imputation in energy star rating\n",
    "cols_to_reduce_numerical = gv.below_temp_col_list \n",
    "cols_to_reduce_categorical = [\"state_factor\", \n",
    "                              \"building_class\", \n",
    "#                               \"facility_type_parsed\"\n",
    "                             ]\n",
    "\n",
    "# Need a one-hot-encoding\n",
    "train_impute_energy_star_dfs_list = []\n",
    "test_impute_energy_star_dfs_list = []\n",
    "for a_categorical_col in cols_to_reduce_categorical:\n",
    "    onehot_encoder = OneHotEncoder().fit(\n",
    "      train_impute_energy_star_df[[a_categorical_col]])\n",
    "    train_impute_energy_star_transformed_array = onehot_encoder.transform(\n",
    "      train_impute_energy_star_df[[a_categorical_col]]).toarray()\n",
    "    test_impute_energy_star_transformed_array = onehot_encoder.transform(\n",
    "      test_impute_energy_star_df[[a_categorical_col]]).toarray()\n",
    "    \n",
    "    train_impute_energy_star_transformed_df = pd.DataFrame(\n",
    "      train_impute_energy_star_transformed_array, \n",
    "      columns=[f\"{a_categorical_col}_{i}\" for i in \n",
    "               range(train_impute_energy_star_transformed_array.shape[1])])\n",
    "    test_impute_energy_star_transformed_df = pd.DataFrame(\n",
    "      test_impute_energy_star_transformed_array, \n",
    "      columns=[f\"{a_categorical_col}_{i}\" for i in \n",
    "               range(test_impute_energy_star_transformed_array.shape[1])])\n",
    "    \n",
    "    train_impute_energy_star_dfs_list.append(train_impute_energy_star_transformed_df)\n",
    "    test_impute_energy_star_dfs_list.append(test_impute_energy_star_transformed_df)\n",
    "\n",
    "# Merge processed categorical data into one based on index\n",
    "train_impute_energy_star_processed_categorical_df = pd.concat(\n",
    "    train_impute_energy_star_dfs_list, axis=1\n",
    ")\n",
    "test_impute_energy_star_processed_categorical_df = pd.concat(\n",
    "    test_impute_energy_star_dfs_list, axis=1\n",
    ")\n",
    "\n",
    "scaled_train_impute_energy_star_df, scaled_test_impute_energy_star_df = mu.scale_data(\n",
    "    train_impute_energy_star_df[cols_to_reduce_numerical], \n",
    "    test_impute_energy_star_df[cols_to_reduce_numerical]\n",
    ")\n",
    "\n",
    "# Merge processed categorical and numerical together\n",
    "train_impute_energy_star_merged_df = train_impute_energy_star_processed_categorical_df.merge(\n",
    "   scaled_train_impute_energy_star_df, left_index=True, right_index=True,\n",
    "   how=\"left\" \n",
    ")\n",
    "\n",
    "test_impute_energy_star_merged_df = test_impute_energy_star_processed_categorical_df.merge(\n",
    "   scaled_test_impute_energy_star_df, left_index=True, right_index=True,\n",
    "   how=\"left\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BlMFI8E6U1RP",
    "outputId": "701c328e-d853-4117-d3b6-8b109871bc80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75757, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"train_impute_energy_star_merged_df.shape\";\n",
       "                var nbb_formatted_code = \"train_impute_energy_star_merged_df.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_impute_energy_star_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "l1zpqQ8vUzBu",
    "outputId": "f3fd69aa-501f-47f2-cba2-0155aafdc777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 1 components\n",
      "0.3831097325643073\n",
      "Fitting PCA with 2 components\n",
      "0.6375057286105854\n",
      "Fitting PCA with 3 components\n",
      "0.7684665901735714\n",
      "Fitting PCA with 4 components\n",
      "0.8570619943039971\n",
      "Fitting PCA with 5 components\n",
      "0.9076500901901875\n",
      "Fitting PCA with 6 components\n",
      "0.9350675016547947\n",
      "Fitting PCA with 7 components\n",
      "0.9601623010186375\n",
      "Fitting PCA with 8 components\n",
      "0.9747696718275874\n",
      "Fitting PCA with 9 components\n",
      "0.981816451573034\n",
      "Fitting PCA with 10 components\n",
      "0.9884331782128024\n",
      "Fitting PCA with 11 components\n",
      "0.9943453683025675\n",
      "Fitting PCA with 12 components\n",
      "0.9971711536739006\n",
      "Fitting PCA with 13 components\n",
      "0.9994555076158925\n",
      "Fitting PCA with 14 components\n",
      "0.9999744472929745\n",
      "Fitting PCA with 15 components\n",
      "1.0000000000000002\n",
      "Fitting PCA with 16 components\n",
      "1.0000000000000002\n",
      "Fitting PCA with 17 components\n",
      "1.0000000000000002\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Find the optimal PCA for energy star imputation\\n# 11 can already explain 99.4% varience\\nfor n_component in range(1, train_impute_energy_star_merged_df.shape[1] + 1):\\n    pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=n_component)\\n    scaled_train_impute_energy_star_w_pca = pca.transform(\\n        train_impute_energy_star_merged_df\\n    )\\n    scaled_test_impute_energy_star_w_pca = pca.transform(\\n        test_impute_energy_star_merged_df\\n    )\\n    print(sum(pca.explained_variance_ratio_))\";\n",
       "                var nbb_formatted_code = \"# Find the optimal PCA for energy star imputation\\n# 11 can already explain 99.4% varience\\nfor n_component in range(1, train_impute_energy_star_merged_df.shape[1] + 1):\\n    pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=n_component)\\n    scaled_train_impute_energy_star_w_pca = pca.transform(\\n        train_impute_energy_star_merged_df\\n    )\\n    scaled_test_impute_energy_star_w_pca = pca.transform(\\n        test_impute_energy_star_merged_df\\n    )\\n    print(sum(pca.explained_variance_ratio_))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the optimal PCA for energy star imputation\n",
    "# 11 can already explain 99.4% varience\n",
    "for n_component in range(1, train_impute_energy_star_merged_df.shape[1] + 1):\n",
    "    pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=n_component)\n",
    "    scaled_train_impute_energy_star_w_pca = pca.transform(\n",
    "        train_impute_energy_star_merged_df\n",
    "    )\n",
    "    scaled_test_impute_energy_star_w_pca = pca.transform(\n",
    "        test_impute_energy_star_merged_df\n",
    "    )\n",
    "    print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "Uz34jCvmWNtW",
    "outputId": "77db4333-310f-49f0-8dad-48315537622f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 11 components\n",
      "0.9943453683025586\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"opt_n_compoent = 11\\npca = du.pca_fit(train_impute_energy_star_merged_df, n_components=opt_n_compoent)\\nscaled_train_impute_energy_star_w_pca_optimal = pca.transform(\\n    train_impute_energy_star_merged_df\\n)\\nscaled_test_impute_energy_star_w_pca_optimal = pca.transform(\\n    test_impute_energy_star_merged_df\\n)\\nprint(sum(pca.explained_variance_ratio_))\";\n",
       "                var nbb_formatted_code = \"opt_n_compoent = 11\\npca = du.pca_fit(train_impute_energy_star_merged_df, n_components=opt_n_compoent)\\nscaled_train_impute_energy_star_w_pca_optimal = pca.transform(\\n    train_impute_energy_star_merged_df\\n)\\nscaled_test_impute_energy_star_w_pca_optimal = pca.transform(\\n    test_impute_energy_star_merged_df\\n)\\nprint(sum(pca.explained_variance_ratio_))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_n_compoent = 11\n",
    "pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=opt_n_compoent)\n",
    "scaled_train_impute_energy_star_w_pca_optimal = pca.transform(\n",
    "    train_impute_energy_star_merged_df\n",
    ")\n",
    "scaled_test_impute_energy_star_w_pca_optimal = pca.transform(\n",
    "    test_impute_energy_star_merged_df\n",
    ")\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hYk0Xp5VW-mm",
    "outputId": "f055ca9a-a4d2-47b6-c0c8-4de25ef5ad45"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"scaled_train_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_train_impute_energy_star_w_pca_optimal,\\n    columns=[\\n        f\\\"pca_{i}\\\"\\n        for i in range(scaled_train_impute_energy_star_w_pca_optimal.shape[1])\\n    ],\\n)\\n\\nscaled_test_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_test_impute_energy_star_w_pca_optimal,\\n    columns=[\\n        f\\\"pca_{i}\\\" for i in range(scaled_test_impute_energy_star_w_pca_optimal.shape[1])\\n    ],\\n)\\n\\n# Add back original energy star rating\\nscaled_train_w_original_energy_star_df = (\\n    scaled_train_impute_energy_star_w_pca_optimal_df.merge(\\n        train_impute_energy_star_df[\\\"energy_star_rating\\\"],\\n        how=\\\"left\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n)\\nscaled_test_w_original_energy_star_df = (\\n    scaled_test_impute_energy_star_w_pca_optimal_df.merge(\\n        test_impute_energy_star_df[\\\"energy_star_rating\\\"],\\n        how=\\\"left\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"scaled_train_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_train_impute_energy_star_w_pca_optimal,\\n    columns=[\\n        f\\\"pca_{i}\\\"\\n        for i in range(scaled_train_impute_energy_star_w_pca_optimal.shape[1])\\n    ],\\n)\\n\\nscaled_test_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_test_impute_energy_star_w_pca_optimal,\\n    columns=[\\n        f\\\"pca_{i}\\\" for i in range(scaled_test_impute_energy_star_w_pca_optimal.shape[1])\\n    ],\\n)\\n\\n# Add back original energy star rating\\nscaled_train_w_original_energy_star_df = (\\n    scaled_train_impute_energy_star_w_pca_optimal_df.merge(\\n        train_impute_energy_star_df[\\\"energy_star_rating\\\"],\\n        how=\\\"left\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n)\\nscaled_test_w_original_energy_star_df = (\\n    scaled_test_impute_energy_star_w_pca_optimal_df.merge(\\n        test_impute_energy_star_df[\\\"energy_star_rating\\\"],\\n        how=\\\"left\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_train_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\n",
    "    scaled_train_impute_energy_star_w_pca_optimal,\n",
    "    columns=[\n",
    "        f\"pca_{i}\"\n",
    "        for i in range(scaled_train_impute_energy_star_w_pca_optimal.shape[1])\n",
    "    ],\n",
    ")\n",
    "\n",
    "scaled_test_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\n",
    "    scaled_test_impute_energy_star_w_pca_optimal,\n",
    "    columns=[\n",
    "        f\"pca_{i}\" for i in range(scaled_test_impute_energy_star_w_pca_optimal.shape[1])\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Add back original energy star rating\n",
    "scaled_train_w_original_energy_star_df = (\n",
    "    scaled_train_impute_energy_star_w_pca_optimal_df.merge(\n",
    "        train_impute_energy_star_df[\"energy_star_rating\"],\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    ")\n",
    "scaled_test_w_original_energy_star_df = (\n",
    "    scaled_test_impute_energy_star_w_pca_optimal_df.merge(\n",
    "        test_impute_energy_star_df[\"energy_star_rating\"],\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "KYT6mRUe-Gjj",
    "outputId": "1014dfc2-7d40-4b44-fe6c-2768d8e6e76d"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Get backfilled energy star rating using scikit-learn iterative imputer based on \\n# other features\\nRANDOM_STATE = 42\\nmax_iter = 10\\nimp = IterativeImputer(max_iter=max_iter, random_state=RANDOM_STATE)\\n# Fit the imputer on training\\nimp.fit(scaled_train_w_original_energy_star_df)\\n# Transform on train and test\\nscaled_train_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_train_w_original_energy_star_df),\\n    columns=scaled_train_w_original_energy_star_df.columns.tolist()\\n    )\\nscaled_test_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_test_w_original_energy_star_df),\\n    columns=scaled_test_w_original_energy_star_df.columns.tolist()\\n    )\";\n",
       "                var nbb_formatted_code = \"# Get backfilled energy star rating using scikit-learn iterative imputer based on\\n# other features\\nRANDOM_STATE = 42\\nmax_iter = 10\\nimp = IterativeImputer(max_iter=max_iter, random_state=RANDOM_STATE)\\n# Fit the imputer on training\\nimp.fit(scaled_train_w_original_energy_star_df)\\n# Transform on train and test\\nscaled_train_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_train_w_original_energy_star_df),\\n    columns=scaled_train_w_original_energy_star_df.columns.tolist(),\\n)\\nscaled_test_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_test_w_original_energy_star_df),\\n    columns=scaled_test_w_original_energy_star_df.columns.tolist(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get backfilled energy star rating using scikit-learn iterative imputer based on \n",
    "# other features\n",
    "RANDOM_STATE = 42\n",
    "max_iter = 10\n",
    "imp = IterativeImputer(max_iter=max_iter, random_state=RANDOM_STATE)\n",
    "# Fit the imputer on training\n",
    "imp.fit(scaled_train_w_original_energy_star_df)\n",
    "# Transform on train and test\n",
    "scaled_train_w_original_energy_star_transformed_df = pd.DataFrame(\n",
    "    imp.transform(scaled_train_w_original_energy_star_df),\n",
    "    columns=scaled_train_w_original_energy_star_df.columns.tolist()\n",
    "    )\n",
    "scaled_test_w_original_energy_star_transformed_df = pd.DataFrame(\n",
    "    imp.transform(scaled_test_w_original_energy_star_df),\n",
    "    columns=scaled_test_w_original_energy_star_df.columns.tolist()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8IEl6PPZV3u"
   },
   "source": [
    "### Add imputed energy star with other processed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "-xYOQb7QZOcl",
    "outputId": "e44909f5-9151-44ee-8cb9-5a640cc9d410"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_factor</th>\n",
       "      <th>state_factor</th>\n",
       "      <th>building_class</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>energy_star_rating</th>\n",
       "      <th>elevation</th>\n",
       "      <th>january_min_temp</th>\n",
       "      <th>january_avg_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>direction_peak_wind_speed</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>days_with_fog</th>\n",
       "      <th>site_eui</th>\n",
       "      <th>id</th>\n",
       "      <th>facility_type_parsed</th>\n",
       "      <th>direction_max_wind_speed_backfilled</th>\n",
       "      <th>backfilled_direction_max_wind_speed</th>\n",
       "      <th>categorized_direction_max_wind_speed</th>\n",
       "      <th>iter_impute_energy_star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>61242.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.682615</td>\n",
       "      <td>0</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Warehouse_Distribution_or_Shipping_center</td>\n",
       "      <td>274000.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.500150</td>\n",
       "      <td>1</td>\n",
       "      <td>Warehouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Retail_Enclosed_mall</td>\n",
       "      <td>280025.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.693619</td>\n",
       "      <td>2</td>\n",
       "      <td>Retail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Education_Other_classroom</td>\n",
       "      <td>55325.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.406926</td>\n",
       "      <td>3</td>\n",
       "      <td>Education</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Warehouse_Nonrefrigerated</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.899395</td>\n",
       "      <td>4</td>\n",
       "      <td>Warehouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_factor state_factor building_class  \\\n",
       "0            1      State_1     Commercial   \n",
       "1            1      State_1     Commercial   \n",
       "2            1      State_1     Commercial   \n",
       "3            1      State_1     Commercial   \n",
       "4            1      State_1     Commercial   \n",
       "\n",
       "                               facility_type  floor_area  year_built  \\\n",
       "0               Grocery_store_or_food_market     61242.0      1942.0   \n",
       "1  Warehouse_Distribution_or_Shipping_center    274000.0      1955.0   \n",
       "2                       Retail_Enclosed_mall    280025.0      1951.0   \n",
       "3                  Education_Other_classroom     55325.0      1980.0   \n",
       "4                  Warehouse_Nonrefrigerated     66000.0      1985.0   \n",
       "\n",
       "   energy_star_rating  elevation  january_min_temp  january_avg_temp  ...  \\\n",
       "0                11.0        2.4                36              50.5  ...   \n",
       "1                45.0        1.8                36              50.5  ...   \n",
       "2                97.0        1.8                36              50.5  ...   \n",
       "3                46.0        1.8                36              50.5  ...   \n",
       "4               100.0        2.4                36              50.5  ...   \n",
       "\n",
       "   direction_peak_wind_speed  max_wind_speed  days_with_fog    site_eui  id  \\\n",
       "0                        1.0             1.0            NaN  248.682615   0   \n",
       "1                        NaN             1.0           12.0   26.500150   1   \n",
       "2                        NaN             1.0           12.0   24.693619   2   \n",
       "3                        NaN             1.0           12.0   48.406926   3   \n",
       "4                        1.0             1.0            NaN    3.899395   4   \n",
       "\n",
       "   facility_type_parsed  direction_max_wind_speed_backfilled  \\\n",
       "0               Grocery                                  1.0   \n",
       "1             Warehouse                                  1.0   \n",
       "2                Retail                                  1.0   \n",
       "3             Education                                  1.0   \n",
       "4             Warehouse                                  1.0   \n",
       "\n",
       "   backfilled_direction_max_wind_speed  categorized_direction_max_wind_speed  \\\n",
       "0                                  1.0                                     N   \n",
       "1                                  1.0                                     N   \n",
       "2                                  1.0                                     N   \n",
       "3                                  1.0                                     N   \n",
       "4                                  1.0                                     N   \n",
       "\n",
       "   iter_impute_energy_star_rating  \n",
       "0                            11.0  \n",
       "1                            45.0  \n",
       "2                            97.0  \n",
       "3                            46.0  \n",
       "4                           100.0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"train_processed_energy_star_df = train_w_categorized_max_wind_speed_df.merge(\\n    scaled_train_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntest_processed_energy_star_df = test_w_categorized_max_wind_speed_df.merge(\\n    scaled_test_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntrain_processed_energy_star_df.head()\";\n",
       "                var nbb_formatted_code = \"train_processed_energy_star_df = train_w_categorized_max_wind_speed_df.merge(\\n    scaled_train_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntest_processed_energy_star_df = test_w_categorized_max_wind_speed_df.merge(\\n    scaled_test_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntrain_processed_energy_star_df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_processed_energy_star_df = train_w_categorized_max_wind_speed_df.merge(\n",
    "    scaled_train_w_original_energy_star_transformed_df[[\"energy_star_rating\"]].rename(\n",
    "        columns={\"energy_star_rating\": \"iter_impute_energy_star_rating\"}\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "test_processed_energy_star_df = test_w_categorized_max_wind_speed_df.merge(\n",
    "    scaled_test_w_original_energy_star_transformed_df[[\"energy_star_rating\"]].rename(\n",
    "        columns={\"energy_star_rating\": \"iter_impute_energy_star_rating\"}\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "train_processed_energy_star_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new labels on facility - energy star information\n",
    "\n",
    "Relabel using Kmeans, and use floor_area, elevation, facility_type_parsed, energy star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 5 clusters\n",
      "Clustering 10 clusters\n",
      "Clustering 15 clusters\n",
      "Clustering 20 clusters\n",
      "Clustering 25 clusters\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"n_clusters_list = [5, 10, 15, 20, 25]\\nnumerical_columns_contribute_to_facility_type = [\\n    \\\"floor_area\\\",\\n    \\\"elevation\\\",\\n    \\\"iter_impute_energy_star_rating\\\",\\n]\\ncategorical_columns_contribute_to_facility_type = [\\\"facility_type_parsed\\\"]\\n\\n\\n# Need a one-hot-encoding on categorical columns\\ntrain_cluster_facility_type_dfs_list = []\\ntest_cluster_facility_type_dfs_list = []\\n\\nfor a_categorical_col in categorical_columns_contribute_to_facility_type:\\n    onehot_encoder = OneHotEncoder().fit(\\n        train_processed_energy_star_df[[a_categorical_col]]\\n    )\\n\\n    train_cluster_facility_type_array = onehot_encoder.transform(\\n        train_processed_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n\\n    test_cluster_facility_type_array = onehot_encoder.transform(\\n        test_processed_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n\\n    train_cluster_facility_type_transformed_df = pd.DataFrame(\\n        train_cluster_facility_type_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(train_cluster_facility_type_array.shape[1])\\n        ],\\n    )\\n    test_cluster_facility_type_transformed_df = pd.DataFrame(\\n        test_cluster_facility_type_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(test_cluster_facility_type_array.shape[1])\\n        ],\\n    )\\n\\n    train_cluster_facility_type_dfs_list.append(\\n        train_cluster_facility_type_transformed_df\\n    )\\n    test_cluster_facility_type_dfs_list.append(\\n        test_cluster_facility_type_transformed_df\\n    )\\n\\n# Merge processed categorical data into one based on index\\ntrain_cluster_facility_type_processed_categorical_df = pd.concat(\\n    train_cluster_facility_type_dfs_list, axis=1\\n)\\ntest_cluster_facility_type_processed_categorical_df = pd.concat(\\n    test_cluster_facility_type_dfs_list, axis=1\\n)\\n\\n# Merge processed categorical data with numerical ones\\ntrain_for_clustering_df = train_processed_energy_star_df[\\n    numerical_columns_contribute_to_facility_type\\n].merge(\\n    train_cluster_facility_type_processed_categorical_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntest_for_clustering_df = test_processed_energy_star_df[\\n    numerical_columns_contribute_to_facility_type\\n].merge(\\n    test_cluster_facility_type_processed_categorical_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\n\\n# Train the KNN model for clustering\\ntrain_for_relabeled_facility_dfs_list = []\\ntest_for_relabeled_facility_dfs_list = []\\nfor n_cluster in n_clusters_list:\\n    print(f\\\"Clustering {n_cluster} clusters\\\")\\n    kmeans = KMeans(n_clusters=n_cluster, random_state=RANDOM_STATE).fit(\\n        train_for_clustering_df\\n    )\\n\\n    train_for_relabled_facility_type_df = pd.DataFrame(\\n        kmeans.predict(train_for_clustering_df),\\n        columns=[f\\\"relabled_facility_type_{n_cluster}_clusters\\\"],\\n        index=train_processed_energy_star_df.index,\\n    )\\n    test_for_relabled_facility_type_df = pd.DataFrame(\\n        kmeans.predict(test_for_clustering_df),\\n        columns=[f\\\"relabled_facility_type_{n_cluster}_clusters\\\"],\\n        index=test_processed_energy_star_df.index,\\n    )\\n\\n    train_for_relabeled_facility_dfs_list.append(train_for_relabled_facility_type_df)\\n    test_for_relabeled_facility_dfs_list.append(test_for_relabled_facility_type_df)\\n\\ntrain_for_relabled_facility_type_multi_clustering_df = pd.concat(\\n    train_for_relabeled_facility_dfs_list, axis=1\\n)\\n\\ntest_for_relabled_facility_type_multi_clustering_df = pd.concat(\\n    test_for_relabeled_facility_dfs_list, axis=1\\n)\\n\\n# Cluster should be treated as categorical features\\ntrain_for_relabled_facility_type_multi_clustering_df = (\\n    train_for_relabled_facility_type_multi_clustering_df.astype(str)\\n)\\ntest_for_relabled_facility_type_multi_clustering_df = (\\n    test_for_relabled_facility_type_multi_clustering_df.astype(str)\\n)\";\n",
       "                var nbb_formatted_code = \"n_clusters_list = [5, 10, 15, 20, 25]\\nnumerical_columns_contribute_to_facility_type = [\\n    \\\"floor_area\\\",\\n    \\\"elevation\\\",\\n    \\\"iter_impute_energy_star_rating\\\",\\n]\\ncategorical_columns_contribute_to_facility_type = [\\\"facility_type_parsed\\\"]\\n\\n\\n# Need a one-hot-encoding on categorical columns\\ntrain_cluster_facility_type_dfs_list = []\\ntest_cluster_facility_type_dfs_list = []\\n\\nfor a_categorical_col in categorical_columns_contribute_to_facility_type:\\n    onehot_encoder = OneHotEncoder().fit(\\n        train_processed_energy_star_df[[a_categorical_col]]\\n    )\\n\\n    train_cluster_facility_type_array = onehot_encoder.transform(\\n        train_processed_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n\\n    test_cluster_facility_type_array = onehot_encoder.transform(\\n        test_processed_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n\\n    train_cluster_facility_type_transformed_df = pd.DataFrame(\\n        train_cluster_facility_type_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(train_cluster_facility_type_array.shape[1])\\n        ],\\n    )\\n    test_cluster_facility_type_transformed_df = pd.DataFrame(\\n        test_cluster_facility_type_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(test_cluster_facility_type_array.shape[1])\\n        ],\\n    )\\n\\n    train_cluster_facility_type_dfs_list.append(\\n        train_cluster_facility_type_transformed_df\\n    )\\n    test_cluster_facility_type_dfs_list.append(\\n        test_cluster_facility_type_transformed_df\\n    )\\n\\n# Merge processed categorical data into one based on index\\ntrain_cluster_facility_type_processed_categorical_df = pd.concat(\\n    train_cluster_facility_type_dfs_list, axis=1\\n)\\ntest_cluster_facility_type_processed_categorical_df = pd.concat(\\n    test_cluster_facility_type_dfs_list, axis=1\\n)\\n\\n# Merge processed categorical data with numerical ones\\ntrain_for_clustering_df = train_processed_energy_star_df[\\n    numerical_columns_contribute_to_facility_type\\n].merge(\\n    train_cluster_facility_type_processed_categorical_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntest_for_clustering_df = test_processed_energy_star_df[\\n    numerical_columns_contribute_to_facility_type\\n].merge(\\n    test_cluster_facility_type_processed_categorical_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\n\\n# Train the KNN model for clustering\\ntrain_for_relabeled_facility_dfs_list = []\\ntest_for_relabeled_facility_dfs_list = []\\nfor n_cluster in n_clusters_list:\\n    print(f\\\"Clustering {n_cluster} clusters\\\")\\n    kmeans = KMeans(n_clusters=n_cluster, random_state=RANDOM_STATE).fit(\\n        train_for_clustering_df\\n    )\\n\\n    train_for_relabled_facility_type_df = pd.DataFrame(\\n        kmeans.predict(train_for_clustering_df),\\n        columns=[f\\\"relabled_facility_type_{n_cluster}_clusters\\\"],\\n        index=train_processed_energy_star_df.index,\\n    )\\n    test_for_relabled_facility_type_df = pd.DataFrame(\\n        kmeans.predict(test_for_clustering_df),\\n        columns=[f\\\"relabled_facility_type_{n_cluster}_clusters\\\"],\\n        index=test_processed_energy_star_df.index,\\n    )\\n\\n    train_for_relabeled_facility_dfs_list.append(train_for_relabled_facility_type_df)\\n    test_for_relabeled_facility_dfs_list.append(test_for_relabled_facility_type_df)\\n\\ntrain_for_relabled_facility_type_multi_clustering_df = pd.concat(\\n    train_for_relabeled_facility_dfs_list, axis=1\\n)\\n\\ntest_for_relabled_facility_type_multi_clustering_df = pd.concat(\\n    test_for_relabeled_facility_dfs_list, axis=1\\n)\\n\\n# Cluster should be treated as categorical features\\ntrain_for_relabled_facility_type_multi_clustering_df = (\\n    train_for_relabled_facility_type_multi_clustering_df.astype(str)\\n)\\ntest_for_relabled_facility_type_multi_clustering_df = (\\n    test_for_relabled_facility_type_multi_clustering_df.astype(str)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_clusters_list = [5, 10, 15, 20, 25]\n",
    "numerical_columns_contribute_to_facility_type = [\n",
    "    \"floor_area\",\n",
    "    \"elevation\",\n",
    "    \"iter_impute_energy_star_rating\",\n",
    "]\n",
    "categorical_columns_contribute_to_facility_type = [\"facility_type_parsed\"]\n",
    "\n",
    "\n",
    "# Need a one-hot-encoding on categorical columns\n",
    "train_cluster_facility_type_dfs_list = []\n",
    "test_cluster_facility_type_dfs_list = []\n",
    "\n",
    "for a_categorical_col in categorical_columns_contribute_to_facility_type:\n",
    "    onehot_encoder = OneHotEncoder().fit(\n",
    "        train_processed_energy_star_df[[a_categorical_col]]\n",
    "    )\n",
    "\n",
    "    train_cluster_facility_type_array = onehot_encoder.transform(\n",
    "        train_processed_energy_star_df[[a_categorical_col]]\n",
    "    ).toarray()\n",
    "\n",
    "    test_cluster_facility_type_array = onehot_encoder.transform(\n",
    "        test_processed_energy_star_df[[a_categorical_col]]\n",
    "    ).toarray()\n",
    "\n",
    "    train_cluster_facility_type_transformed_df = pd.DataFrame(\n",
    "        train_cluster_facility_type_array,\n",
    "        columns=[\n",
    "            f\"{a_categorical_col}_{i}\"\n",
    "            for i in range(train_cluster_facility_type_array.shape[1])\n",
    "        ],\n",
    "    )\n",
    "    test_cluster_facility_type_transformed_df = pd.DataFrame(\n",
    "        test_cluster_facility_type_array,\n",
    "        columns=[\n",
    "            f\"{a_categorical_col}_{i}\"\n",
    "            for i in range(test_cluster_facility_type_array.shape[1])\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    train_cluster_facility_type_dfs_list.append(\n",
    "        train_cluster_facility_type_transformed_df\n",
    "    )\n",
    "    test_cluster_facility_type_dfs_list.append(\n",
    "        test_cluster_facility_type_transformed_df\n",
    "    )\n",
    "\n",
    "# Merge processed categorical data into one based on index\n",
    "train_cluster_facility_type_processed_categorical_df = pd.concat(\n",
    "    train_cluster_facility_type_dfs_list, axis=1\n",
    ")\n",
    "test_cluster_facility_type_processed_categorical_df = pd.concat(\n",
    "    test_cluster_facility_type_dfs_list, axis=1\n",
    ")\n",
    "\n",
    "# Merge processed categorical data with numerical ones\n",
    "train_for_clustering_df = train_processed_energy_star_df[\n",
    "    numerical_columns_contribute_to_facility_type\n",
    "].merge(\n",
    "    train_cluster_facility_type_processed_categorical_df,\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "test_for_clustering_df = test_processed_energy_star_df[\n",
    "    numerical_columns_contribute_to_facility_type\n",
    "].merge(\n",
    "    test_cluster_facility_type_processed_categorical_df,\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "# Train the KNN model for clustering\n",
    "train_for_relabeled_facility_dfs_list = []\n",
    "test_for_relabeled_facility_dfs_list = []\n",
    "for n_cluster in n_clusters_list:\n",
    "    print(f\"Clustering {n_cluster} clusters\")\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=RANDOM_STATE).fit(\n",
    "        train_for_clustering_df\n",
    "    )\n",
    "\n",
    "    train_for_relabled_facility_type_df = pd.DataFrame(\n",
    "        kmeans.predict(train_for_clustering_df),\n",
    "        columns=[f\"relabled_facility_type_{n_cluster}_clusters\"],\n",
    "        index=train_processed_energy_star_df.index,\n",
    "    )\n",
    "    test_for_relabled_facility_type_df = pd.DataFrame(\n",
    "        kmeans.predict(test_for_clustering_df),\n",
    "        columns=[f\"relabled_facility_type_{n_cluster}_clusters\"],\n",
    "        index=test_processed_energy_star_df.index,\n",
    "    )\n",
    "\n",
    "    train_for_relabeled_facility_dfs_list.append(train_for_relabled_facility_type_df)\n",
    "    test_for_relabeled_facility_dfs_list.append(test_for_relabled_facility_type_df)\n",
    "\n",
    "train_for_relabled_facility_type_multi_clustering_df = pd.concat(\n",
    "    train_for_relabeled_facility_dfs_list, axis=1\n",
    ")\n",
    "\n",
    "test_for_relabled_facility_type_multi_clustering_df = pd.concat(\n",
    "    test_for_relabeled_facility_dfs_list, axis=1\n",
    ")\n",
    "\n",
    "# Cluster should be treated as categorical features\n",
    "train_for_relabled_facility_type_multi_clustering_df = (\n",
    "    train_for_relabled_facility_type_multi_clustering_df.astype(str)\n",
    ")\n",
    "test_for_relabled_facility_type_multi_clustering_df = (\n",
    "    test_for_relabled_facility_type_multi_clustering_df.astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_factor</th>\n",
       "      <th>state_factor</th>\n",
       "      <th>building_class</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>energy_star_rating</th>\n",
       "      <th>elevation</th>\n",
       "      <th>january_min_temp</th>\n",
       "      <th>january_avg_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>facility_type_parsed</th>\n",
       "      <th>direction_max_wind_speed_backfilled</th>\n",
       "      <th>backfilled_direction_max_wind_speed</th>\n",
       "      <th>categorized_direction_max_wind_speed</th>\n",
       "      <th>iter_impute_energy_star_rating</th>\n",
       "      <th>relabled_facility_type_5_clusters</th>\n",
       "      <th>relabled_facility_type_10_clusters</th>\n",
       "      <th>relabled_facility_type_15_clusters</th>\n",
       "      <th>relabled_facility_type_20_clusters</th>\n",
       "      <th>relabled_facility_type_25_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>61242.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Warehouse_Distribution_or_Shipping_center</td>\n",
       "      <td>274000.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Warehouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Retail_Enclosed_mall</td>\n",
       "      <td>280025.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Retail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Education_Other_classroom</td>\n",
       "      <td>55325.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Education</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Warehouse_Nonrefrigerated</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Warehouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_factor state_factor building_class  \\\n",
       "0            1      State_1     Commercial   \n",
       "1            1      State_1     Commercial   \n",
       "2            1      State_1     Commercial   \n",
       "3            1      State_1     Commercial   \n",
       "4            1      State_1     Commercial   \n",
       "\n",
       "                               facility_type  floor_area  year_built  \\\n",
       "0               Grocery_store_or_food_market     61242.0      1942.0   \n",
       "1  Warehouse_Distribution_or_Shipping_center    274000.0      1955.0   \n",
       "2                       Retail_Enclosed_mall    280025.0      1951.0   \n",
       "3                  Education_Other_classroom     55325.0      1980.0   \n",
       "4                  Warehouse_Nonrefrigerated     66000.0      1985.0   \n",
       "\n",
       "   energy_star_rating  elevation  january_min_temp  january_avg_temp  ...  \\\n",
       "0                11.0        2.4                36              50.5  ...   \n",
       "1                45.0        1.8                36              50.5  ...   \n",
       "2                97.0        1.8                36              50.5  ...   \n",
       "3                46.0        1.8                36              50.5  ...   \n",
       "4               100.0        2.4                36              50.5  ...   \n",
       "\n",
       "   facility_type_parsed  direction_max_wind_speed_backfilled  \\\n",
       "0               Grocery                                  1.0   \n",
       "1             Warehouse                                  1.0   \n",
       "2                Retail                                  1.0   \n",
       "3             Education                                  1.0   \n",
       "4             Warehouse                                  1.0   \n",
       "\n",
       "   backfilled_direction_max_wind_speed  categorized_direction_max_wind_speed  \\\n",
       "0                                  1.0                                     N   \n",
       "1                                  1.0                                     N   \n",
       "2                                  1.0                                     N   \n",
       "3                                  1.0                                     N   \n",
       "4                                  1.0                                     N   \n",
       "\n",
       "   iter_impute_energy_star_rating  relabled_facility_type_5_clusters  \\\n",
       "0                            11.0                                  1   \n",
       "1                            45.0                                  0   \n",
       "2                            97.0                                  0   \n",
       "3                            46.0                                  1   \n",
       "4                           100.0                                  1   \n",
       "\n",
       "   relabled_facility_type_10_clusters  relabled_facility_type_15_clusters  \\\n",
       "0                                   0                                   1   \n",
       "1                                   3                                   8   \n",
       "2                                   3                                   8   \n",
       "3                                   0                                   1   \n",
       "4                                   0                                   1   \n",
       "\n",
       "   relabled_facility_type_20_clusters  relabled_facility_type_25_clusters  \n",
       "0                                   0                                   0  \n",
       "1                                  12                                   3  \n",
       "2                                  12                                   3  \n",
       "3                                   0                                   0  \n",
       "4                                   0                                   0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Add relabeld facility type with master dataset\\ntrain_processed_df = train_processed_energy_star_df.merge(\\n    train_for_relabled_facility_type_multi_clustering_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntest_processed_df = test_processed_energy_star_df.merge(\\n    test_for_relabled_facility_type_multi_clustering_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\n\\ntrain_processed_df.head()\";\n",
       "                var nbb_formatted_code = \"# Add relabeld facility type with master dataset\\ntrain_processed_df = train_processed_energy_star_df.merge(\\n    train_for_relabled_facility_type_multi_clustering_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntest_processed_df = test_processed_energy_star_df.merge(\\n    test_for_relabled_facility_type_multi_clustering_df,\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\n\\ntrain_processed_df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add relabeld facility type with master dataset\n",
    "train_processed_df = train_processed_energy_star_df.merge(\n",
    "    train_for_relabled_facility_type_multi_clustering_df,\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "test_processed_df = test_processed_energy_star_df.merge(\n",
    "    test_for_relabled_facility_type_multi_clustering_df,\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "train_processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 75757 entries, 0 to 75756\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   relabled_facility_type_5_clusters   75757 non-null  object\n",
      " 1   relabled_facility_type_10_clusters  75757 non-null  object\n",
      " 2   relabled_facility_type_15_clusters  75757 non-null  object\n",
      " 3   relabled_facility_type_20_clusters  75757 non-null  object\n",
      " 4   relabled_facility_type_25_clusters  75757 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 6.0+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"train_processed_df.filter(like=\\\"cluster\\\").info()\";\n",
       "                var nbb_formatted_code = \"train_processed_df.filter(like=\\\"cluster\\\").info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_processed_df.filter(like=\"cluster\").info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"train_filled_df = train_processed_df.copy()\\ntest_filled_df = test_processed_df.copy()\";\n",
       "                var nbb_formatted_code = \"train_filled_df = train_processed_df.copy()\\ntest_filled_df = test_processed_df.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_filled_df = train_processed_df.copy()\n",
    "test_filled_df = test_processed_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "h1yW31p0ZOr6",
    "outputId": "947fb976-c892-45c4-9cfa-188f07970e7d"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"seed = 0\\ndepth = 12\\n\\nmodel_dict = {\\n    \\\"catboost\\\": cb.CatBoostRegressor(\\n        loss_function=\\\"RMSE\\\",\\n        depth=depth,\\n        random_seed=seed,\\n        verbose=False,\\n        nan_mode=\\\"Min\\\",\\n    ),\\n    \\\"xgboost\\\": xgb.XGBRegressor(\\n        eval_metric=\\\"rmse\\\",\\n        seed=seed,\\n        max_depth=3,\\n        n_estimators=100,\\n        booster=\\\"gbtree\\\",\\n        n_jobs=-1,\\n        random_state=0,\\n        learning_rate=0.1,\\n    ),\\n        \\\"lightgbm\\\": lgb.LGBMRegressor (\\n                                n_estimators = 30000,\\n                                max_depth = 11,\\n                                num_leaves = 15,\\n                                learning_rate = 0.05,\\n                                subsample = 0.9,\\n                                colsample_bytree = 0.7,\\n                                random_state = 42 )\\n    \\n}\\n\\nmodel_type_dict = {\\\"catboost\\\": \\\"catboost\\\", \\\"xgboost\\\": \\\"sklearn\\\", \\\"lightgbm\\\": \\\"lightgbm\\\"}\\n\\nfeature_dict = {\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v1\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"facility_type_parsed\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v2\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"facility_type_parsed\\\",\\n            # \\\"direction_max_wind_speed\\\": \\\"categorized_direction_max_wind_speed\\\"\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\":(\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist() + \\n            train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v3\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_5_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\":(\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist() + \\n            train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v4\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_10_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\":(\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist() + \\n            train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v5\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_15_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\":(\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist() + \\n            train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v6\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_20_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\":(\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist() + \\n            train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v7\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_25_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\":(\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist() + \\n            train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\n    # Starting to use Hannah's updated random upsampling code \\n    # beyond v8 - v12 to use random upsampling, with out dropping data columns\\n    # get the optimal number of facility clusters for catboost\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v8\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_25_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\":[],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v9\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_20_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v10\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_15_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v11\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_10_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v12\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_5_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\n    # beyond v12 - vxx to use random upsampling, with out dropping data columns\\n    # try optimal facility type with lightgbm\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_lightgbm_v13\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"lightgbm\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_20_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\n \\n    \\n    \\n}\\n\\nmodel_configs_to_run = [\\n#     \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v2\\\",\\n#         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v3\\\",\\n#         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v4\\\",\\n#         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v5\\\",\\n#         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v6\\\",\\n#         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v7\\\",\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v8\\\",\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v9\\\",\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v10\\\",\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v11\\\",\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v12\\\",\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_lightgbm_v13\\\",\\n    \\n]\";\n",
       "                var nbb_formatted_code = \"seed = 0\\ndepth = 12\\n\\nmodel_dict = {\\n    \\\"catboost\\\": cb.CatBoostRegressor(\\n        loss_function=\\\"RMSE\\\",\\n        depth=depth,\\n        random_seed=seed,\\n        verbose=False,\\n        nan_mode=\\\"Min\\\",\\n    ),\\n    \\\"xgboost\\\": xgb.XGBRegressor(\\n        eval_metric=\\\"rmse\\\",\\n        seed=seed,\\n        max_depth=3,\\n        n_estimators=100,\\n        booster=\\\"gbtree\\\",\\n        n_jobs=-1,\\n        random_state=0,\\n        learning_rate=0.1,\\n    ),\\n    \\\"lightgbm\\\": lgb.LGBMRegressor(\\n        n_estimators=30000,\\n        max_depth=11,\\n        num_leaves=15,\\n        learning_rate=0.05,\\n        subsample=0.9,\\n        colsample_bytree=0.7,\\n        random_state=42,\\n    ),\\n}\\n\\nmodel_type_dict = {\\\"catboost\\\": \\\"catboost\\\", \\\"xgboost\\\": \\\"sklearn\\\", \\\"lightgbm\\\": \\\"lightgbm\\\"}\\n\\nfeature_dict = {\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v1\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"facility_type_parsed\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v2\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"facility_type_parsed\\\",\\n            # \\\"direction_max_wind_speed\\\": \\\"categorized_direction_max_wind_speed\\\"\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": (\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist()\\n            + train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()\\n        ),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v3\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_5_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": (\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist()\\n            + train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()\\n        ),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v4\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_10_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": (\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist()\\n            + train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()\\n        ),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v5\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_15_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": (\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist()\\n            + train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()\\n        ),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v6\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_20_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": (\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist()\\n            + train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()\\n        ),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v7\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_25_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": (\\n            train_processed_df.filter(like=\\\"days_below\\\").columns.tolist()\\n            + train_processed_df.filter(like=\\\"days_above\\\").columns.tolist()\\n        ),\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    },\\n    # Starting to use Hannah's updated random upsampling code\\n    # beyond v8 - v12 to use random upsampling, with out dropping data columns\\n    # get the optimal number of facility clusters for catboost\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v8\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_25_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v9\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_20_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v10\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_15_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v11\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_10_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v12\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_5_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n    # beyond v12 - vxx to use random upsampling, with out dropping data columns\\n    # try optimal facility type with lightgbm\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_lightgbm_v13\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"lightgbm\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"relabled_facility_type_20_clusters\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"drop_data_colums\\\": [],\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"random\\\",\\n        },\\n    },\\n}\\n\\nmodel_configs_to_run = [\\n    #     \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v2\\\",\\n    #         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v3\\\",\\n    #         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v4\\\",\\n    #         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v5\\\",\\n    #         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v6\\\",\\n    #         \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v7\\\",\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v8\\\",\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v9\\\",\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v10\\\",\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v11\\\",\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v12\\\",\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_lightgbm_v13\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 0\n",
    "depth = 12\n",
    "\n",
    "model_dict = {\n",
    "    \"catboost\": cb.CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        depth=depth,\n",
    "        random_seed=seed,\n",
    "        verbose=False,\n",
    "        nan_mode=\"Min\",\n",
    "    ),\n",
    "    \"xgboost\": xgb.XGBRegressor(\n",
    "        eval_metric=\"rmse\",\n",
    "        seed=seed,\n",
    "        max_depth=3,\n",
    "        n_estimators=100,\n",
    "        booster=\"gbtree\",\n",
    "        n_jobs=-1,\n",
    "        random_state=0,\n",
    "        learning_rate=0.1,\n",
    "    ),\n",
    "        \"lightgbm\": lgb.LGBMRegressor (\n",
    "                                n_estimators = 30000,\n",
    "                                max_depth = 11,\n",
    "                                num_leaves = 15,\n",
    "                                learning_rate = 0.05,\n",
    "                                subsample = 0.9,\n",
    "                                colsample_bytree = 0.7,\n",
    "                                random_state = 42 )\n",
    "    \n",
    "}\n",
    "\n",
    "model_type_dict = {\"catboost\": \"catboost\", \"xgboost\": \"sklearn\", \"lightgbm\": \"lightgbm\"}\n",
    "\n",
    "feature_dict = {\n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v1\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"facility_type_parsed\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v2\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"facility_type_parsed\",\n",
    "            # \"direction_max_wind_speed\": \"categorized_direction_max_wind_speed\"\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\":(\n",
    "            train_processed_df.filter(like=\"days_below\").columns.tolist() + \n",
    "            train_processed_df.filter(like=\"days_above\").columns.tolist()),\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v3\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_5_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\":(\n",
    "            train_processed_df.filter(like=\"days_below\").columns.tolist() + \n",
    "            train_processed_df.filter(like=\"days_above\").columns.tolist()),\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v4\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_10_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\":(\n",
    "            train_processed_df.filter(like=\"days_below\").columns.tolist() + \n",
    "            train_processed_df.filter(like=\"days_above\").columns.tolist()),\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v5\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_15_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\":(\n",
    "            train_processed_df.filter(like=\"days_below\").columns.tolist() + \n",
    "            train_processed_df.filter(like=\"days_above\").columns.tolist()),\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v6\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_20_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\":(\n",
    "            train_processed_df.filter(like=\"days_below\").columns.tolist() + \n",
    "            train_processed_df.filter(like=\"days_above\").columns.tolist()),\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v7\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_25_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\":(\n",
    "            train_processed_df.filter(like=\"days_below\").columns.tolist() + \n",
    "            train_processed_df.filter(like=\"days_above\").columns.tolist()),\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # Starting to use Hannah's updated random upsampling code \n",
    "    # beyond v8 - v12 to use random upsampling, with out dropping data columns\n",
    "    # get the optimal number of facility clusters for catboost\n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v8\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_25_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\":[],\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"random\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v9\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_20_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\": [],\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"random\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v10\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_15_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\": [],\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"random\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v11\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_10_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\": [],\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"random\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v12\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_5_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\": [],\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"random\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # beyond v12 - vxx to use random upsampling, with out dropping data columns\n",
    "    # try optimal facility type with lightgbm\n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_lightgbm_v13\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"lightgbm\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_energy_star_rating\",\n",
    "            \"facility_type\": \"relabled_facility_type_20_clusters\",\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"drop_data_colums\": [],\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"random\",\n",
    "        },\n",
    "    },\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "model_configs_to_run = [\n",
    "#     \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v2\",\n",
    "#         \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v3\",\n",
    "#         \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v4\",\n",
    "#         \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v5\",\n",
    "#         \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v6\",\n",
    "#         \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v7\",\n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v8\",\n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v9\",\n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v10\",\n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v11\",\n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v12\",\n",
    "        \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_lightgbm_v13\",\n",
    "    \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "cHaAUxS0ZOyn",
    "outputId": "977108d8-f7db-45bb-fca6-507765ff1244",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v8 ['days_below_30f', 'days_above_90f', 'year_built', 'snowdepth_inches', 'days_below_10f', 'cooling_degree_days', 'elevation', 'state_factor', 'days_above_80f', 'building_class', 'snowfall_inches', 'days_below_0f', 'precipitation_inches', 'days_below_20f', 'direction_peak_wind_speed', 'max_wind_speed', 'heating_degree_days', 'direction_max_wind_speed', 'days_with_fog', 'days_above_110f', 'days_above_100f', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'iter_impute_energy_star_rating', 'relabled_facility_type_25_clusters', 'log10_floor_area'] True\n",
      "Running catboost\n",
      "Modeling 1...\n",
      "Modeling 2...\n",
      "Modeling 3...\n",
      "Modeling 4...\n",
      "Modeling 5...\n",
      "Modeling 6...\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.531438\n",
      "test_rmse        52.365529\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20.114495</td>\n",
       "      <td>66.985671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19.995132</td>\n",
       "      <td>48.764518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18.807949</td>\n",
       "      <td>53.774025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19.908587</td>\n",
       "      <td>46.399388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19.316009</td>\n",
       "      <td>46.405432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>19.046458</td>\n",
       "      <td>51.864139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse\n",
       "0              1   20.114495  66.985671\n",
       "1              2   19.995132  48.764518\n",
       "2              3   18.807949  53.774025\n",
       "3              4   19.908587  46.399388\n",
       "4              5   19.316009  46.405432\n",
       "5              6   19.046458  51.864139"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data train RMSE: 33.046175866942875\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.531438\n",
      "test_rmse        52.365529\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.114495</td>\n",
       "      <td>66.985671</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.995132</td>\n",
       "      <td>48.764518</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.807949</td>\n",
       "      <td>53.774025</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.908587</td>\n",
       "      <td>46.399388</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>19.316009</td>\n",
       "      <td>46.405432</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>19.046458</td>\n",
       "      <td>51.864139</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.046176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   20.114495  66.985671         loyo\n",
       "1            2.0   19.995132  48.764518         loyo\n",
       "2            3.0   18.807949  53.774025         loyo\n",
       "3            4.0   19.908587  46.399388         loyo\n",
       "4            5.0   19.316009  46.405432         loyo\n",
       "5            6.0   19.046458  51.864139         loyo\n",
       "6            0.0   33.046176        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/opt/miniconda3/envs/ds_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v9 ['days_below_30f', 'days_above_90f', 'year_built', 'snowdepth_inches', 'days_below_10f', 'cooling_degree_days', 'elevation', 'state_factor', 'days_above_80f', 'building_class', 'snowfall_inches', 'days_below_0f', 'precipitation_inches', 'days_below_20f', 'direction_peak_wind_speed', 'max_wind_speed', 'heating_degree_days', 'direction_max_wind_speed', 'days_with_fog', 'days_above_110f', 'days_above_100f', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'iter_impute_energy_star_rating', 'relabled_facility_type_20_clusters', 'log10_floor_area'] True\n",
      "Running catboost\n",
      "Modeling 1...\n",
      "Modeling 2...\n",
      "Modeling 3...\n",
      "Modeling 4...\n",
      "Modeling 5...\n",
      "Modeling 6...\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.519525\n",
      "test_rmse        52.217650\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20.040185</td>\n",
       "      <td>67.259111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19.977206</td>\n",
       "      <td>49.888830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19.030070</td>\n",
       "      <td>53.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19.760548</td>\n",
       "      <td>45.813418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19.136425</td>\n",
       "      <td>44.072645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>19.172718</td>\n",
       "      <td>52.787815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse\n",
       "0              1   20.040185  67.259111\n",
       "1              2   19.977206  49.888830\n",
       "2              3   19.030070  53.484080\n",
       "3              4   19.760548  45.813418\n",
       "4              5   19.136425  44.072645\n",
       "5              6   19.172718  52.787815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data train RMSE: 32.93827877571841\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.519525\n",
      "test_rmse        52.217650\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.040185</td>\n",
       "      <td>67.259111</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.977206</td>\n",
       "      <td>49.888830</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19.030070</td>\n",
       "      <td>53.484080</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.760548</td>\n",
       "      <td>45.813418</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>19.136425</td>\n",
       "      <td>44.072645</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>19.172718</td>\n",
       "      <td>52.787815</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.938279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   20.040185  67.259111         loyo\n",
       "1            2.0   19.977206  49.888830         loyo\n",
       "2            3.0   19.030070  53.484080         loyo\n",
       "3            4.0   19.760548  45.813418         loyo\n",
       "4            5.0   19.136425  44.072645         loyo\n",
       "5            6.0   19.172718  52.787815         loyo\n",
       "6            0.0   32.938279        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/opt/miniconda3/envs/ds_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v10 ['days_below_30f', 'days_above_90f', 'year_built', 'snowdepth_inches', 'days_below_10f', 'cooling_degree_days', 'elevation', 'state_factor', 'days_above_80f', 'building_class', 'snowfall_inches', 'days_below_0f', 'precipitation_inches', 'days_below_20f', 'direction_peak_wind_speed', 'max_wind_speed', 'heating_degree_days', 'direction_max_wind_speed', 'days_with_fog', 'days_above_110f', 'days_above_100f', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'iter_impute_energy_star_rating', 'relabled_facility_type_15_clusters', 'log10_floor_area'] True\n",
      "Running catboost\n",
      "Modeling 1...\n",
      "Modeling 2...\n",
      "Modeling 3...\n",
      "Modeling 4...\n",
      "Modeling 5...\n",
      "Modeling 6...\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.546552\n",
      "test_rmse        52.328355\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19.990326</td>\n",
       "      <td>67.424662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19.967078</td>\n",
       "      <td>48.866406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18.862233</td>\n",
       "      <td>53.074678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19.765560</td>\n",
       "      <td>46.371519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19.431131</td>\n",
       "      <td>45.996808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>19.262983</td>\n",
       "      <td>52.236057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse\n",
       "0              1   19.990326  67.424662\n",
       "1              2   19.967078  48.866406\n",
       "2              3   18.862233  53.074678\n",
       "3              4   19.765560  46.371519\n",
       "4              5   19.431131  45.996808\n",
       "5              6   19.262983  52.236057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data train RMSE: 33.065134164868184\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.546552\n",
      "test_rmse        52.328355\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.990326</td>\n",
       "      <td>67.424662</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.967078</td>\n",
       "      <td>48.866406</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.862233</td>\n",
       "      <td>53.074678</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.765560</td>\n",
       "      <td>46.371519</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>19.431131</td>\n",
       "      <td>45.996808</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>19.262983</td>\n",
       "      <td>52.236057</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.065134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   19.990326  67.424662         loyo\n",
       "1            2.0   19.967078  48.866406         loyo\n",
       "2            3.0   18.862233  53.074678         loyo\n",
       "3            4.0   19.765560  46.371519         loyo\n",
       "4            5.0   19.431131  45.996808         loyo\n",
       "5            6.0   19.262983  52.236057         loyo\n",
       "6            0.0   33.065134        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/opt/miniconda3/envs/ds_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v11 ['days_below_30f', 'days_above_90f', 'year_built', 'snowdepth_inches', 'days_below_10f', 'cooling_degree_days', 'elevation', 'state_factor', 'days_above_80f', 'building_class', 'snowfall_inches', 'days_below_0f', 'precipitation_inches', 'days_below_20f', 'direction_peak_wind_speed', 'max_wind_speed', 'heating_degree_days', 'direction_max_wind_speed', 'days_with_fog', 'days_above_110f', 'days_above_100f', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'iter_impute_energy_star_rating', 'relabled_facility_type_10_clusters', 'log10_floor_area'] True\n",
      "Running catboost\n",
      "Modeling 1...\n",
      "Modeling 2...\n",
      "Modeling 3...\n",
      "Modeling 4...\n",
      "Modeling 5...\n",
      "Modeling 6...\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.592008\n",
      "test_rmse        52.190476\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20.174363</td>\n",
       "      <td>67.636925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.119713</td>\n",
       "      <td>48.648124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19.104258</td>\n",
       "      <td>53.322224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19.671742</td>\n",
       "      <td>46.429382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19.325343</td>\n",
       "      <td>44.458199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>19.156626</td>\n",
       "      <td>52.648001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse\n",
       "0              1   20.174363  67.636925\n",
       "1              2   20.119713  48.648124\n",
       "2              3   19.104258  53.322224\n",
       "3              4   19.671742  46.429382\n",
       "4              5   19.325343  44.458199\n",
       "5              6   19.156626  52.648001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data train RMSE: 32.95508853337637\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.592008\n",
      "test_rmse        52.190476\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.174363</td>\n",
       "      <td>67.636925</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.119713</td>\n",
       "      <td>48.648124</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19.104258</td>\n",
       "      <td>53.322224</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.671742</td>\n",
       "      <td>46.429382</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>19.325343</td>\n",
       "      <td>44.458199</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>19.156626</td>\n",
       "      <td>52.648001</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.955089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   20.174363  67.636925         loyo\n",
       "1            2.0   20.119713  48.648124         loyo\n",
       "2            3.0   19.104258  53.322224         loyo\n",
       "3            4.0   19.671742  46.429382         loyo\n",
       "4            5.0   19.325343  44.458199         loyo\n",
       "5            6.0   19.156626  52.648001         loyo\n",
       "6            0.0   32.955089        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/opt/miniconda3/envs/ds_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost_v12 ['days_below_30f', 'days_above_90f', 'year_built', 'snowdepth_inches', 'days_below_10f', 'cooling_degree_days', 'elevation', 'state_factor', 'days_above_80f', 'building_class', 'snowfall_inches', 'days_below_0f', 'precipitation_inches', 'days_below_20f', 'direction_peak_wind_speed', 'max_wind_speed', 'heating_degree_days', 'direction_max_wind_speed', 'days_with_fog', 'days_above_110f', 'days_above_100f', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'iter_impute_energy_star_rating', 'relabled_facility_type_5_clusters', 'log10_floor_area'] True\n",
      "Running catboost\n",
      "Modeling 1...\n",
      "Modeling 2...\n",
      "Modeling 3...\n",
      "Modeling 4...\n",
      "Modeling 5...\n",
      "Modeling 6...\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.780406\n",
      "test_rmse        52.462151\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20.254593</td>\n",
       "      <td>67.796740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.362889</td>\n",
       "      <td>49.360468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19.197399</td>\n",
       "      <td>54.244002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19.898471</td>\n",
       "      <td>46.587817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19.586579</td>\n",
       "      <td>44.789373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>19.382504</td>\n",
       "      <td>51.994504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse\n",
       "0              1   20.254593  67.796740\n",
       "1              2   20.362889  49.360468\n",
       "2              3   19.197399  54.244002\n",
       "3              4   19.898471  46.587817\n",
       "4              5   19.586579  44.789373\n",
       "5              6   19.382504  51.994504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data train RMSE: 33.153953347997145\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       19.780406\n",
      "test_rmse        52.462151\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.254593</td>\n",
       "      <td>67.796740</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.362889</td>\n",
       "      <td>49.360468</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19.197399</td>\n",
       "      <td>54.244002</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.898471</td>\n",
       "      <td>46.587817</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>19.586579</td>\n",
       "      <td>44.789373</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>19.382504</td>\n",
       "      <td>51.994504</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.153953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   20.254593  67.796740         loyo\n",
       "1            2.0   20.362889  49.360468         loyo\n",
       "2            3.0   19.197399  54.244002         loyo\n",
       "3            4.0   19.898471  46.587817         loyo\n",
       "4            5.0   19.586579  44.789373         loyo\n",
       "5            6.0   19.382504  51.994504         loyo\n",
       "6            0.0   33.153953        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/opt/miniconda3/envs/ds_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_lightgbm_v13 ['days_below_30f', 'days_above_90f', 'year_built', 'snowdepth_inches', 'days_below_10f', 'cooling_degree_days', 'elevation', 'state_factor', 'days_above_80f', 'building_class', 'snowfall_inches', 'days_below_0f', 'precipitation_inches', 'days_below_20f', 'direction_peak_wind_speed', 'max_wind_speed', 'heating_degree_days', 'direction_max_wind_speed', 'days_with_fog', 'days_above_110f', 'days_above_100f', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'iter_impute_energy_star_rating', 'relabled_facility_type_20_clusters', 'log10_floor_area'] True\n",
      "Running lightgbm\n",
      "Modeling 1...\n",
      "Modeling 2...\n",
      "Modeling 3...\n",
      "Modeling 4...\n",
      "Modeling 5...\n",
      "Modeling 6...\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       13.744418\n",
      "test_rmse        56.210996\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.234676</td>\n",
       "      <td>72.123026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14.087626</td>\n",
       "      <td>49.708877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.375128</td>\n",
       "      <td>54.520905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14.101754</td>\n",
       "      <td>52.766390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.640852</td>\n",
       "      <td>49.322317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>13.026472</td>\n",
       "      <td>58.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse\n",
       "0              1   14.234676  72.123026\n",
       "1              2   14.087626  49.708877\n",
       "2              3   13.375128  54.520905\n",
       "3              4   14.101754  52.766390\n",
       "4              5   13.640852  49.322317\n",
       "5              6   13.026472  58.824458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data train RMSE: 24.535151193011476\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       13.744418\n",
      "test_rmse        56.210996\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.234676</td>\n",
       "      <td>72.123026</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>14.087626</td>\n",
       "      <td>49.708877</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.375128</td>\n",
       "      <td>54.520905</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.101754</td>\n",
       "      <td>52.766390</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13.640852</td>\n",
       "      <td>49.322317</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>13.026472</td>\n",
       "      <td>58.824458</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.535151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   14.234676  72.123026         loyo\n",
       "1            2.0   14.087626  49.708877         loyo\n",
       "2            3.0   13.375128  54.520905         loyo\n",
       "3            4.0   14.101754  52.766390         loyo\n",
       "4            5.0   13.640852  49.322317         loyo\n",
       "5            6.0   13.026472  58.824458         loyo\n",
       "6            0.0   24.535151        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/opt/miniconda3/envs/ds_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"for config_name in model_configs_to_run:\\n    # get model config\\n    cols_to_reduce_dict = feature_dict[config_name][\\\"cols_to_reduce_dict\\\"]\\n    reduce_number_dict = feature_dict[config_name][\\\"reduce_number_dict\\\"]\\n    log10_transform_cols = feature_dict[config_name][\\\"log10_transform_cols\\\"]\\n    if_one_hot = feature_dict[config_name][\\\"if_one_hot\\\"]\\n    if_scale = feature_dict[config_name][\\\"if_scale\\\"]\\n    replace_original_feature_col_dict = feature_dict[config_name][\\n        \\\"replace_original_feature_col_dict\\\"\\n    ]\\n    resample_param_dict = feature_dict[config_name][\\\"resample_param_dict\\\"]\\n    drop_data_dict = feature_dict[config_name][\\\"drop_data\\\"]\\n    model_name = feature_dict[config_name][\\\"model\\\"]\\n    drop_data_colums = feature_dict[config_name][\\\"drop_data_colums\\\"]\\n\\n    model = model_dict[model_name]\\n\\n    # check if need to drop data\\n    if len(drop_data_dict) > 0:\\n        for one_col, drop_level_list in drop_data_dict.items():\\n            train_filled_df = train_filled_df.query(\\n                f\\\"{one_col} not in {drop_level_list}\\\"\\n            )\\n    # NEWLY ADDED PART TO DROP NECESSARY COLUMNS\\n    if len(drop_data_colums) > 0:\\n        train_filled_subset_df = train_filled_df.drop(columns=drop_data_colums)\\n        test_filled_subset_df = test_filled_df.drop(columns=drop_data_colums)\\n\\n    else:\\n        train_filled_subset_df = train_filled_df\\n        test_filled_subset_df = test_filled_df\\n    # process data\\n    train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\\n        train_filled_subset_df.drop_duplicates(),\\n        test_filled_subset_df.drop_duplicates(),\\n        reduce_col_dict=cols_to_reduce_dict,\\n        cols_to_log_transform=log10_transform_cols,\\n        reduce_number_dict=reduce_number_dict,\\n    )\\n    # Set feature columns after data transformations\\n    all_cols_to_reduce = []\\n    for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\\n        all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\\n\\n    all_cols_to_drop = []\\n    all_cols_to_replace_from_drop = []\\n    for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\\n        all_cols_to_drop.append(col_to_drop)\\n        all_cols_to_replace_from_drop.append(col_to_replace)\\n\\n        subset_feature_columns = (\\n            list(\\n                set(gv.all_feature_columns)\\n                - set(all_cols_to_reduce)\\n                - set(log10_transform_cols)\\n                - set(all_cols_to_drop)\\n            )\\n            + pca_cols\\n            + all_cols_to_replace_from_drop\\n            + [f\\\"log10_{col}\\\" for col in log10_transform_cols]\\n        )\\n\\n    # NEWLY ADDED PART TO DROP NECESSARY COLUMNS\\n    if len(drop_data_colums) > 0:\\n        features_columns = list(set(subset_feature_columns) - set(drop_data_colums))\\n    else:\\n        features_columns = subset_feature_columns\\n\\n    print(config_name, features_columns, if_one_hot)\\n\\n    # run model\\n    ## Run LOY model\\n    model_rmse = mu.run_leave_year_out(\\n        model_df=train_filter_df,\\n        ml_model=model,\\n        features_columns=features_columns,\\n        if_scale_data=if_scale,\\n        if_one_hot=if_one_hot,\\n        model_type=model_type_dict[model_name],\\n        resample_param_dict=resample_param_dict,\\n    )\\n    print(f\\\"Average RMSE:\\\\n{model_rmse.mean()}\\\")\\n    display(model_rmse)\\n\\n    ## predict on test data\\n    if len(resample_param_dict) > 0:\\n        train_for_resample_df = train_filter_df\\n        resample_by_col = resample_param_dict[\\\"resample_by_col\\\"]\\n        resample_type = resample_param_dict[\\\"resample_type\\\"]\\n        if resample_param_dict[\\\"up_or_downsample\\\"] == \\\"upsample\\\":\\n            train_filter_x_df = mu.upsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n        elif resample_param_dict[\\\"up_or_downsample\\\"] == \\\"downsample\\\":\\n            train_filter_x_df = mu.downsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n\\n    train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\\n        train_filter_df, features_columns\\n    )\\n    test_filter_x_df = mu.split_model_feature_response(\\n        test_filter_df, features_columns, if_with_response=False\\n    )\\n    processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\\n        train_filter_x_df,\\n        test_filter_x_df,\\n        if_scale,\\n        if_one_hot,\\n        full_data_df=train_filter_x_df,\\n    )\\n    run_model_dict = {\\n        \\\"xgboost\\\": mu.run_sklearn_model,\\n        \\\"catboost\\\": mu.run_catboost_model,\\n        \\\"lightgbm\\\": mu.run_lgb_model,\\n    }\\n    train_predict, test_predict, fitted_model = run_model_dict[model_name](\\n        model, processed_train_x_df, train_filter_y_df, processed_test_x_df\\n    )\\n    training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\\n    print(f\\\"Whole data train RMSE: {training_rmse}\\\")\\n    \\n    # Save outputs to local\\n    model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\\n    model_rmse[\\\"method\\\"] = model_rmse[\\\"left_out_year\\\"].apply(\\n        lambda x: \\\"loyo\\\" if x > 0 else \\\"whole train\\\"\\n    )\\n    \\n    model_rmse.to_csv(\\n        f\\\"{wids_path}validation_result/meng/{config_name}.csv\\\", index=False\\n    )\\n\\n    print(f\\\"Average RMSE:\\\\n{model_rmse.query('left_out_year != 0').mean()}\\\")\\n    display(model_rmse)\\n\\n    test_prediction_result = test_df[[\\\"id\\\"]]\\n    test_prediction_result[\\\"site_eui\\\"] = test_predict\\n    test_prediction_result.to_csv(\\n        f\\\"{wids_path}prediction_result/meng/{config_name}_{today}.csv\\\", index=False\\n    )\\n\\n    if model_name == \\\"catboost\\\":\\n        viz.plot_catboost_feature_importance(model)\\n        plt.savefig(\\n            f\\\"{wids_path}prediction_result/meng/{config_name}_feature_importance.png\\\"\\n        )\\n        plt.close()\\n    elif model_name == \\\"xgboost\\\":\\n        fig, ax = plt.subplots(figsize=(15, 20))\\n        xgb.plot_importance(fitted_model, ax=ax)\\n        plt.savefig(\\n            f\\\"{wids_path}prediction_result/meng/{config_name}_feature_importance.png\\\"\\n        )\\n        plt.close()\";\n",
       "                var nbb_formatted_code = \"for config_name in model_configs_to_run:\\n    # get model config\\n    cols_to_reduce_dict = feature_dict[config_name][\\\"cols_to_reduce_dict\\\"]\\n    reduce_number_dict = feature_dict[config_name][\\\"reduce_number_dict\\\"]\\n    log10_transform_cols = feature_dict[config_name][\\\"log10_transform_cols\\\"]\\n    if_one_hot = feature_dict[config_name][\\\"if_one_hot\\\"]\\n    if_scale = feature_dict[config_name][\\\"if_scale\\\"]\\n    replace_original_feature_col_dict = feature_dict[config_name][\\n        \\\"replace_original_feature_col_dict\\\"\\n    ]\\n    resample_param_dict = feature_dict[config_name][\\\"resample_param_dict\\\"]\\n    drop_data_dict = feature_dict[config_name][\\\"drop_data\\\"]\\n    model_name = feature_dict[config_name][\\\"model\\\"]\\n    drop_data_colums = feature_dict[config_name][\\\"drop_data_colums\\\"]\\n\\n    model = model_dict[model_name]\\n\\n    # check if need to drop data\\n    if len(drop_data_dict) > 0:\\n        for one_col, drop_level_list in drop_data_dict.items():\\n            train_filled_df = train_filled_df.query(\\n                f\\\"{one_col} not in {drop_level_list}\\\"\\n            )\\n    # NEWLY ADDED PART TO DROP NECESSARY COLUMNS\\n    if len(drop_data_colums) > 0:\\n        train_filled_subset_df = train_filled_df.drop(columns=drop_data_colums)\\n        test_filled_subset_df = test_filled_df.drop(columns=drop_data_colums)\\n\\n    else:\\n        train_filled_subset_df = train_filled_df\\n        test_filled_subset_df = test_filled_df\\n    # process data\\n    train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\\n        train_filled_subset_df.drop_duplicates(),\\n        test_filled_subset_df.drop_duplicates(),\\n        reduce_col_dict=cols_to_reduce_dict,\\n        cols_to_log_transform=log10_transform_cols,\\n        reduce_number_dict=reduce_number_dict,\\n    )\\n    # Set feature columns after data transformations\\n    all_cols_to_reduce = []\\n    for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\\n        all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\\n\\n    all_cols_to_drop = []\\n    all_cols_to_replace_from_drop = []\\n    for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\\n        all_cols_to_drop.append(col_to_drop)\\n        all_cols_to_replace_from_drop.append(col_to_replace)\\n\\n        subset_feature_columns = (\\n            list(\\n                set(gv.all_feature_columns)\\n                - set(all_cols_to_reduce)\\n                - set(log10_transform_cols)\\n                - set(all_cols_to_drop)\\n            )\\n            + pca_cols\\n            + all_cols_to_replace_from_drop\\n            + [f\\\"log10_{col}\\\" for col in log10_transform_cols]\\n        )\\n\\n    # NEWLY ADDED PART TO DROP NECESSARY COLUMNS\\n    if len(drop_data_colums) > 0:\\n        features_columns = list(set(subset_feature_columns) - set(drop_data_colums))\\n    else:\\n        features_columns = subset_feature_columns\\n\\n    print(config_name, features_columns, if_one_hot)\\n\\n    # run model\\n    ## Run LOY model\\n    model_rmse = mu.run_leave_year_out(\\n        model_df=train_filter_df,\\n        ml_model=model,\\n        features_columns=features_columns,\\n        if_scale_data=if_scale,\\n        if_one_hot=if_one_hot,\\n        model_type=model_type_dict[model_name],\\n        resample_param_dict=resample_param_dict,\\n    )\\n    print(f\\\"Average RMSE:\\\\n{model_rmse.mean()}\\\")\\n    display(model_rmse)\\n\\n    ## predict on test data\\n    if len(resample_param_dict) > 0:\\n        train_for_resample_df = train_filter_df\\n        resample_by_col = resample_param_dict[\\\"resample_by_col\\\"]\\n        resample_type = resample_param_dict[\\\"resample_type\\\"]\\n        if resample_param_dict[\\\"up_or_downsample\\\"] == \\\"upsample\\\":\\n            train_filter_x_df = mu.upsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n        elif resample_param_dict[\\\"up_or_downsample\\\"] == \\\"downsample\\\":\\n            train_filter_x_df = mu.downsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n\\n    train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\\n        train_filter_df, features_columns\\n    )\\n    test_filter_x_df = mu.split_model_feature_response(\\n        test_filter_df, features_columns, if_with_response=False\\n    )\\n    processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\\n        train_filter_x_df,\\n        test_filter_x_df,\\n        if_scale,\\n        if_one_hot,\\n        full_data_df=train_filter_x_df,\\n    )\\n    run_model_dict = {\\n        \\\"xgboost\\\": mu.run_sklearn_model,\\n        \\\"catboost\\\": mu.run_catboost_model,\\n        \\\"lightgbm\\\": mu.run_lgb_model,\\n    }\\n    train_predict, test_predict, fitted_model = run_model_dict[model_name](\\n        model, processed_train_x_df, train_filter_y_df, processed_test_x_df\\n    )\\n    training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\\n    print(f\\\"Whole data train RMSE: {training_rmse}\\\")\\n\\n    # Save outputs to local\\n    model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\\n    model_rmse[\\\"method\\\"] = model_rmse[\\\"left_out_year\\\"].apply(\\n        lambda x: \\\"loyo\\\" if x > 0 else \\\"whole train\\\"\\n    )\\n\\n    model_rmse.to_csv(\\n        f\\\"{wids_path}validation_result/meng/{config_name}.csv\\\", index=False\\n    )\\n\\n    print(f\\\"Average RMSE:\\\\n{model_rmse.query('left_out_year != 0').mean()}\\\")\\n    display(model_rmse)\\n\\n    test_prediction_result = test_df[[\\\"id\\\"]]\\n    test_prediction_result[\\\"site_eui\\\"] = test_predict\\n    test_prediction_result.to_csv(\\n        f\\\"{wids_path}prediction_result/meng/{config_name}_{today}.csv\\\", index=False\\n    )\\n\\n    if model_name == \\\"catboost\\\":\\n        viz.plot_catboost_feature_importance(model)\\n        plt.savefig(\\n            f\\\"{wids_path}prediction_result/meng/{config_name}_feature_importance.png\\\"\\n        )\\n        plt.close()\\n    elif model_name == \\\"xgboost\\\":\\n        fig, ax = plt.subplots(figsize=(15, 20))\\n        xgb.plot_importance(fitted_model, ax=ax)\\n        plt.savefig(\\n            f\\\"{wids_path}prediction_result/meng/{config_name}_feature_importance.png\\\"\\n        )\\n        plt.close()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for config_name in model_configs_to_run:\n",
    "    # get model config\n",
    "    cols_to_reduce_dict = feature_dict[config_name][\"cols_to_reduce_dict\"]\n",
    "    reduce_number_dict = feature_dict[config_name][\"reduce_number_dict\"]\n",
    "    log10_transform_cols = feature_dict[config_name][\"log10_transform_cols\"]\n",
    "    if_one_hot = feature_dict[config_name][\"if_one_hot\"]\n",
    "    if_scale = feature_dict[config_name][\"if_scale\"]\n",
    "    replace_original_feature_col_dict = feature_dict[config_name][\n",
    "        \"replace_original_feature_col_dict\"\n",
    "    ]\n",
    "    resample_param_dict = feature_dict[config_name][\"resample_param_dict\"]\n",
    "    drop_data_dict = feature_dict[config_name][\"drop_data\"]\n",
    "    model_name = feature_dict[config_name][\"model\"]\n",
    "    drop_data_colums = feature_dict[config_name][\"drop_data_colums\"]\n",
    "\n",
    "    model = model_dict[model_name]\n",
    "\n",
    "    # check if need to drop data\n",
    "    if len(drop_data_dict) > 0:\n",
    "        for one_col, drop_level_list in drop_data_dict.items():\n",
    "            train_filled_df = train_filled_df.query(\n",
    "                f\"{one_col} not in {drop_level_list}\"\n",
    "            )\n",
    "    # NEWLY ADDED PART TO DROP NECESSARY COLUMNS\n",
    "    if len(drop_data_colums) > 0:\n",
    "        train_filled_subset_df = train_filled_df.drop(columns=drop_data_colums)\n",
    "        test_filled_subset_df = test_filled_df.drop(columns=drop_data_colums)\n",
    "\n",
    "    else:\n",
    "        train_filled_subset_df = train_filled_df\n",
    "        test_filled_subset_df = test_filled_df\n",
    "    # process data\n",
    "    train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\n",
    "        train_filled_subset_df.drop_duplicates(),\n",
    "        test_filled_subset_df.drop_duplicates(),\n",
    "        reduce_col_dict=cols_to_reduce_dict,\n",
    "        cols_to_log_transform=log10_transform_cols,\n",
    "        reduce_number_dict=reduce_number_dict,\n",
    "    )\n",
    "    # Set feature columns after data transformations\n",
    "    all_cols_to_reduce = []\n",
    "    for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\n",
    "        all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\n",
    "\n",
    "    all_cols_to_drop = []\n",
    "    all_cols_to_replace_from_drop = []\n",
    "    for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\n",
    "        all_cols_to_drop.append(col_to_drop)\n",
    "        all_cols_to_replace_from_drop.append(col_to_replace)\n",
    "\n",
    "        subset_feature_columns = (\n",
    "            list(\n",
    "                set(gv.all_feature_columns)\n",
    "                - set(all_cols_to_reduce)\n",
    "                - set(log10_transform_cols)\n",
    "                - set(all_cols_to_drop)\n",
    "            )\n",
    "            + pca_cols\n",
    "            + all_cols_to_replace_from_drop\n",
    "            + [f\"log10_{col}\" for col in log10_transform_cols]\n",
    "        )\n",
    "\n",
    "    # NEWLY ADDED PART TO DROP NECESSARY COLUMNS\n",
    "    if len(drop_data_colums) > 0:\n",
    "        features_columns = list(set(subset_feature_columns) - set(drop_data_colums))\n",
    "    else:\n",
    "        features_columns = subset_feature_columns\n",
    "\n",
    "    print(config_name, features_columns, if_one_hot)\n",
    "\n",
    "    # run model\n",
    "    ## Run LOY model\n",
    "    model_rmse = mu.run_leave_year_out(\n",
    "        model_df=train_filter_df,\n",
    "        ml_model=model,\n",
    "        features_columns=features_columns,\n",
    "        if_scale_data=if_scale,\n",
    "        if_one_hot=if_one_hot,\n",
    "        model_type=model_type_dict[model_name],\n",
    "        resample_param_dict=resample_param_dict,\n",
    "    )\n",
    "    print(f\"Average RMSE:\\n{model_rmse.mean()}\")\n",
    "    display(model_rmse)\n",
    "\n",
    "    ## predict on test data\n",
    "    if len(resample_param_dict) > 0:\n",
    "        train_for_resample_df = train_filter_df\n",
    "        resample_by_col = resample_param_dict[\"resample_by_col\"]\n",
    "        resample_type = resample_param_dict[\"resample_type\"]\n",
    "        if resample_param_dict[\"up_or_downsample\"] == \"upsample\":\n",
    "            train_filter_x_df = mu.upsampling_by_column(\n",
    "                train_for_resample_df, resample_by_col, resample_type=resample_type\n",
    "            )\n",
    "        elif resample_param_dict[\"up_or_downsample\"] == \"downsample\":\n",
    "            train_filter_x_df = mu.downsampling_by_column(\n",
    "                train_for_resample_df, resample_by_col, resample_type=resample_type\n",
    "            )\n",
    "\n",
    "    train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\n",
    "        train_filter_df, features_columns\n",
    "    )\n",
    "    test_filter_x_df = mu.split_model_feature_response(\n",
    "        test_filter_df, features_columns, if_with_response=False\n",
    "    )\n",
    "    processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\n",
    "        train_filter_x_df,\n",
    "        test_filter_x_df,\n",
    "        if_scale,\n",
    "        if_one_hot,\n",
    "        full_data_df=train_filter_x_df,\n",
    "    )\n",
    "    run_model_dict = {\n",
    "        \"xgboost\": mu.run_sklearn_model,\n",
    "        \"catboost\": mu.run_catboost_model,\n",
    "        \"lightgbm\": mu.run_lgb_model,\n",
    "    }\n",
    "    train_predict, test_predict, fitted_model = run_model_dict[model_name](\n",
    "        model, processed_train_x_df, train_filter_y_df, processed_test_x_df\n",
    "    )\n",
    "    training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\n",
    "    print(f\"Whole data train RMSE: {training_rmse}\")\n",
    "    \n",
    "    # Save outputs to local\n",
    "    model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\n",
    "    model_rmse[\"method\"] = model_rmse[\"left_out_year\"].apply(\n",
    "        lambda x: \"loyo\" if x > 0 else \"whole train\"\n",
    "    )\n",
    "    \n",
    "    model_rmse.to_csv(\n",
    "        f\"{wids_path}validation_result/meng/{config_name}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    print(f\"Average RMSE:\\n{model_rmse.query('left_out_year != 0').mean()}\")\n",
    "    display(model_rmse)\n",
    "\n",
    "    test_prediction_result = test_df[[\"id\"]]\n",
    "    test_prediction_result[\"site_eui\"] = test_predict\n",
    "    test_prediction_result.to_csv(\n",
    "        f\"{wids_path}prediction_result/meng/{config_name}_{today}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    if model_name == \"catboost\":\n",
    "        viz.plot_catboost_feature_importance(model)\n",
    "        plt.savefig(\n",
    "            f\"{wids_path}prediction_result/meng/{config_name}_feature_importance.png\"\n",
    "        )\n",
    "        plt.close()\n",
    "    elif model_name == \"xgboost\":\n",
    "        fig, ax = plt.subplots(figsize=(15, 20))\n",
    "        xgb.plot_importance(fitted_model, ax=ax)\n",
    "        plt.savefig(\n",
    "            f\"{wids_path}prediction_result/meng/{config_name}_feature_importance.png\"\n",
    "        )\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_run.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
