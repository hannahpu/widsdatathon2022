{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UrBvH-g8GxD",
    "outputId": "65ac4b7c-55e6-461a-da73-3310573b02d6"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/hannahpu/widsdatathon2022.git\n",
    "# ! ls ./widsdatathon2022\n",
    "# ! pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "wBT_F_YX7tyX",
    "outputId": "1cfedaf2-6f51-4eb3-96d0-0111e7e7b0e0"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import sys\\n\\nimport pandas as pd\\nimport catboost as cb\\nimport xgboost as xgb\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# Will need enable_iterative_imputer import otherwise IterativeImputer\\n# gives import error\\nfrom sklearn.experimental import enable_iterative_imputer\\nfrom sklearn.impute import IterativeImputer\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\nsys.path.append(\\\"..\\\")\\nimport global_vars as gv\\nfrom utils import model_utils as mu\\nfrom utils import data_utils as du\\nfrom utils import data_process_utils as dpu\\nfrom utils import visualize as viz\\n\\n# from utils.data_utils im\\\"port *\\n# from utils.data_process_utils import *\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import sys\\n\\nimport pandas as pd\\nimport catboost as cb\\nimport xgboost as xgb\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# Will need enable_iterative_imputer import otherwise IterativeImputer\\n# gives import error\\nfrom sklearn.experimental import enable_iterative_imputer\\nfrom sklearn.impute import IterativeImputer\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\nsys.path.append(\\\"..\\\")\\nimport global_vars as gv\\nfrom utils import model_utils as mu\\nfrom utils import data_utils as du\\nfrom utils import data_process_utils as dpu\\nfrom utils import visualize as viz\\n\\n# from utils.data_utils im\\\"port *\\n# from utils.data_process_utils import *\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Will need enable_iterative_imputer import otherwise IterativeImputer\n",
    "# gives import error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import global_vars as gv\n",
    "from utils import model_utils as mu\n",
    "from utils import data_utils as du\n",
    "from utils import data_process_utils as dpu\n",
    "from utils import visualize as viz\n",
    "\n",
    "# from utils.data_utils im\"port *\n",
    "# from utils.data_process_utils import *\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tY7bD2Awnps9",
    "outputId": "d22e2d8d-459c-442e-b508-f33f6fee5b7e"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"wids_path = \\\"../\\\"\";\n",
       "                var nbb_formatted_code = \"wids_path = \\\"../\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wids_path = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "miNzq96M7xAu",
    "outputId": "39810107-9d80-4d6b-dcea-72cb9a7a7b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dimension: (9705, 63)\n",
      "Train dimension: (75757, 64)\n",
      "Sample solution dimension: (9705, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"test_df = pd.read_csv(\\\"../data/test.csv\\\")\\nprint(f\\\"Test dimension: {test_df.shape}\\\")\\ntrain_df = pd.read_csv(\\\"../data/train.csv\\\")\\nprint(f\\\"Train dimension: {train_df.shape}\\\")\\nsample_solution_df = pd.read_csv(\\\"../data/sample_solution.csv\\\")\\nprint(f\\\"Sample solution dimension: {sample_solution_df.shape}\\\")\\ntrain_df.columns = train_df.columns.str.lower()\\ntest_df.columns = test_df.columns.str.lower()\";\n",
       "                var nbb_formatted_code = \"test_df = pd.read_csv(\\\"../data/test.csv\\\")\\nprint(f\\\"Test dimension: {test_df.shape}\\\")\\ntrain_df = pd.read_csv(\\\"../data/train.csv\\\")\\nprint(f\\\"Train dimension: {train_df.shape}\\\")\\nsample_solution_df = pd.read_csv(\\\"../data/sample_solution.csv\\\")\\nprint(f\\\"Sample solution dimension: {sample_solution_df.shape}\\\")\\ntrain_df.columns = train_df.columns.str.lower()\\ntest_df.columns = test_df.columns.str.lower()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "print(f\"Test dimension: {test_df.shape}\")\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"Train dimension: {train_df.shape}\")\n",
    "sample_solution_df = pd.read_csv(\"../data/sample_solution.csv\")\n",
    "print(f\"Sample solution dimension: {sample_solution_df.shape}\")\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "test_df.columns = test_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "xHd39G2t9b4H",
    "outputId": "dc1d9151-b0bb-4afc-9740-2f9f45084b9e"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Add parsed facility type, after parsing it has 20 types\\ntrain_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=train_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\\ntest_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=test_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"# Add parsed facility type, after parsing it has 20 types\\ntrain_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=train_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\\ntest_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=test_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add parsed facility type, after parsing it has 20 types\n",
    "train_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
    "    input_df=train_df.copy(), facility_type_colname=\"facility_type\"\n",
    ")\n",
    "test_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
    "    input_df=test_df.copy(), facility_type_colname=\"facility_type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "6vRguYhg-3Ii",
    "outputId": "d8b7171c-0415-4050-9359-22f0c4cfb68c"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Backfill missing 'direction_max_wind_speed' with categorized values based on\\n# [\\\"state_factor\\\", \\\"year\\\"] aggregation\\ngroupby_list = [\\\"state_factor\\\", \\\"year_factor\\\"]\\ncol = \\\"direction_max_wind_speed\\\"\\n\\ntrain_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=train_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=groupby_list,\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# Because there is only one year in test data therefore backfill based on\\n# [\\\"state_factor\\\", \\\"year_factor\\\"] won't work, therefore we only used \\\"state_factor\\\"\\n# instead\\ntest_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=test_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=[\\\"state_factor\\\"],\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# print(train_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n# print(test_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n\\n# Get categorized on 'backfilled_direction_max_wind_speed'\\nbackfilled_max_wind_speed_col = \\\"backfilled_direction_max_wind_speed\\\"\\ntrain_w_categorized_max_wind_speed_df = (\\n    train_backfill_direction_max_wind_speed_df.assign(\\n        categorized_direction_max_wind_speed=lambda df: df[\\n            backfilled_max_wind_speed_col\\n        ].apply(\\n            lambda a_direction_value: dpu.categorize_wind_direction(\\n                wind_direction_degree=a_direction_value, n_bins_categorized=8\\n            )\\n        )\\n    )\\n)\\n\\ntest_w_categorized_max_wind_speed_df = test_backfill_direction_max_wind_speed_df.assign(\\n    categorized_direction_max_wind_speed=lambda df: df[\\n        backfilled_max_wind_speed_col\\n    ].apply(\\n        lambda a_direction_value: dpu.categorize_wind_direction(\\n            wind_direction_degree=a_direction_value, n_bins_categorized=8\\n        )\\n    )\\n)\\n# print(train_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\\n# print(test_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\";\n",
       "                var nbb_formatted_code = \"# Backfill missing 'direction_max_wind_speed' with categorized values based on\\n# [\\\"state_factor\\\", \\\"year\\\"] aggregation\\ngroupby_list = [\\\"state_factor\\\", \\\"year_factor\\\"]\\ncol = \\\"direction_max_wind_speed\\\"\\n\\ntrain_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=train_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=groupby_list,\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# Because there is only one year in test data therefore backfill based on\\n# [\\\"state_factor\\\", \\\"year_factor\\\"] won't work, therefore we only used \\\"state_factor\\\"\\n# instead\\ntest_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\\n    input_df=test_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=[\\\"state_factor\\\"],\\n    wind_direction_colname=col,\\n    agg_approach_func=np.nanmean,\\n)\\n# print(train_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n# print(test_backfill_direction_max_wind_speed_df.filter(like=\\\"direction_max\\\").info())\\n\\n# Get categorized on 'backfilled_direction_max_wind_speed'\\nbackfilled_max_wind_speed_col = \\\"backfilled_direction_max_wind_speed\\\"\\ntrain_w_categorized_max_wind_speed_df = (\\n    train_backfill_direction_max_wind_speed_df.assign(\\n        categorized_direction_max_wind_speed=lambda df: df[\\n            backfilled_max_wind_speed_col\\n        ].apply(\\n            lambda a_direction_value: dpu.categorize_wind_direction(\\n                wind_direction_degree=a_direction_value, n_bins_categorized=8\\n            )\\n        )\\n    )\\n)\\n\\ntest_w_categorized_max_wind_speed_df = test_backfill_direction_max_wind_speed_df.assign(\\n    categorized_direction_max_wind_speed=lambda df: df[\\n        backfilled_max_wind_speed_col\\n    ].apply(\\n        lambda a_direction_value: dpu.categorize_wind_direction(\\n            wind_direction_degree=a_direction_value, n_bins_categorized=8\\n        )\\n    )\\n)\\n# print(train_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\\n# print(test_w_categorized_max_wind_speed_df.filter(like=\\\"categorized_direction\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Backfill missing 'direction_max_wind_speed' with categorized values based on\n",
    "# [\"state_factor\", \"year\"] aggregation\n",
    "groupby_list = [\"state_factor\", \"year_factor\"]\n",
    "col = \"direction_max_wind_speed\"\n",
    "\n",
    "train_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\n",
    "    input_df=train_w_parsed_facility_type_df,\n",
    "    mapping_df=train_w_parsed_facility_type_df,\n",
    "    groupby_list=groupby_list,\n",
    "    wind_direction_colname=col,\n",
    "    agg_approach_func=np.nanmean,\n",
    ")\n",
    "# Because there is only one year in test data therefore backfill based on\n",
    "# [\"state_factor\", \"year_factor\"] won't work, therefore we only used \"state_factor\"\n",
    "# instead\n",
    "test_backfill_direction_max_wind_speed_df = dpu.backfill_wind_direction(\n",
    "    input_df=test_w_parsed_facility_type_df,\n",
    "    mapping_df=train_w_parsed_facility_type_df,\n",
    "    groupby_list=[\"state_factor\"],\n",
    "    wind_direction_colname=col,\n",
    "    agg_approach_func=np.nanmean,\n",
    ")\n",
    "# print(train_backfill_direction_max_wind_speed_df.filter(like=\"direction_max\").info())\n",
    "# print(test_backfill_direction_max_wind_speed_df.filter(like=\"direction_max\").info())\n",
    "\n",
    "# Get categorized on 'backfilled_direction_max_wind_speed'\n",
    "backfilled_max_wind_speed_col = \"backfilled_direction_max_wind_speed\"\n",
    "train_w_categorized_max_wind_speed_df = (\n",
    "    train_backfill_direction_max_wind_speed_df.assign(\n",
    "        categorized_direction_max_wind_speed=lambda df: df[\n",
    "            backfilled_max_wind_speed_col\n",
    "        ].apply(\n",
    "            lambda a_direction_value: dpu.categorize_wind_direction(\n",
    "                wind_direction_degree=a_direction_value, n_bins_categorized=8\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "test_w_categorized_max_wind_speed_df = test_backfill_direction_max_wind_speed_df.assign(\n",
    "    categorized_direction_max_wind_speed=lambda df: df[\n",
    "        backfilled_max_wind_speed_col\n",
    "    ].apply(\n",
    "        lambda a_direction_value: dpu.categorize_wind_direction(\n",
    "            wind_direction_degree=a_direction_value, n_bins_categorized=8\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# print(train_w_categorized_max_wind_speed_df.filter(like=\"categorized_direction\"))\n",
    "# print(test_w_categorized_max_wind_speed_df.filter(like=\"categorized_direction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkuPjfeMYrnY"
   },
   "source": [
    "**Use iterative imputer to impute energy star ratings**\n",
    "\n",
    "With PCA components = 4 which explains 81% variance and one-hot-encoding. The categorical features used in the imputer are \"state_factor\", \"building_class\", and \"facility_type_parsed\". The numerical features are all below temp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "rHdy0I7SImpp",
    "outputId": "a4163469-b1a5-4fef-b1f7-aa91c5fe40ed"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"train_impute_energy_star_df = train_w_categorized_max_wind_speed_df.copy()\\ntest_impute_energy_star_df = test_w_categorized_max_wind_speed_df.copy()\\n\\n# Run a PCA for missing value imputation in energy star rating\\ncols_to_reduce_numerical = gv.below_temp_col_list \\ncols_to_reduce_categorical = [\\\"state_factor\\\", \\n                              \\\"building_class\\\", \\n                              \\\"facility_type_parsed\\\"]\\n\\n# Need a one-hot-encoding\\ntrain_impute_energy_star_dfs_list = []\\ntest_impute_energy_star_dfs_list = []\\nfor a_categorical_col in cols_to_reduce_categorical:\\n    onehot_encoder = OneHotEncoder().fit(\\n      train_impute_energy_star_df[[a_categorical_col]])\\n    train_impute_energy_star_transformed_array = onehot_encoder.transform(\\n      train_impute_energy_star_df[[a_categorical_col]]).toarray()\\n    test_impute_energy_star_transformed_array = onehot_encoder.transform(\\n      test_impute_energy_star_df[[a_categorical_col]]).toarray()\\n    \\n    train_impute_energy_star_transformed_df = pd.DataFrame(\\n      train_impute_energy_star_transformed_array, \\n      columns=[f\\\"{a_categorical_col}_{i}\\\" for i in \\n               range(train_impute_energy_star_transformed_array.shape[1])])\\n    test_impute_energy_star_transformed_df = pd.DataFrame(\\n      test_impute_energy_star_transformed_array, \\n      columns=[f\\\"{a_categorical_col}_{i}\\\" for i in \\n               range(test_impute_energy_star_transformed_array.shape[1])])\\n    \\n    train_impute_energy_star_dfs_list.append(train_impute_energy_star_transformed_df)\\n    test_impute_energy_star_dfs_list.append(test_impute_energy_star_transformed_df)\\n\\n# Merge processed categorical data into one based on index\\ntrain_impute_energy_star_processed_categorical_df = pd.concat(\\n    train_impute_energy_star_dfs_list, axis=1\\n)\\ntest_impute_energy_star_processed_categorical_df = pd.concat(\\n    test_impute_energy_star_dfs_list, axis=1\\n)\\n\\nscaled_train_impute_energy_star_df, scaled_test_impute_energy_star_df = mu.scale_data(\\n    train_impute_energy_star_df[cols_to_reduce_numerical], \\n    test_impute_energy_star_df[cols_to_reduce_numerical]\\n)\\n\\n# Merge processed categorical and numerical together\\ntrain_impute_energy_star_merged_df = train_impute_energy_star_processed_categorical_df.merge(\\n   scaled_train_impute_energy_star_df, left_index=True, right_index=True,\\n   how=\\\"left\\\" \\n)\\n\\ntest_impute_energy_star_merged_df = test_impute_energy_star_processed_categorical_df.merge(\\n   scaled_test_impute_energy_star_df, left_index=True, right_index=True,\\n   how=\\\"left\\\" \\n)\";\n",
       "                var nbb_formatted_code = \"train_impute_energy_star_df = train_w_categorized_max_wind_speed_df.copy()\\ntest_impute_energy_star_df = test_w_categorized_max_wind_speed_df.copy()\\n\\n# Run a PCA for missing value imputation in energy star rating\\ncols_to_reduce_numerical = gv.below_temp_col_list\\ncols_to_reduce_categorical = [\\\"state_factor\\\", \\\"building_class\\\", \\\"facility_type_parsed\\\"]\\n\\n# Need a one-hot-encoding\\ntrain_impute_energy_star_dfs_list = []\\ntest_impute_energy_star_dfs_list = []\\nfor a_categorical_col in cols_to_reduce_categorical:\\n    onehot_encoder = OneHotEncoder().fit(\\n        train_impute_energy_star_df[[a_categorical_col]]\\n    )\\n    train_impute_energy_star_transformed_array = onehot_encoder.transform(\\n        train_impute_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n    test_impute_energy_star_transformed_array = onehot_encoder.transform(\\n        test_impute_energy_star_df[[a_categorical_col]]\\n    ).toarray()\\n\\n    train_impute_energy_star_transformed_df = pd.DataFrame(\\n        train_impute_energy_star_transformed_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(train_impute_energy_star_transformed_array.shape[1])\\n        ],\\n    )\\n    test_impute_energy_star_transformed_df = pd.DataFrame(\\n        test_impute_energy_star_transformed_array,\\n        columns=[\\n            f\\\"{a_categorical_col}_{i}\\\"\\n            for i in range(test_impute_energy_star_transformed_array.shape[1])\\n        ],\\n    )\\n\\n    train_impute_energy_star_dfs_list.append(train_impute_energy_star_transformed_df)\\n    test_impute_energy_star_dfs_list.append(test_impute_energy_star_transformed_df)\\n\\n# Merge processed categorical data into one based on index\\ntrain_impute_energy_star_processed_categorical_df = pd.concat(\\n    train_impute_energy_star_dfs_list, axis=1\\n)\\ntest_impute_energy_star_processed_categorical_df = pd.concat(\\n    test_impute_energy_star_dfs_list, axis=1\\n)\\n\\nscaled_train_impute_energy_star_df, scaled_test_impute_energy_star_df = mu.scale_data(\\n    train_impute_energy_star_df[cols_to_reduce_numerical],\\n    test_impute_energy_star_df[cols_to_reduce_numerical],\\n)\\n\\n# Merge processed categorical and numerical together\\ntrain_impute_energy_star_merged_df = (\\n    train_impute_energy_star_processed_categorical_df.merge(\\n        scaled_train_impute_energy_star_df,\\n        left_index=True,\\n        right_index=True,\\n        how=\\\"left\\\",\\n    )\\n)\\n\\ntest_impute_energy_star_merged_df = (\\n    test_impute_energy_star_processed_categorical_df.merge(\\n        scaled_test_impute_energy_star_df, left_index=True, right_index=True, how=\\\"left\\\"\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_impute_energy_star_df = train_w_categorized_max_wind_speed_df.copy()\n",
    "test_impute_energy_star_df = test_w_categorized_max_wind_speed_df.copy()\n",
    "\n",
    "# Run a PCA for missing value imputation in energy star rating\n",
    "cols_to_reduce_numerical = gv.below_temp_col_list \n",
    "cols_to_reduce_categorical = [\"state_factor\", \n",
    "                              \"building_class\", \n",
    "                              \"facility_type_parsed\"]\n",
    "\n",
    "# Need a one-hot-encoding\n",
    "train_impute_energy_star_dfs_list = []\n",
    "test_impute_energy_star_dfs_list = []\n",
    "for a_categorical_col in cols_to_reduce_categorical:\n",
    "    onehot_encoder = OneHotEncoder().fit(\n",
    "      train_impute_energy_star_df[[a_categorical_col]])\n",
    "    train_impute_energy_star_transformed_array = onehot_encoder.transform(\n",
    "      train_impute_energy_star_df[[a_categorical_col]]).toarray()\n",
    "    test_impute_energy_star_transformed_array = onehot_encoder.transform(\n",
    "      test_impute_energy_star_df[[a_categorical_col]]).toarray()\n",
    "    \n",
    "    train_impute_energy_star_transformed_df = pd.DataFrame(\n",
    "      train_impute_energy_star_transformed_array, \n",
    "      columns=[f\"{a_categorical_col}_{i}\" for i in \n",
    "               range(train_impute_energy_star_transformed_array.shape[1])])\n",
    "    test_impute_energy_star_transformed_df = pd.DataFrame(\n",
    "      test_impute_energy_star_transformed_array, \n",
    "      columns=[f\"{a_categorical_col}_{i}\" for i in \n",
    "               range(test_impute_energy_star_transformed_array.shape[1])])\n",
    "    \n",
    "    train_impute_energy_star_dfs_list.append(train_impute_energy_star_transformed_df)\n",
    "    test_impute_energy_star_dfs_list.append(test_impute_energy_star_transformed_df)\n",
    "\n",
    "# Merge processed categorical data into one based on index\n",
    "train_impute_energy_star_processed_categorical_df = pd.concat(\n",
    "    train_impute_energy_star_dfs_list, axis=1\n",
    ")\n",
    "test_impute_energy_star_processed_categorical_df = pd.concat(\n",
    "    test_impute_energy_star_dfs_list, axis=1\n",
    ")\n",
    "\n",
    "scaled_train_impute_energy_star_df, scaled_test_impute_energy_star_df = mu.scale_data(\n",
    "    train_impute_energy_star_df[cols_to_reduce_numerical], \n",
    "    test_impute_energy_star_df[cols_to_reduce_numerical]\n",
    ")\n",
    "\n",
    "# Merge processed categorical and numerical together\n",
    "train_impute_energy_star_merged_df = train_impute_energy_star_processed_categorical_df.merge(\n",
    "   scaled_train_impute_energy_star_df, left_index=True, right_index=True,\n",
    "   how=\"left\" \n",
    ")\n",
    "\n",
    "test_impute_energy_star_merged_df = test_impute_energy_star_processed_categorical_df.merge(\n",
    "   scaled_test_impute_energy_star_df, left_index=True, right_index=True,\n",
    "   how=\"left\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BlMFI8E6U1RP",
    "outputId": "701c328e-d853-4117-d3b6-8b109871bc80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75757, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"train_impute_energy_star_merged_df.shape\";\n",
       "                var nbb_formatted_code = \"train_impute_energy_star_merged_df.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_impute_energy_star_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "l1zpqQ8vUzBu",
    "outputId": "f3fd69aa-501f-47f2-cba2-0155aafdc777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 1 components\n",
      "0.35658576032912437\n",
      "Fitting PCA with 2 components\n",
      "0.5933198019960959\n",
      "Fitting PCA with 3 components\n",
      "0.7206991605976221\n",
      "Fitting PCA with 4 components\n",
      "0.8136952019723978\n",
      "Fitting PCA with 5 components\n",
      "0.813695201972416\n",
      "Fitting PCA with 6 components\n",
      "0.8136952019724146\n",
      "Fitting PCA with 7 components\n",
      "0.8136952019724111\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Find the optimal PCA for energy star imputation\\n# 4 can already explain 81% varience \\nfor n_component in range(1, 8):\\n    pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=n_component)\\n    scaled_train_impute_energy_star_w_pca = pca.transform(train_impute_energy_star_merged_df)\\n    scaled_test_impute_energy_star_w_pca = pca.transform(test_impute_energy_star_merged_df)\\n    print(sum(pca.explained_variance_ratio_[:4]))\";\n",
       "                var nbb_formatted_code = \"# Find the optimal PCA for energy star imputation\\n# 4 can already explain 81% varience\\nfor n_component in range(1, 8):\\n    pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=n_component)\\n    scaled_train_impute_energy_star_w_pca = pca.transform(\\n        train_impute_energy_star_merged_df\\n    )\\n    scaled_test_impute_energy_star_w_pca = pca.transform(\\n        test_impute_energy_star_merged_df\\n    )\\n    print(sum(pca.explained_variance_ratio_[:4]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the optimal PCA for energy star imputation\n",
    "# 4 can already explain 81% varience\n",
    "for n_component in range(1, 8):\n",
    "    pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=n_component)\n",
    "    scaled_train_impute_energy_star_w_pca = pca.transform(\n",
    "        train_impute_energy_star_merged_df\n",
    "    )\n",
    "    scaled_test_impute_energy_star_w_pca = pca.transform(\n",
    "        test_impute_energy_star_merged_df\n",
    "    )\n",
    "    print(sum(pca.explained_variance_ratio_[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "Uz34jCvmWNtW",
    "outputId": "77db4333-310f-49f0-8dad-48315537622f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 4 components\n",
      "0.8136952019724096\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=4)\\nscaled_train_impute_energy_star_w_pca_optimal = pca.transform(train_impute_energy_star_merged_df)\\nscaled_test_impute_energy_star_w_pca_optimal = pca.transform(test_impute_energy_star_merged_df)\\nprint(sum(pca.explained_variance_ratio_[:4]))\";\n",
       "                var nbb_formatted_code = \"pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=4)\\nscaled_train_impute_energy_star_w_pca_optimal = pca.transform(\\n    train_impute_energy_star_merged_df\\n)\\nscaled_test_impute_energy_star_w_pca_optimal = pca.transform(\\n    test_impute_energy_star_merged_df\\n)\\nprint(sum(pca.explained_variance_ratio_[:4]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = du.pca_fit(train_impute_energy_star_merged_df, n_components=4)\n",
    "scaled_train_impute_energy_star_w_pca_optimal = pca.transform(\n",
    "    train_impute_energy_star_merged_df\n",
    ")\n",
    "scaled_test_impute_energy_star_w_pca_optimal = pca.transform(\n",
    "    test_impute_energy_star_merged_df\n",
    ")\n",
    "print(sum(pca.explained_variance_ratio_[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hYk0Xp5VW-mm",
    "outputId": "f055ca9a-a4d2-47b6-c0c8-4de25ef5ad45"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"scaled_train_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_train_impute_energy_star_w_pca_optimal, columns=[\\n       f\\\"pca_{i}\\\" for i in range(scaled_train_impute_energy_star_w_pca_optimal.shape[1])\\n    ]\\n)\\n\\nscaled_test_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_test_impute_energy_star_w_pca_optimal, columns=[\\n       f\\\"pca_{i}\\\" for i in range(scaled_test_impute_energy_star_w_pca_optimal.shape[1])\\n    ]\\n)\\n\\n# Add back original energy star rating\\nscaled_train_w_original_energy_star_df = scaled_train_impute_energy_star_w_pca_optimal_df.merge(\\n    train_impute_energy_star_df[\\\"energy_star_rating\\\"], how=\\\"left\\\", left_index=True,\\n    right_index=True\\n)\\nscaled_test_w_original_energy_star_df = scaled_test_impute_energy_star_w_pca_optimal_df.merge(\\n    test_impute_energy_star_df[\\\"energy_star_rating\\\"], how=\\\"left\\\", left_index=True,\\n    right_index=True\\n)\";\n",
       "                var nbb_formatted_code = \"scaled_train_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_train_impute_energy_star_w_pca_optimal,\\n    columns=[\\n        f\\\"pca_{i}\\\"\\n        for i in range(scaled_train_impute_energy_star_w_pca_optimal.shape[1])\\n    ],\\n)\\n\\nscaled_test_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\\n    scaled_test_impute_energy_star_w_pca_optimal,\\n    columns=[\\n        f\\\"pca_{i}\\\" for i in range(scaled_test_impute_energy_star_w_pca_optimal.shape[1])\\n    ],\\n)\\n\\n# Add back original energy star rating\\nscaled_train_w_original_energy_star_df = (\\n    scaled_train_impute_energy_star_w_pca_optimal_df.merge(\\n        train_impute_energy_star_df[\\\"energy_star_rating\\\"],\\n        how=\\\"left\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n)\\nscaled_test_w_original_energy_star_df = (\\n    scaled_test_impute_energy_star_w_pca_optimal_df.merge(\\n        test_impute_energy_star_df[\\\"energy_star_rating\\\"],\\n        how=\\\"left\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_train_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\n",
    "    scaled_train_impute_energy_star_w_pca_optimal,\n",
    "    columns=[\n",
    "        f\"pca_{i}\"\n",
    "        for i in range(scaled_train_impute_energy_star_w_pca_optimal.shape[1])\n",
    "    ],\n",
    ")\n",
    "\n",
    "scaled_test_impute_energy_star_w_pca_optimal_df = pd.DataFrame(\n",
    "    scaled_test_impute_energy_star_w_pca_optimal,\n",
    "    columns=[\n",
    "        f\"pca_{i}\" for i in range(scaled_test_impute_energy_star_w_pca_optimal.shape[1])\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Add back original energy star rating\n",
    "scaled_train_w_original_energy_star_df = (\n",
    "    scaled_train_impute_energy_star_w_pca_optimal_df.merge(\n",
    "        train_impute_energy_star_df[\"energy_star_rating\"],\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    ")\n",
    "scaled_test_w_original_energy_star_df = (\n",
    "    scaled_test_impute_energy_star_w_pca_optimal_df.merge(\n",
    "        test_impute_energy_star_df[\"energy_star_rating\"],\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "KYT6mRUe-Gjj",
    "outputId": "1014dfc2-7d40-4b44-fe6c-2768d8e6e76d"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Get backfilled energy star rating using scikit-learn iterative imputer based on \\n# other features\\nrandom_state = 42\\nmax_iter = 10\\nimp = IterativeImputer(max_iter=max_iter, random_state=random_state)\\n# Fit the imputer on training\\nimp.fit(scaled_train_w_original_energy_star_df)\\n# Transform on train and test\\nscaled_train_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_train_w_original_energy_star_df),\\n    columns=scaled_train_w_original_energy_star_df.columns.tolist()\\n    )\\nscaled_test_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_test_w_original_energy_star_df),\\n    columns=scaled_test_w_original_energy_star_df.columns.tolist()\\n    )\";\n",
       "                var nbb_formatted_code = \"# Get backfilled energy star rating using scikit-learn iterative imputer based on\\n# other features\\nrandom_state = 42\\nmax_iter = 10\\nimp = IterativeImputer(max_iter=max_iter, random_state=random_state)\\n# Fit the imputer on training\\nimp.fit(scaled_train_w_original_energy_star_df)\\n# Transform on train and test\\nscaled_train_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_train_w_original_energy_star_df),\\n    columns=scaled_train_w_original_energy_star_df.columns.tolist(),\\n)\\nscaled_test_w_original_energy_star_transformed_df = pd.DataFrame(\\n    imp.transform(scaled_test_w_original_energy_star_df),\\n    columns=scaled_test_w_original_energy_star_df.columns.tolist(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get backfilled energy star rating using scikit-learn iterative imputer based on \n",
    "# other features\n",
    "random_state = 42\n",
    "max_iter = 10\n",
    "imp = IterativeImputer(max_iter=max_iter, random_state=random_state)\n",
    "# Fit the imputer on training\n",
    "imp.fit(scaled_train_w_original_energy_star_df)\n",
    "# Transform on train and test\n",
    "scaled_train_w_original_energy_star_transformed_df = pd.DataFrame(\n",
    "    imp.transform(scaled_train_w_original_energy_star_df),\n",
    "    columns=scaled_train_w_original_energy_star_df.columns.tolist()\n",
    "    )\n",
    "scaled_test_w_original_energy_star_transformed_df = pd.DataFrame(\n",
    "    imp.transform(scaled_test_w_original_energy_star_df),\n",
    "    columns=scaled_test_w_original_energy_star_df.columns.tolist()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8IEl6PPZV3u"
   },
   "source": [
    "### Add imputed energy star with other processed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "-xYOQb7QZOcl",
    "outputId": "e44909f5-9151-44ee-8cb9-5a640cc9d410"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_factor</th>\n",
       "      <th>state_factor</th>\n",
       "      <th>building_class</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>energy_star_rating</th>\n",
       "      <th>elevation</th>\n",
       "      <th>january_min_temp</th>\n",
       "      <th>january_avg_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>direction_peak_wind_speed</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>days_with_fog</th>\n",
       "      <th>site_eui</th>\n",
       "      <th>id</th>\n",
       "      <th>facility_type_parsed</th>\n",
       "      <th>direction_max_wind_speed_backfilled</th>\n",
       "      <th>backfilled_direction_max_wind_speed</th>\n",
       "      <th>categorized_direction_max_wind_speed</th>\n",
       "      <th>iter_impute_renergy_star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>61242.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.682615</td>\n",
       "      <td>0</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Warehouse_Distribution_or_Shipping_center</td>\n",
       "      <td>274000.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.500150</td>\n",
       "      <td>1</td>\n",
       "      <td>Warehouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Retail_Enclosed_mall</td>\n",
       "      <td>280025.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.693619</td>\n",
       "      <td>2</td>\n",
       "      <td>Retail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Education_Other_classroom</td>\n",
       "      <td>55325.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.406926</td>\n",
       "      <td>3</td>\n",
       "      <td>Education</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Warehouse_Nonrefrigerated</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.899395</td>\n",
       "      <td>4</td>\n",
       "      <td>Warehouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_factor state_factor building_class  \\\n",
       "0            1      State_1     Commercial   \n",
       "1            1      State_1     Commercial   \n",
       "2            1      State_1     Commercial   \n",
       "3            1      State_1     Commercial   \n",
       "4            1      State_1     Commercial   \n",
       "\n",
       "                               facility_type  floor_area  year_built  \\\n",
       "0               Grocery_store_or_food_market     61242.0      1942.0   \n",
       "1  Warehouse_Distribution_or_Shipping_center    274000.0      1955.0   \n",
       "2                       Retail_Enclosed_mall    280025.0      1951.0   \n",
       "3                  Education_Other_classroom     55325.0      1980.0   \n",
       "4                  Warehouse_Nonrefrigerated     66000.0      1985.0   \n",
       "\n",
       "   energy_star_rating  elevation  january_min_temp  january_avg_temp  ...  \\\n",
       "0                11.0        2.4                36              50.5  ...   \n",
       "1                45.0        1.8                36              50.5  ...   \n",
       "2                97.0        1.8                36              50.5  ...   \n",
       "3                46.0        1.8                36              50.5  ...   \n",
       "4               100.0        2.4                36              50.5  ...   \n",
       "\n",
       "   direction_peak_wind_speed  max_wind_speed  days_with_fog    site_eui  id  \\\n",
       "0                        1.0             1.0            NaN  248.682615   0   \n",
       "1                        NaN             1.0           12.0   26.500150   1   \n",
       "2                        NaN             1.0           12.0   24.693619   2   \n",
       "3                        NaN             1.0           12.0   48.406926   3   \n",
       "4                        1.0             1.0            NaN    3.899395   4   \n",
       "\n",
       "   facility_type_parsed  direction_max_wind_speed_backfilled  \\\n",
       "0               Grocery                                  1.0   \n",
       "1             Warehouse                                  1.0   \n",
       "2                Retail                                  1.0   \n",
       "3             Education                                  1.0   \n",
       "4             Warehouse                                  1.0   \n",
       "\n",
       "   backfilled_direction_max_wind_speed  categorized_direction_max_wind_speed  \\\n",
       "0                                  1.0                                     N   \n",
       "1                                  1.0                                     N   \n",
       "2                                  1.0                                     N   \n",
       "3                                  1.0                                     N   \n",
       "4                                  1.0                                     N   \n",
       "\n",
       "   iter_impute_renergy_star_rating  \n",
       "0                             11.0  \n",
       "1                             45.0  \n",
       "2                             97.0  \n",
       "3                             46.0  \n",
       "4                            100.0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"train_processed_df = train_w_categorized_max_wind_speed_df.merge(\\n    scaled_train_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_renergy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True, right_index=True\\n)\\ntest_processed_df = test_w_categorized_max_wind_speed_df.merge(\\n    scaled_test_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_renergy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True, right_index=True\\n)\\ntrain_processed_df.head()\";\n",
       "                var nbb_formatted_code = \"train_processed_df = train_w_categorized_max_wind_speed_df.merge(\\n    scaled_train_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_renergy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntest_processed_df = test_w_categorized_max_wind_speed_df.merge(\\n    scaled_test_w_original_energy_star_transformed_df[[\\\"energy_star_rating\\\"]].rename(\\n        columns={\\\"energy_star_rating\\\": \\\"iter_impute_renergy_star_rating\\\"}\\n    ),\\n    how=\\\"left\\\",\\n    left_index=True,\\n    right_index=True,\\n)\\ntrain_processed_df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_processed_df = train_w_categorized_max_wind_speed_df.merge(\n",
    "    scaled_train_w_original_energy_star_transformed_df[[\"energy_star_rating\"]].rename(\n",
    "        columns={\"energy_star_rating\": \"iter_impute_renergy_star_rating\"}\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "test_processed_df = test_w_categorized_max_wind_speed_df.merge(\n",
    "    scaled_test_w_original_energy_star_transformed_df[[\"energy_star_rating\"]].rename(\n",
    "        columns={\"energy_star_rating\": \"iter_impute_renergy_star_rating\"}\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "train_processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "h1yW31p0ZOr6",
    "outputId": "947fb976-c892-45c4-9cfa-188f07970e7d"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"seed = 0\\ndepth = 12\\n\\nmodel_dict = {\\n    \\\"catboost\\\": cb.CatBoostRegressor(\\n                loss_function=\\\"RMSE\\\",\\n                depth=depth,\\n                random_seed=seed,\\n                verbose=False,\\n                nan_mode=\\\"Min\\\",\\n            ),\\n    \\\"xgboost\\\": xgb.XGBRegressor(\\n        eval_metric= 'rmse', \\n        seed = seed, max_depth=3, n_estimators=100, \\n        booster='gbtree', n_jobs=-1,\\n        random_state=0, learning_rate=0.1)\\n\\n}\\n\\nmodel_type_dict = {\\n    \\\"catboost\\\": \\\"catboost\\\",\\n    \\\"xgboost\\\": \\\"sklearn\\\"\\n}\\n\\nfeature_dict = {\\n        \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n        \\\"energy_star_rating\\\": \\\"iter_impute_renergy_star_rating\\\", \\n        \\\"facility_type\\\": \\\"facility_type_parsed\\\",\\n        # \\\"direction_max_wind_speed\\\": \\\"categorized_direction_max_wind_speed\\\"\\n        },\\n\\n        \\\"drop_data\\\": {},\\n        \\\"resample_param_dict\\\": {\\\"up_or_downsample\\\": \\\"upsample\\\", \\n                                \\\"resample_by_col\\\": \\\"state_factor\\\", \\n                                \\\"resample_type\\\": \\\"smote\\\"}\\n    }}\\n\\nmodel_configs_to_run =[\\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost\\\"]\";\n",
       "                var nbb_formatted_code = \"seed = 0\\ndepth = 12\\n\\nmodel_dict = {\\n    \\\"catboost\\\": cb.CatBoostRegressor(\\n        loss_function=\\\"RMSE\\\",\\n        depth=depth,\\n        random_seed=seed,\\n        verbose=False,\\n        nan_mode=\\\"Min\\\",\\n    ),\\n    \\\"xgboost\\\": xgb.XGBRegressor(\\n        eval_metric=\\\"rmse\\\",\\n        seed=seed,\\n        max_depth=3,\\n        n_estimators=100,\\n        booster=\\\"gbtree\\\",\\n        n_jobs=-1,\\n        random_state=0,\\n        learning_rate=0.1,\\n    ),\\n}\\n\\nmodel_type_dict = {\\\"catboost\\\": \\\"catboost\\\", \\\"xgboost\\\": \\\"sklearn\\\"}\\n\\nfeature_dict = {\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 0},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": False,\\n        \\\"model\\\": \\\"catboost\\\",\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"iter_impute_renergy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"facility_type_parsed\\\",\\n            # \\\"direction_max_wind_speed\\\": \\\"categorized_direction_max_wind_speed\\\"\\n        },\\n        \\\"drop_data\\\": {},\\n        \\\"resample_param_dict\\\": {\\n            \\\"up_or_downsample\\\": \\\"upsample\\\",\\n            \\\"resample_by_col\\\": \\\"state_factor\\\",\\n            \\\"resample_type\\\": \\\"smote\\\",\\n        },\\n    }\\n}\\n\\nmodel_configs_to_run = [\\n    \\\"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost\\\"\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 0\n",
    "depth = 12\n",
    "\n",
    "model_dict = {\n",
    "    \"catboost\": cb.CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        depth=depth,\n",
    "        random_seed=seed,\n",
    "        verbose=False,\n",
    "        nan_mode=\"Min\",\n",
    "    ),\n",
    "    \"xgboost\": xgb.XGBRegressor(\n",
    "        eval_metric=\"rmse\",\n",
    "        seed=seed,\n",
    "        max_depth=3,\n",
    "        n_estimators=100,\n",
    "        booster=\"gbtree\",\n",
    "        n_jobs=-1,\n",
    "        random_state=0,\n",
    "        learning_rate=0.1,\n",
    "    ),\n",
    "}\n",
    "\n",
    "model_type_dict = {\"catboost\": \"catboost\", \"xgboost\": \"sklearn\"}\n",
    "\n",
    "feature_dict = {\n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 0},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": False,\n",
    "        \"model\": \"catboost\",\n",
    "        \"replace_original_feature_col_dict\": {\n",
    "            \"energy_star_rating\": \"iter_impute_renergy_star_rating\",\n",
    "            \"facility_type\": \"facility_type_parsed\",\n",
    "            # \"direction_max_wind_speed\": \"categorized_direction_max_wind_speed\"\n",
    "        },\n",
    "        \"drop_data\": {},\n",
    "        \"resample_param_dict\": {\n",
    "            \"up_or_downsample\": \"upsample\",\n",
    "            \"resample_by_col\": \"state_factor\",\n",
    "            \"resample_type\": \"smote\",\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "model_configs_to_run = [\n",
    "    \"log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "0gm6uYWgbq0P",
    "outputId": "2f56bfee-c824-484e-e079-00611757280b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"train_filled_df = train_processed_df.copy()\\ntest_filled_df = test_processed_df.copy()\";\n",
       "                var nbb_formatted_code = \"train_filled_df = train_processed_df.copy()\\ntest_filled_df = test_processed_df.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_filled_df = train_processed_df.copy()\n",
    "test_filled_df = test_processed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "cHaAUxS0ZOyn",
    "outputId": "977108d8-f7db-45bb-fca6-507765ff1244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "log_temp_pca_onehot_iter_impute_star_parse_upsamplesmote_catboost ['days_above_90f', 'days_below_10f', 'max_wind_speed', 'days_above_110f', 'snowdepth_inches', 'direction_max_wind_speed', 'days_below_30f', 'state_factor', 'precipitation_inches', 'elevation', 'cooling_degree_days', 'snowfall_inches', 'days_below_0f', 'days_above_100f', 'heating_degree_days', 'building_class', 'days_below_20f', 'year_built', 'days_above_80f', 'days_with_fog', 'direction_peak_wind_speed', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'iter_impute_renergy_star_rating', 'facility_type_parsed', 'log10_floor_area'] True\n",
      "Running catboost\n",
      "Modeling 1...\n",
      "Modeling 2...\n",
      "Modeling 3...\n",
      "Modeling 4...\n",
      "Modeling 5...\n",
      "Modeling 6...\n",
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       17.244938\n",
      "test_rmse        55.384514\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.806883</td>\n",
       "      <td>67.397333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16.424218</td>\n",
       "      <td>46.498981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.931650</td>\n",
       "      <td>60.976550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.816126</td>\n",
       "      <td>55.144646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17.109658</td>\n",
       "      <td>49.087078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>16.381093</td>\n",
       "      <td>53.202495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse\n",
       "0              1   17.806883  67.397333\n",
       "1              2   16.424218  46.498981\n",
       "2              3   17.931650  60.976550\n",
       "3              4   17.816126  55.144646\n",
       "4              5   17.109658  49.087078\n",
       "5              6   16.381093  53.202495"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data train RMSE: 26.5533038084134\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"for config_name in model_configs_to_run:\\n    # get model config\\n    cols_to_reduce_dict = feature_dict[config_name][\\\"cols_to_reduce_dict\\\"]\\n    reduce_number_dict = feature_dict[config_name][\\\"reduce_number_dict\\\"]\\n    log10_transform_cols = feature_dict[config_name][\\\"log10_transform_cols\\\"]\\n    if_one_hot = feature_dict[config_name][\\\"if_one_hot\\\"]\\n    if_scale = feature_dict[config_name][\\\"if_scale\\\"]\\n    replace_original_feature_col_dict = feature_dict[config_name][\\\"replace_original_feature_col_dict\\\"]\\n    resample_param_dict = feature_dict[config_name][\\\"resample_param_dict\\\"]\\n    drop_data_dict = feature_dict[config_name][\\\"drop_data\\\"]\\n    model_name = feature_dict[config_name][\\\"model\\\"]\\n    model = model_dict[model_name]\\n    # check if need to drop data\\n    if len(drop_data_dict) > 0:\\n        for one_col, drop_level_list in drop_data_dict.items():\\n            train_filled_df = train_filled_df.query(f\\\"{one_col} not in {drop_level_list}\\\")\\n    # process data\\n    train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\\n        train_filled_df.drop_duplicates(),\\n        test_filled_df.drop_duplicates(),\\n        reduce_col_dict = cols_to_reduce_dict,\\n        cols_to_log_transform = log10_transform_cols,\\n        reduce_number_dict = reduce_number_dict,\\n    )\\n    # Set feature columns after data transformations\\n    all_cols_to_reduce = []\\n    for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\\n        all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\\n\\n    all_cols_to_drop = []\\n    all_cols_to_replace_from_drop = []\\n    for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\\n        all_cols_to_drop.append(col_to_drop)\\n        all_cols_to_replace_from_drop.append(col_to_replace)\\n\\n    features_columns = (\\n        list(set(gv.all_feature_columns) - set(all_cols_to_reduce) - set(log10_transform_cols) - set(all_cols_to_drop))\\n        + pca_cols\\n        + all_cols_to_replace_from_drop\\n        + [f\\\"log10_{col}\\\" for col in log10_transform_cols]\\n    )\\n    print(config_name, features_columns, if_one_hot)\\n\\n    # run model\\n    ## Run LOY model\\n    model_rmse = mu.run_leave_year_out(\\n        model_df=train_filter_df,\\n        ml_model=model,\\n        features_columns=features_columns,\\n        if_scale_data=if_scale,\\n        if_one_hot=if_one_hot,\\n        model_type=model_type_dict[model_name],\\n        resample_param_dict = resample_param_dict\\n    )\\n    print(f\\\"Average RMSE:\\\\n{model_rmse.mean()}\\\")\\n    display(model_rmse)\\n\\n    ## predict on test data\\n    if len(resample_param_dict) > 0:\\n        train_for_resample_df = train_filter_df\\n        resample_by_col = resample_param_dict[\\\"resample_by_col\\\"]\\n        resample_type = resample_param_dict[\\\"resample_type\\\"]\\n        if resample_param_dict[\\\"up_or_downsample\\\"] == \\\"upsample\\\":\\n            train_filter_x_df = mu.upsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n        elif resample_param_dict[\\\"up_or_downsample\\\"] == \\\"downsample\\\":\\n            train_filter_x_df = mu.downsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n        \\n    train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\\n        train_filter_df, features_columns\\n    )\\n    test_filter_x_df = mu.split_model_feature_response(\\n        test_filter_df, features_columns, if_with_response=False\\n    )\\n    processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\\n        train_filter_x_df, test_filter_x_df, if_scale, if_one_hot, full_data_df = train_filter_x_df\\n    )\\n    run_model_dict = {\\\"xgboost\\\": mu.run_sklearn_model, \\\"catboost\\\": mu.run_catboost_model}\\n    train_predict, test_predict, fitted_model = run_model_dict[model_name](\\n            model, processed_train_x_df, train_filter_y_df, processed_test_x_df\\n        )\\n    training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\\n    print(f\\\"Whole data train RMSE: {training_rmse}\\\")\";\n",
       "                var nbb_formatted_code = \"for config_name in model_configs_to_run:\\n    # get model config\\n    cols_to_reduce_dict = feature_dict[config_name][\\\"cols_to_reduce_dict\\\"]\\n    reduce_number_dict = feature_dict[config_name][\\\"reduce_number_dict\\\"]\\n    log10_transform_cols = feature_dict[config_name][\\\"log10_transform_cols\\\"]\\n    if_one_hot = feature_dict[config_name][\\\"if_one_hot\\\"]\\n    if_scale = feature_dict[config_name][\\\"if_scale\\\"]\\n    replace_original_feature_col_dict = feature_dict[config_name][\\n        \\\"replace_original_feature_col_dict\\\"\\n    ]\\n    resample_param_dict = feature_dict[config_name][\\\"resample_param_dict\\\"]\\n    drop_data_dict = feature_dict[config_name][\\\"drop_data\\\"]\\n    model_name = feature_dict[config_name][\\\"model\\\"]\\n    model = model_dict[model_name]\\n    # check if need to drop data\\n    if len(drop_data_dict) > 0:\\n        for one_col, drop_level_list in drop_data_dict.items():\\n            train_filled_df = train_filled_df.query(\\n                f\\\"{one_col} not in {drop_level_list}\\\"\\n            )\\n    # process data\\n    train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\\n        train_filled_df.drop_duplicates(),\\n        test_filled_df.drop_duplicates(),\\n        reduce_col_dict=cols_to_reduce_dict,\\n        cols_to_log_transform=log10_transform_cols,\\n        reduce_number_dict=reduce_number_dict,\\n    )\\n    # Set feature columns after data transformations\\n    all_cols_to_reduce = []\\n    for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\\n        all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\\n\\n    all_cols_to_drop = []\\n    all_cols_to_replace_from_drop = []\\n    for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\\n        all_cols_to_drop.append(col_to_drop)\\n        all_cols_to_replace_from_drop.append(col_to_replace)\\n\\n    features_columns = (\\n        list(\\n            set(gv.all_feature_columns)\\n            - set(all_cols_to_reduce)\\n            - set(log10_transform_cols)\\n            - set(all_cols_to_drop)\\n        )\\n        + pca_cols\\n        + all_cols_to_replace_from_drop\\n        + [f\\\"log10_{col}\\\" for col in log10_transform_cols]\\n    )\\n    print(config_name, features_columns, if_one_hot)\\n\\n    # run model\\n    ## Run LOY model\\n    model_rmse = mu.run_leave_year_out(\\n        model_df=train_filter_df,\\n        ml_model=model,\\n        features_columns=features_columns,\\n        if_scale_data=if_scale,\\n        if_one_hot=if_one_hot,\\n        model_type=model_type_dict[model_name],\\n        resample_param_dict=resample_param_dict,\\n    )\\n    print(f\\\"Average RMSE:\\\\n{model_rmse.mean()}\\\")\\n    display(model_rmse)\\n\\n    ## predict on test data\\n    if len(resample_param_dict) > 0:\\n        train_for_resample_df = train_filter_df\\n        resample_by_col = resample_param_dict[\\\"resample_by_col\\\"]\\n        resample_type = resample_param_dict[\\\"resample_type\\\"]\\n        if resample_param_dict[\\\"up_or_downsample\\\"] == \\\"upsample\\\":\\n            train_filter_x_df = mu.upsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n        elif resample_param_dict[\\\"up_or_downsample\\\"] == \\\"downsample\\\":\\n            train_filter_x_df = mu.downsampling_by_column(\\n                train_for_resample_df, resample_by_col, resample_type=resample_type\\n            )\\n\\n    train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\\n        train_filter_df, features_columns\\n    )\\n    test_filter_x_df = mu.split_model_feature_response(\\n        test_filter_df, features_columns, if_with_response=False\\n    )\\n    processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\\n        train_filter_x_df,\\n        test_filter_x_df,\\n        if_scale,\\n        if_one_hot,\\n        full_data_df=train_filter_x_df,\\n    )\\n    run_model_dict = {\\n        \\\"xgboost\\\": mu.run_sklearn_model,\\n        \\\"catboost\\\": mu.run_catboost_model,\\n    }\\n    train_predict, test_predict, fitted_model = run_model_dict[model_name](\\n        model, processed_train_x_df, train_filter_y_df, processed_test_x_df\\n    )\\n    training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\\n    print(f\\\"Whole data train RMSE: {training_rmse}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for config_name in model_configs_to_run:\n",
    "    # get model config\n",
    "    cols_to_reduce_dict = feature_dict[config_name][\"cols_to_reduce_dict\"]\n",
    "    reduce_number_dict = feature_dict[config_name][\"reduce_number_dict\"]\n",
    "    log10_transform_cols = feature_dict[config_name][\"log10_transform_cols\"]\n",
    "    if_one_hot = feature_dict[config_name][\"if_one_hot\"]\n",
    "    if_scale = feature_dict[config_name][\"if_scale\"]\n",
    "    replace_original_feature_col_dict = feature_dict[config_name][\n",
    "        \"replace_original_feature_col_dict\"\n",
    "    ]\n",
    "    resample_param_dict = feature_dict[config_name][\"resample_param_dict\"]\n",
    "    drop_data_dict = feature_dict[config_name][\"drop_data\"]\n",
    "    model_name = feature_dict[config_name][\"model\"]\n",
    "    model = model_dict[model_name]\n",
    "    # check if need to drop data\n",
    "    if len(drop_data_dict) > 0:\n",
    "        for one_col, drop_level_list in drop_data_dict.items():\n",
    "            train_filled_df = train_filled_df.query(\n",
    "                f\"{one_col} not in {drop_level_list}\"\n",
    "            )\n",
    "    # process data\n",
    "    train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\n",
    "        train_filled_df.drop_duplicates(),\n",
    "        test_filled_df.drop_duplicates(),\n",
    "        reduce_col_dict=cols_to_reduce_dict,\n",
    "        cols_to_log_transform=log10_transform_cols,\n",
    "        reduce_number_dict=reduce_number_dict,\n",
    "    )\n",
    "    # Set feature columns after data transformations\n",
    "    all_cols_to_reduce = []\n",
    "    for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\n",
    "        all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\n",
    "\n",
    "    all_cols_to_drop = []\n",
    "    all_cols_to_replace_from_drop = []\n",
    "    for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\n",
    "        all_cols_to_drop.append(col_to_drop)\n",
    "        all_cols_to_replace_from_drop.append(col_to_replace)\n",
    "\n",
    "    features_columns = (\n",
    "        list(\n",
    "            set(gv.all_feature_columns)\n",
    "            - set(all_cols_to_reduce)\n",
    "            - set(log10_transform_cols)\n",
    "            - set(all_cols_to_drop)\n",
    "        )\n",
    "        + pca_cols\n",
    "        + all_cols_to_replace_from_drop\n",
    "        + [f\"log10_{col}\" for col in log10_transform_cols]\n",
    "    )\n",
    "    print(config_name, features_columns, if_one_hot)\n",
    "\n",
    "    # run model\n",
    "    ## Run LOY model\n",
    "    model_rmse = mu.run_leave_year_out(\n",
    "        model_df=train_filter_df,\n",
    "        ml_model=model,\n",
    "        features_columns=features_columns,\n",
    "        if_scale_data=if_scale,\n",
    "        if_one_hot=if_one_hot,\n",
    "        model_type=model_type_dict[model_name],\n",
    "        resample_param_dict=resample_param_dict,\n",
    "    )\n",
    "    print(f\"Average RMSE:\\n{model_rmse.mean()}\")\n",
    "    display(model_rmse)\n",
    "\n",
    "    ## predict on test data\n",
    "    if len(resample_param_dict) > 0:\n",
    "        train_for_resample_df = train_filter_df\n",
    "        resample_by_col = resample_param_dict[\"resample_by_col\"]\n",
    "        resample_type = resample_param_dict[\"resample_type\"]\n",
    "        if resample_param_dict[\"up_or_downsample\"] == \"upsample\":\n",
    "            train_filter_x_df = mu.upsampling_by_column(\n",
    "                train_for_resample_df, resample_by_col, resample_type=resample_type\n",
    "            )\n",
    "        elif resample_param_dict[\"up_or_downsample\"] == \"downsample\":\n",
    "            train_filter_x_df = mu.downsampling_by_column(\n",
    "                train_for_resample_df, resample_by_col, resample_type=resample_type\n",
    "            )\n",
    "\n",
    "    train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\n",
    "        train_filter_df, features_columns\n",
    "    )\n",
    "    test_filter_x_df = mu.split_model_feature_response(\n",
    "        test_filter_df, features_columns, if_with_response=False\n",
    "    )\n",
    "    processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\n",
    "        train_filter_x_df,\n",
    "        test_filter_x_df,\n",
    "        if_scale,\n",
    "        if_one_hot,\n",
    "        full_data_df=train_filter_x_df,\n",
    "    )\n",
    "    run_model_dict = {\n",
    "        \"xgboost\": mu.run_sklearn_model,\n",
    "        \"catboost\": mu.run_catboost_model,\n",
    "    }\n",
    "    train_predict, test_predict, fitted_model = run_model_dict[model_name](\n",
    "        model, processed_train_x_df, train_filter_y_df, processed_test_x_df\n",
    "    )\n",
    "    training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\n",
    "    print(f\"Whole data train RMSE: {training_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "SSK0qcFtbjNW",
    "outputId": "d74d34a2-e83c-4219-efab-1ee7e0f98f14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.806883</td>\n",
       "      <td>67.397333</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.424218</td>\n",
       "      <td>46.498981</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>17.931650</td>\n",
       "      <td>60.976550</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>17.816126</td>\n",
       "      <td>55.144646</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.109658</td>\n",
       "      <td>49.087078</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>16.381093</td>\n",
       "      <td>53.202495</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26.553304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   17.806883  67.397333         loyo\n",
       "1            2.0   16.424218  46.498981         loyo\n",
       "2            3.0   17.931650  60.976550         loyo\n",
       "3            4.0   17.816126  55.144646         loyo\n",
       "4            5.0   17.109658  49.087078         loyo\n",
       "5            6.0   16.381093  53.202495         loyo\n",
       "6            0.0   26.553304        NaN  whole train\n",
       "7            NaN         NaN        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE:\n",
      "left_out_year     3.500000\n",
      "train_rmse       17.244938\n",
      "test_rmse        55.384514\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_out_year</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.806883</td>\n",
       "      <td>67.397333</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.424218</td>\n",
       "      <td>46.498981</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>17.931650</td>\n",
       "      <td>60.976550</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>17.816126</td>\n",
       "      <td>55.144646</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.109658</td>\n",
       "      <td>49.087078</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>16.381093</td>\n",
       "      <td>53.202495</td>\n",
       "      <td>loyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26.553304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_out_year  train_rmse  test_rmse       method\n",
       "0            1.0   17.806883  67.397333         loyo\n",
       "1            2.0   16.424218  46.498981         loyo\n",
       "2            3.0   17.931650  60.976550         loyo\n",
       "3            4.0   17.816126  55.144646         loyo\n",
       "4            5.0   17.109658  49.087078         loyo\n",
       "5            6.0   16.381093  53.202495         loyo\n",
       "6            0.0   26.553304        NaN  whole train\n",
       "7            NaN         NaN        NaN  whole train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/opt/miniconda3/envs/ds_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\\nmodel_rmse[\\\"method\\\"] = model_rmse[\\\"left_out_year\\\"].apply(\\n    lambda x: \\\"loyo\\\" if x > 0 else \\\"whole train\\\"\\n)\\ndisplay(model_rmse)\\n# model_rmse.to_csv(f\\\"{wids_path}prediction_result/meng/{config_name}.csv\\\", index=False)\\n\\nprint(f\\\"Average RMSE:\\\\n{model_rmse.query('left_out_year != 0').mean()}\\\")\\ndisplay(model_rmse)\\n\\ntest_prediction_result = test_df[[\\\"id\\\"]]\\ntest_prediction_result[\\\"site_eui\\\"] = test_predict\\ntest_prediction_result.to_csv(\\n    f\\\"{wids_path}prediction_result/meng/{config_name}.csv\\\", index=False\\n)\\n\\n# if model_name == \\\"catboost\\\":\\n#     viz.plot_catboost_feature_importance(model)\\n#     plt.savefig(\\n#         f\\\"{wids_path}/validation_result/hannah/{config_name}_feature_importance.png\\\"\\n#     )\\n#     plt.close()\\n# elif model_name == \\\"xgboost\\\":\\n#     fig, ax = plt.subplots(figsize=(15, 20))\\n#     xgb.plot_importance(fitted_model, ax=ax)\\n#     plt.savefig(\\n#         f\\\"{wids_path}/validation_result/hannah/{config_name}_feature_importance.png\\\"\\n#     )\\n#     plt.close()\\n\\n\\n# rmse_df = du.get_rmse_by_group(\\n#     train_filter_x_df.rename(\\n#         columns={\\\"backfilled_energy_star_rating\\\": \\\"energy_star_rating\\\", \\\"backfilled_energy_star_rating_v1\\\": \\\"energy_star_rating\\\", \\\"facility_type_parsed\\\": \\\"facility_type\\\"}\\n#     ),\\n#     train_filter_y_df,\\n#     train_predict,\\n# )\\n# viz.plot_rmse_by_group(rmse_df)\\n# plt.savefig(\\n#     f\\\"{wids_path}/validation_result/hannah/{config_name}_rmse_by_group.png\\\"\\n# )\\n# plt.close()\";\n",
       "                var nbb_formatted_code = \"# model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\\nmodel_rmse[\\\"method\\\"] = model_rmse[\\\"left_out_year\\\"].apply(\\n    lambda x: \\\"loyo\\\" if x > 0 else \\\"whole train\\\"\\n)\\ndisplay(model_rmse)\\n# model_rmse.to_csv(f\\\"{wids_path}prediction_result/meng/{config_name}.csv\\\", index=False)\\n\\nprint(f\\\"Average RMSE:\\\\n{model_rmse.query('left_out_year != 0').mean()}\\\")\\ndisplay(model_rmse)\\n\\ntest_prediction_result = test_df[[\\\"id\\\"]]\\ntest_prediction_result[\\\"site_eui\\\"] = test_predict\\ntest_prediction_result.to_csv(\\n    f\\\"{wids_path}prediction_result/meng/{config_name}.csv\\\", index=False\\n)\\n\\n# if model_name == \\\"catboost\\\":\\n#     viz.plot_catboost_feature_importance(model)\\n#     plt.savefig(\\n#         f\\\"{wids_path}/validation_result/hannah/{config_name}_feature_importance.png\\\"\\n#     )\\n#     plt.close()\\n# elif model_name == \\\"xgboost\\\":\\n#     fig, ax = plt.subplots(figsize=(15, 20))\\n#     xgb.plot_importance(fitted_model, ax=ax)\\n#     plt.savefig(\\n#         f\\\"{wids_path}/validation_result/hannah/{config_name}_feature_importance.png\\\"\\n#     )\\n#     plt.close()\\n\\n\\n# rmse_df = du.get_rmse_by_group(\\n#     train_filter_x_df.rename(\\n#         columns={\\\"backfilled_energy_star_rating\\\": \\\"energy_star_rating\\\", \\\"backfilled_energy_star_rating_v1\\\": \\\"energy_star_rating\\\", \\\"facility_type_parsed\\\": \\\"facility_type\\\"}\\n#     ),\\n#     train_filter_y_df,\\n#     train_predict,\\n# )\\n# viz.plot_rmse_by_group(rmse_df)\\n# plt.savefig(\\n#     f\\\"{wids_path}/validation_result/hannah/{config_name}_rmse_by_group.png\\\"\\n# )\\n# plt.close()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\n",
    "model_rmse[\"method\"] = model_rmse[\"left_out_year\"].apply(\n",
    "    lambda x: \"loyo\" if x > 0 else \"whole train\"\n",
    ")\n",
    "display(model_rmse)\n",
    "# model_rmse.to_csv(f\"{wids_path}prediction_result/meng/{config_name}.csv\", index=False)\n",
    "\n",
    "print(f\"Average RMSE:\\n{model_rmse.query('left_out_year != 0').mean()}\")\n",
    "display(model_rmse)\n",
    "\n",
    "test_prediction_result = test_df[[\"id\"]]\n",
    "test_prediction_result[\"site_eui\"] = test_predict\n",
    "test_prediction_result.to_csv(\n",
    "    f\"{wids_path}prediction_result/meng/{config_name}.csv\", index=False\n",
    ")\n",
    "\n",
    "# if model_name == \"catboost\":\n",
    "#     viz.plot_catboost_feature_importance(model)\n",
    "#     plt.savefig(\n",
    "#         f\"{wids_path}/validation_result/hannah/{config_name}_feature_importance.png\"\n",
    "#     )\n",
    "#     plt.close()\n",
    "# elif model_name == \"xgboost\":\n",
    "#     fig, ax = plt.subplots(figsize=(15, 20))\n",
    "#     xgb.plot_importance(fitted_model, ax=ax)\n",
    "#     plt.savefig(\n",
    "#         f\"{wids_path}/validation_result/hannah/{config_name}_feature_importance.png\"\n",
    "#     )\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "# rmse_df = du.get_rmse_by_group(\n",
    "#     train_filter_x_df.rename(\n",
    "#         columns={\"backfilled_energy_star_rating\": \"energy_star_rating\", \"backfilled_energy_star_rating_v1\": \"energy_star_rating\", \"facility_type_parsed\": \"facility_type\"}\n",
    "#     ),\n",
    "#     train_filter_y_df,\n",
    "#     train_predict,\n",
    "# )\n",
    "# viz.plot_rmse_by_group(rmse_df)\n",
    "# plt.savefig(\n",
    "#     f\"{wids_path}/validation_result/hannah/{config_name}_rmse_by_group.png\"\n",
    "# )\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_run.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
