{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"import sys\\n\\nimport pandas as pd\\nimport catboost as cb\\nimport xgboost as xgb\\nimport imblearn\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\nsys.path.append(\\\"..\\\")\\nimport global_vars as gv\\nfrom utils import model_utils as mu\\nfrom utils import data_utils as du\\nfrom utils import data_process_utils as dpu\\nfrom utils import visualize as viz\\n\\n%load_ext nb_black\";\n                var nbb_formatted_code = \"import sys\\n\\nimport pandas as pd\\nimport catboost as cb\\nimport xgboost as xgb\\nimport imblearn\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\nsys.path.append(\\\"..\\\")\\nimport global_vars as gv\\nfrom utils import model_utils as mu\\nfrom utils import data_utils as du\\nfrom utils import data_process_utils as dpu\\nfrom utils import visualize as viz\\n\\n%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import global_vars as gv\n",
    "from utils import model_utils as mu\n",
    "from utils import data_utils as du\n",
    "from utils import data_process_utils as dpu\n",
    "from utils import visualize as viz\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.model_utils' from '../utils/model_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"import importlib\\nimportlib.reload(gv)\\nimportlib.reload(du)\\nimportlib.reload(mu)\";\n                var nbb_formatted_code = \"import importlib\\n\\nimportlib.reload(gv)\\nimportlib.reload(du)\\nimportlib.reload(mu)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gv)\n",
    "importlib.reload(du)\n",
    "importlib.reload(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dimension: (9705, 63)\n",
      "Train dimension: (75757, 64)\n",
      "Sample solution dimension: (9705, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"#### read in data\\nwids_path = \\\"..\\\"\\ntest_df = pd.read_csv(\\\"../data/test.csv\\\")\\nprint(f\\\"Test dimension: {test_df.shape}\\\")\\ntrain_df = pd.read_csv(\\\"../data/train.csv\\\")\\nprint(f\\\"Train dimension: {train_df.shape}\\\")\\nsample_solution_df = pd.read_csv(\\\"../data/sample_solution.csv\\\")\\nprint(f\\\"Sample solution dimension: {sample_solution_df.shape}\\\")\\ntrain_df.columns = train_df.columns.str.lower()\\ntest_df.columns = test_df.columns.str.lower()\";\n                var nbb_formatted_code = \"#### read in data\\nwids_path = \\\"..\\\"\\ntest_df = pd.read_csv(\\\"../data/test.csv\\\")\\nprint(f\\\"Test dimension: {test_df.shape}\\\")\\ntrain_df = pd.read_csv(\\\"../data/train.csv\\\")\\nprint(f\\\"Train dimension: {train_df.shape}\\\")\\nsample_solution_df = pd.read_csv(\\\"../data/sample_solution.csv\\\")\\nprint(f\\\"Sample solution dimension: {sample_solution_df.shape}\\\")\\ntrain_df.columns = train_df.columns.str.lower()\\ntest_df.columns = test_df.columns.str.lower()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### read in data\n",
    "wids_path = \"..\"\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "print(f\"Test dimension: {test_df.shape}\")\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"Train dimension: {train_df.shape}\")\n",
    "sample_solution_df = pd.read_csv(\"../data/sample_solution.csv\")\n",
    "print(f\"Sample solution dimension: {sample_solution_df.shape}\")\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "test_df.columns = test_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add backfilled, processed columns in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"train_w_parsed_facility_type_df = dpu.parse_facility_type(\\n        input_df=train_df.copy(),\\n        facility_type_colname=\\\"facility_type\\\")\\ntest_w_parsed_facility_type_df = dpu.parse_facility_type(\\n        input_df=test_df.copy(),\\n        facility_type_colname=\\\"facility_type\\\")\";\n                var nbb_formatted_code = \"train_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=train_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\\ntest_w_parsed_facility_type_df = dpu.parse_facility_type(\\n    input_df=test_df.copy(), facility_type_colname=\\\"facility_type\\\"\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
    "        input_df=train_df.copy(),\n",
    "        facility_type_colname=\"facility_type\")\n",
    "test_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
    "        input_df=test_df.copy(),\n",
    "        facility_type_colname=\"facility_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"groupby_list = [\\\"state_factor\\\", \\\"building_class\\\", \\\"facility_type\\\"]\\ncol = \\\"energy_star_rating\\\"\\ntrain_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\\n                input_df=train_df,\\n                mapping_df=train_df,\\n                groupby_list=groupby_list,\\n                energy_star_rating_colname=col,\\n                agg_approach_func=np.nanmedian,\\n            )\\ntest_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\\n                input_df=test_df,\\n                mapping_df=train_df,\\n                groupby_list=groupby_list,\\n                energy_star_rating_colname=col,\\n                agg_approach_func=np.nanmedian,\\n            )\";\n                var nbb_formatted_code = \"groupby_list = [\\\"state_factor\\\", \\\"building_class\\\", \\\"facility_type\\\"]\\ncol = \\\"energy_star_rating\\\"\\ntrain_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\\n    input_df=train_df,\\n    mapping_df=train_df,\\n    groupby_list=groupby_list,\\n    energy_star_rating_colname=col,\\n    agg_approach_func=np.nanmedian,\\n)\\ntest_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\\n    input_df=test_df,\\n    mapping_df=train_df,\\n    groupby_list=groupby_list,\\n    energy_star_rating_colname=col,\\n    agg_approach_func=np.nanmedian,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groupby_list = [\"state_factor\", \"building_class\", \"facility_type\"]\n",
    "col = \"energy_star_rating\"\n",
    "train_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\n",
    "                input_df=train_df,\n",
    "                mapping_df=train_df,\n",
    "                groupby_list=groupby_list,\n",
    "                energy_star_rating_colname=col,\n",
    "                agg_approach_func=np.nanmedian,\n",
    "            )\n",
    "test_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\n",
    "                input_df=test_df,\n",
    "                mapping_df=train_df,\n",
    "                groupby_list=groupby_list,\n",
    "                energy_star_rating_colname=col,\n",
    "                agg_approach_func=np.nanmedian,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"groupby_list = [\\\"state_factor\\\", \\\"building_class\\\", \\\"facility_type_parsed\\\"]\\ncol = \\\"energy_star_rating\\\"\\ntrain_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\\n                input_df=train_w_parsed_facility_type_df,\\n                mapping_df=train_w_parsed_facility_type_df,\\n                groupby_list=groupby_list,\\n                energy_star_rating_colname=col,\\n                agg_approach_func=np.nanmedian,\\n            ).rename(columns = {\\\"backfilled_energy_star_rating\\\": \\\"backfilled_energy_star_rating_v1\\\"})\\ntest_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\\n                input_df=test_w_parsed_facility_type_df,\\n                mapping_df=train_w_parsed_facility_type_df,\\n                groupby_list=groupby_list,\\n                energy_star_rating_colname=col,\\n                agg_approach_func=np.nanmedian,\\n            ).rename(columns = {\\\"backfilled_energy_star_rating\\\": \\\"backfilled_energy_star_rating_v1\\\"})\";\n                var nbb_formatted_code = \"groupby_list = [\\\"state_factor\\\", \\\"building_class\\\", \\\"facility_type_parsed\\\"]\\ncol = \\\"energy_star_rating\\\"\\ntrain_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\\n    input_df=train_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=groupby_list,\\n    energy_star_rating_colname=col,\\n    agg_approach_func=np.nanmedian,\\n).rename(columns={\\\"backfilled_energy_star_rating\\\": \\\"backfilled_energy_star_rating_v1\\\"})\\ntest_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\\n    input_df=test_w_parsed_facility_type_df,\\n    mapping_df=train_w_parsed_facility_type_df,\\n    groupby_list=groupby_list,\\n    energy_star_rating_colname=col,\\n    agg_approach_func=np.nanmedian,\\n).rename(columns={\\\"backfilled_energy_star_rating\\\": \\\"backfilled_energy_star_rating_v1\\\"})\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groupby_list = [\"state_factor\", \"building_class\", \"facility_type_parsed\"]\n",
    "col = \"energy_star_rating\"\n",
    "train_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\n",
    "                input_df=train_w_parsed_facility_type_df,\n",
    "                mapping_df=train_w_parsed_facility_type_df,\n",
    "                groupby_list=groupby_list,\n",
    "                energy_star_rating_colname=col,\n",
    "                agg_approach_func=np.nanmedian,\n",
    "            ).rename(columns = {\"backfilled_energy_star_rating\": \"backfilled_energy_star_rating_v1\"})\n",
    "test_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\n",
    "                input_df=test_w_parsed_facility_type_df,\n",
    "                mapping_df=train_w_parsed_facility_type_df,\n",
    "                groupby_list=groupby_list,\n",
    "                energy_star_rating_colname=col,\n",
    "                agg_approach_func=np.nanmedian,\n",
    "            ).rename(columns = {\"backfilled_energy_star_rating\": \"backfilled_energy_star_rating_v1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75757, 64)\n",
      "(75757, 67)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                  75757\n",
       "energy_star_rating                  49048\n",
       "backfilled_energy_star_rating       73491\n",
       "backfilled_energy_star_rating_v1    75239\n",
       "facility_type                       75757\n",
       "facility_type_parsed                75757\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# add back to train\\ntrain_filled_df = train_df.merge(\\n    train_backfill_energy_star_rating_df[[\\\"id\\\", \\\"backfilled_energy_star_rating\\\"]],\\n    on = \\\"id\\\",\\n    how = \\\"left\\\"\\n).merge(\\n    train_w_parsed_facility_type_df[[\\\"id\\\", \\\"facility_type_parsed\\\"]],\\n    on = \\\"id\\\",\\n    how = \\\"left\\\"\\n).merge(\\n    train_backfill_energy_star_rating_df_v1[[\\\"id\\\", \\\"backfilled_energy_star_rating_v1\\\"]],\\n    on = \\\"id\\\",\\n    how = \\\"left\\\"\\n)\\nprint(train_df.shape)\\nprint(train_filled_df.shape)\\ndisplay(train_filled_df[[\\\"id\\\", \\\"energy_star_rating\\\",\\\"backfilled_energy_star_rating\\\",\\\"backfilled_energy_star_rating_v1\\\",  \\\"facility_type\\\",\\\"facility_type_parsed\\\"]].notnull().sum())\\nassert train_filled_df.shape[0] == train_df.shape[0]\";\n                var nbb_formatted_code = \"# add back to train\\ntrain_filled_df = (\\n    train_df.merge(\\n        train_backfill_energy_star_rating_df[[\\\"id\\\", \\\"backfilled_energy_star_rating\\\"]],\\n        on=\\\"id\\\",\\n        how=\\\"left\\\",\\n    )\\n    .merge(\\n        train_w_parsed_facility_type_df[[\\\"id\\\", \\\"facility_type_parsed\\\"]],\\n        on=\\\"id\\\",\\n        how=\\\"left\\\",\\n    )\\n    .merge(\\n        train_backfill_energy_star_rating_df_v1[\\n            [\\\"id\\\", \\\"backfilled_energy_star_rating_v1\\\"]\\n        ],\\n        on=\\\"id\\\",\\n        how=\\\"left\\\",\\n    )\\n)\\nprint(train_df.shape)\\nprint(train_filled_df.shape)\\ndisplay(\\n    train_filled_df[\\n        [\\n            \\\"id\\\",\\n            \\\"energy_star_rating\\\",\\n            \\\"backfilled_energy_star_rating\\\",\\n            \\\"backfilled_energy_star_rating_v1\\\",\\n            \\\"facility_type\\\",\\n            \\\"facility_type_parsed\\\",\\n        ]\\n    ]\\n    .notnull()\\n    .sum()\\n)\\nassert train_filled_df.shape[0] == train_df.shape[0]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add back to train\n",
    "train_filled_df = train_df.merge(\n",
    "    train_backfill_energy_star_rating_df[[\"id\", \"backfilled_energy_star_rating\"]],\n",
    "    on = \"id\",\n",
    "    how = \"left\"\n",
    ").merge(\n",
    "    train_w_parsed_facility_type_df[[\"id\", \"facility_type_parsed\"]],\n",
    "    on = \"id\",\n",
    "    how = \"left\"\n",
    ").merge(\n",
    "    train_backfill_energy_star_rating_df_v1[[\"id\", \"backfilled_energy_star_rating_v1\"]],\n",
    "    on = \"id\",\n",
    "    how = \"left\"\n",
    ")\n",
    "print(train_df.shape)\n",
    "print(train_filled_df.shape)\n",
    "display(train_filled_df[[\"id\", \"energy_star_rating\",\"backfilled_energy_star_rating\",\"backfilled_energy_star_rating_v1\",  \"facility_type\",\"facility_type_parsed\"]].notnull().sum())\n",
    "assert train_filled_df.shape[0] == train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9705, 63)\n",
      "(9705, 66)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                  9705\n",
       "energy_star_rating                  7451\n",
       "backfilled_energy_star_rating       9153\n",
       "backfilled_energy_star_rating_v1    9546\n",
       "facility_type                       9705\n",
       "facility_type_parsed                9705\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"# add back to test\\ntest_filled_df = test_df.merge(\\n    test_backfill_energy_star_rating_df[[\\\"id\\\", \\\"backfilled_energy_star_rating\\\"]],\\n    on = \\\"id\\\",\\n    how = \\\"left\\\"\\n).merge(\\n    test_w_parsed_facility_type_df[[\\\"id\\\", \\\"facility_type_parsed\\\"]],\\n    on = \\\"id\\\",\\n    how = \\\"left\\\"\\n).merge(\\n    test_backfill_energy_star_rating_df_v1[[\\\"id\\\", \\\"backfilled_energy_star_rating_v1\\\"]],\\n    on = \\\"id\\\",\\n    how = \\\"left\\\"\\n)\\nprint(test_df.shape)\\nprint(test_filled_df.shape)\\ndisplay(test_filled_df[[\\\"id\\\", \\\"energy_star_rating\\\",\\\"backfilled_energy_star_rating\\\", \\\"backfilled_energy_star_rating_v1\\\",\\\"facility_type\\\",\\\"facility_type_parsed\\\"]].notnull().sum())\\nassert test_filled_df.shape[0] == test_df.shape[0]\";\n                var nbb_formatted_code = \"# add back to test\\ntest_filled_df = (\\n    test_df.merge(\\n        test_backfill_energy_star_rating_df[[\\\"id\\\", \\\"backfilled_energy_star_rating\\\"]],\\n        on=\\\"id\\\",\\n        how=\\\"left\\\",\\n    )\\n    .merge(\\n        test_w_parsed_facility_type_df[[\\\"id\\\", \\\"facility_type_parsed\\\"]],\\n        on=\\\"id\\\",\\n        how=\\\"left\\\",\\n    )\\n    .merge(\\n        test_backfill_energy_star_rating_df_v1[\\n            [\\\"id\\\", \\\"backfilled_energy_star_rating_v1\\\"]\\n        ],\\n        on=\\\"id\\\",\\n        how=\\\"left\\\",\\n    )\\n)\\nprint(test_df.shape)\\nprint(test_filled_df.shape)\\ndisplay(\\n    test_filled_df[\\n        [\\n            \\\"id\\\",\\n            \\\"energy_star_rating\\\",\\n            \\\"backfilled_energy_star_rating\\\",\\n            \\\"backfilled_energy_star_rating_v1\\\",\\n            \\\"facility_type\\\",\\n            \\\"facility_type_parsed\\\",\\n        ]\\n    ]\\n    .notnull()\\n    .sum()\\n)\\nassert test_filled_df.shape[0] == test_df.shape[0]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add back to test\n",
    "test_filled_df = test_df.merge(\n",
    "    test_backfill_energy_star_rating_df[[\"id\", \"backfilled_energy_star_rating\"]],\n",
    "    on = \"id\",\n",
    "    how = \"left\"\n",
    ").merge(\n",
    "    test_w_parsed_facility_type_df[[\"id\", \"facility_type_parsed\"]],\n",
    "    on = \"id\",\n",
    "    how = \"left\"\n",
    ").merge(\n",
    "    test_backfill_energy_star_rating_df_v1[[\"id\", \"backfilled_energy_star_rating_v1\"]],\n",
    "    on = \"id\",\n",
    "    how = \"left\"\n",
    ")\n",
    "print(test_df.shape)\n",
    "print(test_filled_df.shape)\n",
    "display(test_filled_df[[\"id\", \"energy_star_rating\",\"backfilled_energy_star_rating\", \"backfilled_energy_star_rating_v1\",\"facility_type\",\"facility_type_parsed\"]].notnull().sum())\n",
    "assert test_filled_df.shape[0] == test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"model_type_dict = {\\n    \\\"catboost\\\": \\\"catboost\\\",\\n    \\\"xgboost\\\": \\\"sklearn\\\"\\n}\\n\\nfeature_dict = {\\n     \\\"xgb_tune\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 9},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": True,\\n        \\\"replace_original_feature_col_dict\\\": {\\\"energy_star_rating\\\": \\\"backfilled_energy_star_rating\\\", \\\"facility_type\\\": \\\"facility_type_parsed\\\"},\\n        \\\"drop_data\\\": {}\\n    }\\n}\";\n                var nbb_formatted_code = \"model_type_dict = {\\\"catboost\\\": \\\"catboost\\\", \\\"xgboost\\\": \\\"sklearn\\\"}\\n\\nfeature_dict = {\\n    \\\"xgb_tune\\\": {\\n        \\\"cols_to_reduce_dict\\\": {\\\"temp\\\": viz.temp_col_list},\\n        \\\"reduce_number_dict\\\": {\\\"temp\\\": 9},\\n        \\\"log10_transform_cols\\\": [\\\"floor_area\\\"],\\n        \\\"if_one_hot\\\": True,\\n        \\\"if_scale\\\": True,\\n        \\\"replace_original_feature_col_dict\\\": {\\n            \\\"energy_star_rating\\\": \\\"backfilled_energy_star_rating\\\",\\n            \\\"facility_type\\\": \\\"facility_type_parsed\\\",\\n        },\\n        \\\"drop_data\\\": {},\\n    }\\n}\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type_dict = {\n",
    "    \"catboost\": \"catboost\",\n",
    "    \"xgboost\": \"sklearn\"\n",
    "}\n",
    "\n",
    "feature_dict = {\n",
    "     \"xgb_tune\": {\n",
    "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
    "        \"reduce_number_dict\": {\"temp\": 9},\n",
    "        \"log10_transform_cols\": [\"floor_area\"],\n",
    "        \"if_one_hot\": True,\n",
    "        \"if_scale\": True,\n",
    "        \"replace_original_feature_col_dict\": {\"energy_star_rating\": \"backfilled_energy_star_rating\", \"facility_type\": \"facility_type_parsed\"},\n",
    "        \"drop_data\": {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# tuning\\n# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\\n# max_depth, min_child_weight and gamma.\\n# subsample and colsample_bytree.\\nseed = 0\\neta_list = [0.1, 0.2, 0.3]\\nmax_depth_list = [3,6,9]\\nmin_child_weight_list = [1,5,10]\\ngamma_list = [0,2,6]\\nsubsample_list = [0.5,1]\\ncolsample_bytree_list = [0.5,1]\";\n                var nbb_formatted_code = \"# tuning\\n# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\\n# max_depth, min_child_weight and gamma.\\n# subsample and colsample_bytree.\\nseed = 0\\neta_list = [0.1, 0.2, 0.3]\\nmax_depth_list = [3, 6, 9]\\nmin_child_weight_list = [1, 5, 10]\\ngamma_list = [0, 2, 6]\\nsubsample_list = [0.5, 1]\\ncolsample_bytree_list = [0.5, 1]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tuning\n",
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "# max_depth, min_child_weight and gamma.\n",
    "# subsample and colsample_bytree.\n",
    "seed = 0\n",
    "eta_list = [0.1, 0.2, 0.3]\n",
    "max_depth_list = [3,6,9]\n",
    "min_child_weight_list = [1,5,10]\n",
    "gamma_list = [0,2,6]\n",
    "subsample_list = [0.5,1]\n",
    "colsample_bytree_list = [0.5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA with 9 components\n",
      "xgb_tune ['max_wind_speed', 'days_above_80f', 'days_below_20f', 'heating_degree_days', 'snowdepth_inches', 'days_below_0f', 'days_above_110f', 'days_above_100f', 'days_with_fog', 'building_class', 'days_above_90f', 'direction_peak_wind_speed', 'precipitation_inches', 'elevation', 'days_below_30f', 'direction_max_wind_speed', 'days_below_10f', 'year_built', 'cooling_degree_days', 'state_factor', 'snowfall_inches', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'backfilled_energy_star_rating', 'facility_type_parsed', 'log10_floor_area'] True\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"config_name = \\\"xgb_tune\\\"\\nmodel_name = \\\"xgboost\\\"\\n\\n# get model config\\ncols_to_reduce_dict = feature_dict[config_name][\\\"cols_to_reduce_dict\\\"]\\nreduce_number_dict = feature_dict[config_name][\\\"reduce_number_dict\\\"]\\nlog10_transform_cols = feature_dict[config_name][\\\"log10_transform_cols\\\"]\\nif_one_hot = feature_dict[config_name][\\\"if_one_hot\\\"]\\nif_scale = feature_dict[config_name][\\\"if_scale\\\"]\\nreplace_original_feature_col_dict = feature_dict[config_name][\\\"replace_original_feature_col_dict\\\"]\\ndrop_data_dict = feature_dict[config_name][\\\"drop_data\\\"]\\n\\n# check if need to drop data\\nif len(drop_data_dict) > 0:\\n    for one_col, drop_level_list in drop_data_dict.items():\\n        train_filled_df = train_filled_df.query(f\\\"{one_col} not in {drop_level_list}\\\")\\n# process data\\ntrain_filter_df, test_filter_df, pca_cols = du.process_data_v1(\\n    train_filled_df.drop_duplicates(),\\n    test_filled_df.drop_duplicates(),\\n    reduce_col_dict = cols_to_reduce_dict,\\n    cols_to_log_transform = log10_transform_cols,\\n    reduce_number_dict = reduce_number_dict,\\n)\\n# Set feature columns after data transformations\\nall_cols_to_reduce = []\\nfor _, one_set_col_to_reduce in cols_to_reduce_dict.items():\\n    all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\\n\\nall_cols_to_drop = []\\nall_cols_to_replace_from_drop = []\\nfor col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\\n    all_cols_to_drop.append(col_to_drop)\\n    all_cols_to_replace_from_drop.append(col_to_replace)\\n\\nfeatures_columns = (\\n    list(set(gv.all_feature_columns) - set(all_cols_to_reduce) - set(log10_transform_cols) - set(all_cols_to_drop))\\n    + pca_cols\\n    + all_cols_to_replace_from_drop\\n    + [f\\\"log10_{col}\\\" for col in log10_transform_cols]\\n)\\nprint(config_name, features_columns, if_one_hot)\\n\\n\\n## predict on test data\\ntrain_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\\n    train_filter_df, features_columns\\n)\\ntest_filter_x_df = mu.split_model_feature_response(\\n    test_filter_df, features_columns, if_with_response=False\\n)\\nprocessed_train_x_df, processed_test_x_df = mu.process_train_test_data(\\n    train_filter_x_df, test_filter_x_df, if_scale, if_one_hot, full_data_df = train_filter_x_df\\n)\";\n                var nbb_formatted_code = \"config_name = \\\"xgb_tune\\\"\\nmodel_name = \\\"xgboost\\\"\\n\\n# get model config\\ncols_to_reduce_dict = feature_dict[config_name][\\\"cols_to_reduce_dict\\\"]\\nreduce_number_dict = feature_dict[config_name][\\\"reduce_number_dict\\\"]\\nlog10_transform_cols = feature_dict[config_name][\\\"log10_transform_cols\\\"]\\nif_one_hot = feature_dict[config_name][\\\"if_one_hot\\\"]\\nif_scale = feature_dict[config_name][\\\"if_scale\\\"]\\nreplace_original_feature_col_dict = feature_dict[config_name][\\n    \\\"replace_original_feature_col_dict\\\"\\n]\\ndrop_data_dict = feature_dict[config_name][\\\"drop_data\\\"]\\n\\n# check if need to drop data\\nif len(drop_data_dict) > 0:\\n    for one_col, drop_level_list in drop_data_dict.items():\\n        train_filled_df = train_filled_df.query(f\\\"{one_col} not in {drop_level_list}\\\")\\n# process data\\ntrain_filter_df, test_filter_df, pca_cols = du.process_data_v1(\\n    train_filled_df.drop_duplicates(),\\n    test_filled_df.drop_duplicates(),\\n    reduce_col_dict=cols_to_reduce_dict,\\n    cols_to_log_transform=log10_transform_cols,\\n    reduce_number_dict=reduce_number_dict,\\n)\\n# Set feature columns after data transformations\\nall_cols_to_reduce = []\\nfor _, one_set_col_to_reduce in cols_to_reduce_dict.items():\\n    all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\\n\\nall_cols_to_drop = []\\nall_cols_to_replace_from_drop = []\\nfor col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\\n    all_cols_to_drop.append(col_to_drop)\\n    all_cols_to_replace_from_drop.append(col_to_replace)\\n\\nfeatures_columns = (\\n    list(\\n        set(gv.all_feature_columns)\\n        - set(all_cols_to_reduce)\\n        - set(log10_transform_cols)\\n        - set(all_cols_to_drop)\\n    )\\n    + pca_cols\\n    + all_cols_to_replace_from_drop\\n    + [f\\\"log10_{col}\\\" for col in log10_transform_cols]\\n)\\nprint(config_name, features_columns, if_one_hot)\\n\\n\\n## predict on test data\\ntrain_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\\n    train_filter_df, features_columns\\n)\\ntest_filter_x_df = mu.split_model_feature_response(\\n    test_filter_df, features_columns, if_with_response=False\\n)\\nprocessed_train_x_df, processed_test_x_df = mu.process_train_test_data(\\n    train_filter_x_df,\\n    test_filter_x_df,\\n    if_scale,\\n    if_one_hot,\\n    full_data_df=train_filter_x_df,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_name = \"xgb_tune\"\n",
    "model_name = \"xgboost\"\n",
    "\n",
    "# get model config\n",
    "cols_to_reduce_dict = feature_dict[config_name][\"cols_to_reduce_dict\"]\n",
    "reduce_number_dict = feature_dict[config_name][\"reduce_number_dict\"]\n",
    "log10_transform_cols = feature_dict[config_name][\"log10_transform_cols\"]\n",
    "if_one_hot = feature_dict[config_name][\"if_one_hot\"]\n",
    "if_scale = feature_dict[config_name][\"if_scale\"]\n",
    "replace_original_feature_col_dict = feature_dict[config_name][\"replace_original_feature_col_dict\"]\n",
    "drop_data_dict = feature_dict[config_name][\"drop_data\"]\n",
    "\n",
    "# check if need to drop data\n",
    "if len(drop_data_dict) > 0:\n",
    "    for one_col, drop_level_list in drop_data_dict.items():\n",
    "        train_filled_df = train_filled_df.query(f\"{one_col} not in {drop_level_list}\")\n",
    "# process data\n",
    "train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\n",
    "    train_filled_df.drop_duplicates(),\n",
    "    test_filled_df.drop_duplicates(),\n",
    "    reduce_col_dict = cols_to_reduce_dict,\n",
    "    cols_to_log_transform = log10_transform_cols,\n",
    "    reduce_number_dict = reduce_number_dict,\n",
    ")\n",
    "# Set feature columns after data transformations\n",
    "all_cols_to_reduce = []\n",
    "for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\n",
    "    all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\n",
    "\n",
    "all_cols_to_drop = []\n",
    "all_cols_to_replace_from_drop = []\n",
    "for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\n",
    "    all_cols_to_drop.append(col_to_drop)\n",
    "    all_cols_to_replace_from_drop.append(col_to_replace)\n",
    "\n",
    "features_columns = (\n",
    "    list(set(gv.all_feature_columns) - set(all_cols_to_reduce) - set(log10_transform_cols) - set(all_cols_to_drop))\n",
    "    + pca_cols\n",
    "    + all_cols_to_replace_from_drop\n",
    "    + [f\"log10_{col}\" for col in log10_transform_cols]\n",
    ")\n",
    "print(config_name, features_columns, if_one_hot)\n",
    "\n",
    "\n",
    "## predict on test data\n",
    "train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\n",
    "    train_filter_df, features_columns\n",
    ")\n",
    "test_filter_x_df = mu.split_model_feature_response(\n",
    "    test_filter_df, features_columns, if_with_response=False\n",
    ")\n",
    "processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\n",
    "    train_filter_x_df, test_filter_x_df, if_scale, if_one_hot, full_data_df = train_filter_x_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in eta_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        for min_child_weight in min_child_weight_list:\n",
    "            for gamma in gamma_list:\n",
    "                for subsample in subsample_list:\n",
    "                    for colsample_bytree in colsample_bytree_list:\n",
    "                        updated_config_name = f\"{config_name}_eta{eta}_max_depth{max_depth}_min_child_weight{min_child_weight}_gamma{gamma}_subsample{subsample}_colsample_bytree{colsample_bytree}\"\n",
    "                        print(updated_config_name)\n",
    "                        model = xgb.XGBRegressor(eval_metric= 'rmse', max_depth=max_depth,\n",
    "                                            random_state=seed, learning_rate=eta, min_child_weight = min_child_weight, gamma = gamma,\n",
    "                                            subsample = subsample, colsample_bytree =  colsample_bytree)\n",
    "\n",
    "                        # run model\n",
    "                        ## Run LOY model\n",
    "                        model_rmse = mu.run_leave_year_out(\n",
    "                            model_df=train_filter_df,\n",
    "                            ml_model=model,\n",
    "                            features_columns=features_columns,\n",
    "                            if_scale_data=if_scale,\n",
    "                            if_one_hot=if_one_hot,\n",
    "                            model_type=model_type_dict[model_name],\n",
    "                        )\n",
    "                        print(f\"Average RMSE:\\n{model_rmse.mean()}\")\n",
    "                        # predict on test\n",
    "                        run_model_dict = {\"xgboost\": mu.run_sklearn_model, \"catboost\": mu.run_catboost_model}\n",
    "                        train_predict, test_predict, fitted_model = run_model_dict[model_name](\n",
    "                                model, processed_train_x_df, train_filter_y_df, processed_test_x_df\n",
    "                            )\n",
    "                        training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\n",
    "                        print(f\"Whole data train RMSE: {training_rmse}\")\n",
    "\n",
    "                        ## output save result\n",
    "                        model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\n",
    "                        model_rmse[\"method\"] = model_rmse[\"left_out_year\"].apply(\n",
    "                            lambda x: \"loyo\" if x > 0 else \"whole train\"\n",
    "                        )\n",
    "                        display(model_rmse)\n",
    "                        model_rmse.to_csv(\n",
    "                            f\"{wids_path}/validation_result/hannah/{updated_config_name}.csv\", index=False\n",
    "                        )\n",
    "\n",
    "                        test_prediction_result = test_df[[\"id\"]]\n",
    "                        test_prediction_result[\"site_eui\"] = test_predict\n",
    "                        test_prediction_result.to_csv(\n",
    "                            f\"{wids_path}/prediction_result/hannah/{updated_config_name}.csv\", index=False\n",
    "                        )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c9406938a25e8996f586329557c557bc25292cb1e4f903a4d05f33f301b2f1a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('general-project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
