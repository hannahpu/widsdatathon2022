{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_run_hannah_stack_regressor_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sMSZSRi4_UUfIIzPoSHapOBR0MhrxSI-",
      "authorship_tag": "ABX9TyNiD2U6wSacWlkbFbIeqskW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannahpu/widsdatathon2022/blob/main/notebook/model_run_hannah_stack_regressor_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m1l1JOzQ7tT",
        "outputId": "3f3f505d-cd25-4ebe-fd2a-a6b93d013ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'widsdatathon2022'...\n",
            "remote: Enumerating objects: 354, done.\u001b[K\n",
            "remote: Counting objects: 100% (354/354), done.\u001b[K\n",
            "remote: Compressing objects: 100% (216/216), done.\u001b[K\n",
            "remote: Total 354 (delta 197), reused 283 (delta 136), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (354/354), 27.06 MiB | 12.50 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n"
          ]
        }
      ],
      "source": [
        "# repo: https://github.com/hannahpu/widsdatathon2022\n",
        "! git clone https://github.com/hannahpu/widsdatathon2022.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # run this line of code when there is update in git repo\n",
        "# %cd /content/widsdatathon2022\n",
        "# ! git pull"
      ],
      "metadata": {
        "id": "8YtpkJHOTrNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install xgboost\n",
        "!pip install mlxtend\n",
        "!pip install imblearn\n",
        "!pip install nb-black"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XNoBpxpjISz",
        "outputId": "40186d33-3d83-46e9-da34-98c4238b32ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.5)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (60.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.1.0)\n",
            "Requirement already satisfied: nb-black in /usr/local/lib/python3.7/dist-packages (1.0.7)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from nb-black) (5.5.0)\n",
            "Requirement already satisfied: black>='19.3' in /usr/local/lib/python3.7/dist-packages (from nb-black) (22.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (2.0.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (2.5.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (8.0.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (0.4.3)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (0.9.0)\n",
            "Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black>='19.3'->nb-black) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black>='19.3'->nb-black) (3.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (60.9.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->nb-black) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->nb-black) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->nb-black) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lightgbm gpu https://medium.com/@am.sharma/lgbm-on-colab-with-gpu-c1c09e83f2af\n",
        "# https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#build-gpu-version\n",
        "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "%cd /content/LightGBM\n",
        "!mkdir build\n",
        "!cmake -DUSE_GPU=1 #avoid ..\n",
        "!make -j$(nproc)\n",
        "!sudo apt-get -y install python-pip\n",
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
        "%cd /content/LightGBM/python-package\n",
        "!sudo python setup.py install — precompile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP6sfQUJFVY_",
        "outputId": "b35fd49a-23df-44a2-b3c1-1277388bc2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 25053, done.\u001b[K\n",
            "remote: Counting objects: 100% (729/729), done.\u001b[K\n",
            "remote: Compressing objects: 100% (402/402), done.\u001b[K\n",
            "remote: Total 25053 (delta 469), reused 520 (delta 320), pack-reused 24324\u001b[K\n",
            "Receiving objects: 100% (25053/25053), 18.65 MiB | 12.67 MiB/s, done.\n",
            "Resolving deltas: 100% (18418/18418), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
            "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
            "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
            "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/compute'...\n",
            "remote: Enumerating objects: 21733, done.        \n",
            "remote: Counting objects: 100% (5/5), done.        \n",
            "remote: Compressing objects: 100% (5/5), done.        \n",
            "remote: Total 21733 (delta 1), reused 2 (delta 0), pack-reused 21728        \n",
            "Receiving objects: 100% (21733/21733), 8.51 MiB | 14.36 MiB/s, done.\n",
            "Resolving deltas: 100% (17567/17567), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/eigen'...\n",
            "remote: Enumerating objects: 114824, done.        \n",
            "remote: Counting objects: 100% (4/4), done.        \n",
            "remote: Compressing objects: 100% (4/4), done.        \n",
            "remote: Total 114824 (delta 0), reused 1 (delta 0), pack-reused 114820        \n",
            "Receiving objects: 100% (114824/114824), 101.98 MiB | 23.90 MiB/s, done.\n",
            "Resolving deltas: 100% (94707/94707), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fast_double_parser'...\n",
            "remote: Enumerating objects: 692, done.        \n",
            "remote: Counting objects: 100% (192/192), done.        \n",
            "remote: Compressing objects: 100% (124/124), done.        \n",
            "remote: Total 692 (delta 95), reused 99 (delta 41), pack-reused 500        \n",
            "Receiving objects: 100% (692/692), 802.86 KiB | 6.75 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fmt'...\n",
            "remote: Enumerating objects: 28965, done.        \n",
            "remote: Counting objects: 100% (325/325), done.        \n",
            "remote: Compressing objects: 100% (135/135), done.        \n",
            "remote: Total 28965 (delta 197), reused 246 (delta 139), pack-reused 28640        \n",
            "Receiving objects: 100% (28965/28965), 13.81 MiB | 20.77 MiB/s, done.\n",
            "Resolving deltas: 100% (19551/19551), done.\n",
            "Submodule path 'external_libs/compute': checked out '36350b7de849300bd3d72a05d8bf890ca405a014'\n",
            "Submodule path 'external_libs/eigen': checked out '3147391d946bb4b6c68edd901f2add6ac1f31f8c'\n",
            "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
            "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
            "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
            "remote: Enumerating objects: 16275, done.        \n",
            "remote: Counting objects: 100% (401/401), done.        \n",
            "remote: Compressing objects: 100% (303/303), done.        \n",
            "remote: Total 16275 (delta 228), reused 183 (delta 98), pack-reused 15874        \n",
            "Receiving objects: 100% (16275/16275), 10.56 MiB | 18.61 MiB/s, done.\n",
            "Resolving deltas: 100% (12502/12502), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
            "remote: Enumerating objects: 1338, done.        \n",
            "remote: Counting objects: 100% (182/182), done.        \n",
            "remote: Compressing objects: 100% (140/140), done.        \n",
            "remote: Total 1338 (delta 98), reused 85 (delta 35), pack-reused 1156        \n",
            "Receiving objects: 100% (1338/1338), 7.14 MiB | 17.33 MiB/s, done.\n",
            "Resolving deltas: 100% (870/870), done.\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
            "Submodule path 'external_libs/fmt': checked out 'b6f4ceaed0a0a24ccf575fab6c56dd50ccf6f1a9'\n",
            "/content/LightGBM\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "-- Found OpenMP_C: -fopenmp  \n",
            "-- Found OpenMP_CXX: -fopenmp  \n",
            "-- Found OpenMP: TRUE   \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Using _mm_prefetch\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM\n",
            "[  2%] Built target lightgbm_capi_objs\n",
            "[ 89%] Built target lightgbm_objs\n",
            "[ 97%] Built target lightgbm\n",
            "[100%] Built target _lightgbm\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.5).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (60.9.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "/content/LightGBM/python-package\n",
            "invalid command name '—'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import catboost as cb\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor \n",
        "from mlxtend.regressor import StackingRegressor\n",
        "import imblearn\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, VotingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
        "from pandas.api.types import is_categorical_dtype\n",
        "\n",
        "wids_path = \"/content/widsdatathon2022/\"\n",
        "sys.path.append(wids_path)\n",
        "import global_vars as gv\n",
        "from utils import model_utils as mu\n",
        "from utils import data_utils as du\n",
        "from utils import data_process_utils as dpu\n",
        "from utils import visualize as viz"
      ],
      "metadata": {
        "id": "aiv9e4lcTPUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### read in data\n",
        "test_df = pd.read_csv(\"/content/widsdatathon2022/data/test.csv\")\n",
        "print(f\"Test dimension: {test_df.shape}\")\n",
        "train_df = pd.read_csv(\"/content/widsdatathon2022/data/train.csv\")\n",
        "print(f\"Train dimension: {train_df.shape}\")\n",
        "sample_solution_df = pd.read_csv(\"/content/widsdatathon2022/data/sample_solution.csv\")\n",
        "print(f\"Sample solution dimension: {sample_solution_df.shape}\")\n",
        "train_df.columns = train_df.columns.str.lower()\n",
        "test_df.columns = test_df.columns.str.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U52FxGXbj-DC",
        "outputId": "763df805-842d-4573-9fcd-a2207e99e52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dimension: (9705, 63)\n",
            "Train dimension: (75757, 64)\n",
            "Sample solution dimension: (9705, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory optimization\n",
        "\n",
        "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
        "# Modified to support timestamp type, categorical type\n",
        "# Modified to add option to use float16\n",
        "def reduce_mem_usage(data, use_float16=False) -> pd.DataFrame:\n",
        "    start_mem = data.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in data.columns:\n",
        "        if is_datetime(data[col]) or is_categorical_dtype(data[col]):\n",
        "            continue\n",
        "        col_type = data[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = data[col].min()\n",
        "            c_max = data[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    data[col] = data[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    data[col] = data[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    data[col] = data[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    data[col] = data[col].astype(np.int64)\n",
        "            else:\n",
        "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    data[col] = data[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    data[col] = data[col].astype(np.float32)\n",
        "                else:\n",
        "                    data[col] = data[col].astype(np.float64)\n",
        "        else:\n",
        "            data[col] = data[col].astype('category')\n",
        "\n",
        "    end_mem = data.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.2f}%'.format(\n",
        "        100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "0x05zCIxkB4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory optimization\n",
        "train_df = reduce_mem_usage(train_df, use_float16=True)\n",
        "test_df = reduce_mem_usage(test_df, use_float16=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPJv5QnLkMF3",
        "outputId": "21783e8d-295b-452e-df87-dad9ea68d4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage of dataframe is 36.99 MB\n",
            "Memory usage after optimization is: 7.16 MB\n",
            "Decreased by 80.66%\n",
            "Memory usage of dataframe is 4.66 MB\n",
            "Memory usage after optimization is: 0.87 MB\n",
            "Decreased by 81.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
        "        input_df=train_df.copy(),\n",
        "        facility_type_colname=\"facility_type\")\n",
        "test_w_parsed_facility_type_df = dpu.parse_facility_type(\n",
        "        input_df=test_df.copy(),\n",
        "        facility_type_colname=\"facility_type\")"
      ],
      "metadata": {
        "id": "PyB5dpqFkOTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groupby_list = [\"state_factor\", \"building_class\", \"facility_type\"]\n",
        "col = \"energy_star_rating\"\n",
        "train_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\n",
        "                input_df=train_df,\n",
        "                mapping_df=train_df,\n",
        "                groupby_list=groupby_list,\n",
        "                energy_star_rating_colname=col,\n",
        "                agg_approach_func=np.nanmedian,\n",
        "            )\n",
        "test_backfill_energy_star_rating_df = dpu.backfill_energy_star_rating(\n",
        "                input_df=test_df,\n",
        "                mapping_df=train_df,\n",
        "                groupby_list=groupby_list,\n",
        "                energy_star_rating_colname=col,\n",
        "                agg_approach_func=np.nanmedian,\n",
        "            )"
      ],
      "metadata": {
        "id": "XZ49kLGkkQq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groupby_list = [\"state_factor\", \"building_class\", \"facility_type_parsed\"]\n",
        "col = \"energy_star_rating\"\n",
        "train_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\n",
        "                input_df=train_w_parsed_facility_type_df,\n",
        "                mapping_df=train_w_parsed_facility_type_df,\n",
        "                groupby_list=groupby_list,\n",
        "                energy_star_rating_colname=col,\n",
        "                agg_approach_func=np.nanmedian,\n",
        "            ).rename(columns = {\"backfilled_energy_star_rating\": \"backfilled_energy_star_rating_v1\"})\n",
        "test_backfill_energy_star_rating_df_v1 = dpu.backfill_energy_star_rating(\n",
        "                input_df=test_w_parsed_facility_type_df,\n",
        "                mapping_df=train_w_parsed_facility_type_df,\n",
        "                groupby_list=groupby_list,\n",
        "                energy_star_rating_colname=col,\n",
        "                agg_approach_func=np.nanmedian,\n",
        "            ).rename(columns = {\"backfilled_energy_star_rating\": \"backfilled_energy_star_rating_v1\"})"
      ],
      "metadata": {
        "id": "HjtvH1LnkSiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add back to train\n",
        "train_filled_df = train_df.merge(\n",
        "    train_backfill_energy_star_rating_df[[\"id\", \"backfilled_energy_star_rating\"]],\n",
        "    on = \"id\",\n",
        "    how = \"left\"\n",
        ").merge(\n",
        "    train_w_parsed_facility_type_df[[\"id\", \"facility_type_parsed\"]],\n",
        "    on = \"id\",\n",
        "    how = \"left\"\n",
        ").merge(\n",
        "    train_backfill_energy_star_rating_df_v1[[\"id\", \"backfilled_energy_star_rating_v1\"]],\n",
        "    on = \"id\",\n",
        "    how = \"left\"\n",
        ")\n",
        "print(train_df.shape)\n",
        "print(train_filled_df.shape)\n",
        "display(train_filled_df[[\"id\", \"energy_star_rating\",\"backfilled_energy_star_rating\",\"backfilled_energy_star_rating_v1\",  \"facility_type\",\"facility_type_parsed\"]].notnull().sum())\n",
        "assert train_filled_df.shape[0] == train_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "V1D_ab3ekUxK",
        "outputId": "4f26830e-e451-428d-f386-2c716921f335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75757, 64)\n",
            "(75757, 67)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "id                                  75757\n",
              "energy_star_rating                  49048\n",
              "backfilled_energy_star_rating       73491\n",
              "backfilled_energy_star_rating_v1    75239\n",
              "facility_type                       75757\n",
              "facility_type_parsed                75757\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_filled_df = train_filled_df.assign(resample_priority = train_filled_df[\"energy_star_rating\"].notnull())\n",
        "weighted_dict = {True: 1, False: 0.5}\n",
        "train_filled_df[\"resample_weights\"] = train_filled_df[\"resample_priority\"].replace(weighted_dict)\n",
        "# train_filled_df = train_filled_df.assign(resample_weights = train_filled_df[\"resample_priority\"].astype(int))"
      ],
      "metadata": {
        "id": "WX60SKH_kXNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add back to test\n",
        "test_filled_df = test_df.merge(\n",
        "    test_backfill_energy_star_rating_df[[\"id\", \"backfilled_energy_star_rating\"]],\n",
        "    on = \"id\",\n",
        "    how = \"left\"\n",
        ").merge(\n",
        "    test_w_parsed_facility_type_df[[\"id\", \"facility_type_parsed\"]],\n",
        "    on = \"id\",\n",
        "    how = \"left\"\n",
        ").merge(\n",
        "    test_backfill_energy_star_rating_df_v1[[\"id\", \"backfilled_energy_star_rating_v1\"]],\n",
        "    on = \"id\",\n",
        "    how = \"left\"\n",
        ")\n",
        "print(test_df.shape)\n",
        "print(test_filled_df.shape)\n",
        "display(test_filled_df[[\"id\", \"energy_star_rating\",\"backfilled_energy_star_rating\", \"backfilled_energy_star_rating_v1\",\"facility_type\",\"facility_type_parsed\"]].notnull().sum())\n",
        "assert test_filled_df.shape[0] == test_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "8SYEQ4FhkZd_",
        "outputId": "b6d759e5-7b60-4334-d14a-0def5a4da31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9705, 63)\n",
            "(9705, 66)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "id                                  9705\n",
              "energy_star_rating                  7451\n",
              "backfilled_energy_star_rating       9153\n",
              "backfilled_energy_star_rating_v1    9546\n",
              "facility_type                       9705\n",
              "facility_type_parsed                9705\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qz7rihhpkcK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model config"
      ],
      "metadata": {
        "id": "VFCmp1jCkdC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat = CatBoostRegressor(\n",
        "                    iterations=3000,\n",
        "                    grow_policy='Lossguide',\n",
        "                    verbose=False,\n",
        "                    task_type='GPU',\n",
        "                    l2_leaf_reg=1,\n",
        "                    learning_rate=0.1,\n",
        "                    depth= 10,\n",
        "                )\n",
        "xgb_model = XGBRegressor(\n",
        "                    grow_policy='lossguide',\n",
        "                    tree_method='gpu_hist',\n",
        "                    n_estimators=3000,\n",
        "                    eta=0.1, \n",
        "                    max_depth= 10,\n",
        "                    reg_lambda=1 #\n",
        "                )\n",
        "lgbm_model = LGBMRegressor(\n",
        "    \n",
        "                                max_depth = 11,\n",
        "                                num_leaves = 15,\n",
        "                                learning_rate = 0.05,\n",
        "                                subsample = 0.9,\n",
        "                                colsample_bytree = 0.7,\n",
        "                    \n",
        "                    device=\"gpu\",\n",
        "                  \n",
        "                    reg_lambda=10 \n",
        "                )\n",
        "knn = KNeighborsRegressor(n_neighbors=20)\n",
        "svr = SVR(C=1.0, epsilon=0.2)\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(20,20,20),random_state=1, max_iter=500)\n",
        "lightgbm = LGBMRegressor(objective='regression', learning_rate=0.05, num_leaves=1024,\n",
        "device=\"gpu\",\n",
        "    feature_fraction=0.8, bagging_fraction=0.9, bagging_freq=5) \n",
        "\n",
        "ridge = Ridge(alpha=10)\n",
        "lasso = Lasso(alpha=0.3)"
      ],
      "metadata": {
        "id": "Spmvd5PakeXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "depth = 12\n",
        "\n",
        "model_dict = {\n",
        "    \"catboost\": cb.CatBoostRegressor(\n",
        "                loss_function=\"RMSE\",\n",
        "                depth=depth,\n",
        "                random_seed=seed,\n",
        "                verbose=False,\n",
        "                nan_mode=\"Min\",\n",
        "            ),\n",
        "    # \"stackingregressor\": StackingRegressor(regressors=(lgbm_model, cat, xgb_model, knn, ridge, svr),  #from mlx library\n",
        "    #     meta_regressor=xgb_model, use_features_in_secondary=True, verbose = 2),\n",
        "    \"stackingregressor\": StackingRegressor(regressors=(cat, xgb_model, knn, ridge, svr),  #from mlx library\n",
        "        meta_regressor=xgb_model, use_features_in_secondary=True, verbose = 2),\n",
        "    \"xgboost\": xgb.XGBRegressor(eval_metric= 'rmse', seed = seed, max_depth=11, n_estimators=1000, \n",
        "                           booster='gbtree', n_jobs=-1,num_leaves = 15,subsample = 0.9,\n",
        "                                colsample_bytree = 0.7,\n",
        "                           random_state=0, learning_rate=0.05),\n",
        "\n",
        "    \"lightgbm\": lgb.LGBMRegressor (\n",
        "                                n_estimators = 30000,\n",
        "                                max_depth = 11,\n",
        "                                num_leaves = 15,\n",
        "                                learning_rate = 0.05,\n",
        "                                subsample = 0.9,\n",
        "                                colsample_bytree = 0.7,\n",
        "                                random_state = 42 )\n",
        "\n",
        "}\n",
        "\n",
        "model_type_dict = {\n",
        "    \"catboost\": \"catboost\",\n",
        "    \"xgboost\": \"sklearn\",\n",
        "    \"lightgbm\": \"lightgbm\",\n",
        "    \"stackingregressor\": \"sklearn\"\n",
        "}\n",
        "\n",
        "feature_dict = {\n",
        "   \"log_temp_pca_onehot_impute_parse_stacking\": {\n",
        "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
        "        \"reduce_number_dict\": {\"temp\": 9},\n",
        "        \"log10_transform_cols\": [\"floor_area\"],\n",
        "        \"if_one_hot\": True,\n",
        "        \"if_scale\": False,\n",
        "        \"model\": \"stackingregressor\",\n",
        "        \"replace_original_feature_col_dict\": {\"energy_star_rating\": \"backfilled_energy_star_rating\", \"facility_type\": \"facility_type_parsed\"},\n",
        "        \"drop_data\": {},\n",
        "        \"resample_param_dict\": {}\n",
        "    },\n",
        "    \"log_temp_pca_onehot_impute_parse_upsample_stacking\": {\n",
        "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
        "        \"reduce_number_dict\": {\"temp\": 9},\n",
        "        \"log10_transform_cols\": [\"floor_area\"],\n",
        "        \"if_one_hot\": True,\n",
        "        \"if_scale\": False,\n",
        "        \"model\": \"stackingregressor\",\n",
        "        \"replace_original_feature_col_dict\": {\"energy_star_rating\": \"backfilled_energy_star_rating\", \"facility_type\": \"facility_type_parsed\"},\n",
        "        \"drop_data\": {},\n",
        "        \"resample_param_dict\": {\"up_or_downsample\": \"upsample\", \"resample_by_col\": \"state_factor\", \"resample_type\": \"random\"}\n",
        "    },\n",
        "    \"log_temp_pca_onehot_impute_parse_upsample_lightgbm\": {\n",
        "        \"cols_to_reduce_dict\": {\"temp\": viz.temp_col_list},\n",
        "        \"reduce_number_dict\": {\"temp\": 9},\n",
        "        \"log10_transform_cols\": [\"floor_area\"],\n",
        "        \"if_one_hot\": True,\n",
        "        \"if_scale\": False,\n",
        "        \"model\": \"lightgbm\",\n",
        "        \"replace_original_feature_col_dict\": {\"energy_star_rating\": \"backfilled_energy_star_rating\", \"facility_type\": \"facility_type_parsed\"},\n",
        "        \"drop_data\": {},\n",
        "        \"resample_param_dict\": {\"up_or_downsample\": \"upsample\", \"resample_by_col\": \"state_factor\", \"resample_type\": \"random\"}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "iBMr8D4akjRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs_to_run =[\"log_temp_pca_onehot_impute_parse_upsample_stacking\", \"log_temp_pca_onehot_impute_parse_stacking\"]"
      ],
      "metadata": {
        "id": "J_9-hAADknru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for config_name in model_configs_to_run:\n",
        "# config_name = \"log_temp_pca_onehot_impute_catboost\"\n",
        "    # get model config\n",
        "    cols_to_reduce_dict = feature_dict[config_name][\"cols_to_reduce_dict\"]\n",
        "    reduce_number_dict = feature_dict[config_name][\"reduce_number_dict\"]\n",
        "    log10_transform_cols = feature_dict[config_name][\"log10_transform_cols\"]\n",
        "    if_one_hot = feature_dict[config_name][\"if_one_hot\"]\n",
        "    if_scale = feature_dict[config_name][\"if_scale\"]\n",
        "    replace_original_feature_col_dict = feature_dict[config_name][\"replace_original_feature_col_dict\"]\n",
        "    resample_param_dict = feature_dict[config_name][\"resample_param_dict\"]\n",
        "    drop_data_dict = feature_dict[config_name][\"drop_data\"]\n",
        "    model_name = feature_dict[config_name][\"model\"]\n",
        "    model = model_dict[model_name]\n",
        "    # check if need to drop data\n",
        "    if len(drop_data_dict) > 0:\n",
        "        for one_col, drop_level_list in drop_data_dict.items():\n",
        "            train_filled_df = train_filled_df.query(f\"{one_col} not in {drop_level_list}\")\n",
        "    # process data\n",
        "    train_filter_df, test_filter_df, pca_cols = du.process_data_v1(\n",
        "        train_filled_df.drop_duplicates(),\n",
        "        test_filled_df.drop_duplicates(),\n",
        "        reduce_col_dict = cols_to_reduce_dict,\n",
        "        cols_to_log_transform = log10_transform_cols,\n",
        "        reduce_number_dict = reduce_number_dict,\n",
        "    )\n",
        "    # Set feature columns after data transformations\n",
        "    all_cols_to_reduce = []\n",
        "    for _, one_set_col_to_reduce in cols_to_reduce_dict.items():\n",
        "        all_cols_to_reduce = all_cols_to_reduce + one_set_col_to_reduce\n",
        "\n",
        "    all_cols_to_drop = []\n",
        "    all_cols_to_replace_from_drop = []\n",
        "    for col_to_drop, col_to_replace in replace_original_feature_col_dict.items():\n",
        "        all_cols_to_drop.append(col_to_drop)\n",
        "        all_cols_to_replace_from_drop.append(col_to_replace)\n",
        "\n",
        "    features_columns = (\n",
        "        list(set(gv.all_feature_columns) - set(all_cols_to_reduce) - set(log10_transform_cols) - set(all_cols_to_drop))\n",
        "        + pca_cols\n",
        "        + all_cols_to_replace_from_drop\n",
        "        + [f\"log10_{col}\" for col in log10_transform_cols]\n",
        "    )\n",
        "    print(config_name, model_name, features_columns, if_one_hot)\n",
        "\n",
        "    # run model\n",
        "    ## Run LOY model\n",
        "    model_rmse = mu.run_leave_year_out(\n",
        "        model_df=train_filter_df,\n",
        "        ml_model=model,\n",
        "        features_columns=features_columns,\n",
        "        if_scale_data=if_scale,\n",
        "        if_one_hot=if_one_hot,\n",
        "        model_type=model_type_dict[model_name],\n",
        "        resample_param_dict = resample_param_dict\n",
        "    )\n",
        "    print(f\"Average RMSE:\\n{model_rmse.mean()}\")\n",
        "    display(model_rmse)\n",
        "\n",
        "    ## predict on test data    \n",
        "    train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\n",
        "        train_filter_df, features_columns\n",
        "    )\n",
        "    test_filter_x_df = mu.split_model_feature_response(\n",
        "        test_filter_df, features_columns, if_with_response=False\n",
        "    )\n",
        "    if len(resample_param_dict) > 0:\n",
        "        train_for_resample_df = train_filter_x_df\n",
        "        train_for_resample_df[\"site_eui\"] = train_filter_y_df\n",
        "        resample_by_col = resample_param_dict[\"resample_by_col\"]\n",
        "        resample_type = resample_param_dict[\"resample_type\"]\n",
        "        if resample_param_dict[\"up_or_downsample\"] == \"upsample\":\n",
        "            train_after_resampled_df = mu.upsampling_by_column(\n",
        "                train_for_resample_df, resample_by_col, resample_type=resample_type\n",
        "            )\n",
        "        elif resample_param_dict[\"up_or_downsample\"] == \"downsample\":\n",
        "            train_after_resampled_df = mu.downsampling_by_column(\n",
        "                train_for_resample_df, resample_by_col, resample_type=resample_type\n",
        "            )\n",
        "        elif resample_param_dict[\"up_or_downsample\"] == \"custom_upsample\":\n",
        "            print(\"getting custom upsample\")\n",
        "            train_after_resampled_df = mu.custom_weighted_upsample(train_for_resample_df, train_filter_df, resample_by_col)\n",
        "        train_filter_x_df, train_filter_y_df = mu.split_model_feature_response(\n",
        "                    train_after_resampled_df,\n",
        "                    features_columns,\n",
        "                    if_with_response=True,\n",
        "                    response_col=\"site_eui\",\n",
        "                )\n",
        "\n",
        "    \n",
        "    processed_train_x_df, processed_test_x_df = mu.process_train_test_data(\n",
        "        train_filter_x_df, test_filter_x_df, if_scale, if_one_hot, full_data_df = pd.concat([train_filter_x_df,test_filter_x_df])\n",
        "    )\n",
        "    ##\n",
        "    # Missing data imputation\n",
        "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "    imputer.fit(processed_train_x_df)\n",
        "    processed_train_x_df = pd.DataFrame(imputer.transform(processed_train_x_df))\n",
        "    processed_test_x_df = pd.DataFrame(imputer.transform(processed_test_x_df))\n",
        "    ##\n",
        "    # run_model_dict = {\"xgboost\": mu.run_sklearn_model, \"catboost\": mu.run_catboost_model}\n",
        "    run_model_dict = {\n",
        "        \"sklearn\": mu.run_sklearn_model,\n",
        "        \"catboost\": mu.run_catboost_model,\n",
        "        \"lightgbm\": mu.run_lgb_model,\n",
        "        \"stackingregressor\": mu.run_sklearn_model,\n",
        "    }\n",
        "    train_predict, test_predict, fitted_model = run_model_dict[model_name](\n",
        "            model, processed_train_x_df, train_filter_y_df, processed_test_x_df\n",
        "        )\n",
        "    training_rmse = mu.calculate_rmse(train_filter_y_df, train_predict)\n",
        "    print(f\"Whole data train RMSE: {training_rmse}\")\n",
        "\n",
        "    ## output save result\n",
        "    model_rmse.loc[model_rmse.shape[0], :] = [0, training_rmse, np.nan]\n",
        "    model_rmse[\"method\"] = model_rmse[\"left_out_year\"].apply(\n",
        "        lambda x: \"loyo\" if x > 0 else \"whole train\"\n",
        "    )\n",
        "    display(model_rmse)\n",
        "    model_rmse.to_csv(\n",
        "        f\"{wids_path}validation_result/{config_name}.csv\", index=False\n",
        "    )\n",
        "    test_prediction_result = test_df[[\"id\"]]\n",
        "    test_prediction_result[\"site_eui\"] = test_predict\n",
        "    test_prediction_result.to_csv(f\"{wids_path}prediction_result/{config_name}.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRTWA3Wekpkr",
        "outputId": "5e60d9f4-24bb-434f-9209-7030b7a4f89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting PCA with 9 components\n",
            "log_temp_pca_onehot_impute_parse_upsample_stacking stackingregressor ['direction_peak_wind_speed', 'days_above_100f', 'days_above_90f', 'max_wind_speed', 'days_with_fog', 'snowdepth_inches', 'snowfall_inches', 'building_class', 'precipitation_inches', 'year_built', 'cooling_degree_days', 'days_below_10f', 'days_above_80f', 'state_factor', 'direction_max_wind_speed', 'heating_degree_days', 'days_below_30f', 'days_below_20f', 'days_above_110f', 'elevation', 'days_below_0f', 'temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4', 'temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'temp_pca9', 'backfilled_energy_star_rating', 'facility_type_parsed', 'log10_floor_area'] True\n",
            "Running sklearn\n",
            "Modeling 1...\n",
            "Fitting 5 regressors...\n",
            "Fitting regressor1: catboostregressor (1/5)\n",
            "<catboost.core.CatBoostRegressor object at 0x7f1e69f99590>\n",
            "Fitting regressor2: xgbregressor (2/5)\n",
            "XGBRegressor(eta=0.1, grow_policy='lossguide', max_depth=10, n_estimators=3000,\n",
            "             tree_method='gpu_hist')\n",
            "[03:51:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Fitting regressor3: kneighborsregressor (3/5)\n",
            "KNeighborsRegressor(n_neighbors=20)\n",
            "Fitting regressor4: ridge (4/5)\n",
            "Ridge(alpha=10)\n",
            "Fitting regressor5: svr (5/5)\n",
            "SVR(epsilon=0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mI4NwUlRIESs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}